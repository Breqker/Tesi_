\chapter{Sistemi di raccomandazione}
\label{chap:sistemi-raccomandazione}

L'evoluzione del Web e la pervasività dei dispositivi mobili intelligenti hanno trasformato radicalmente il modo in cui gli utenti interagiscono con i servizi online. La crescita esponenziale del traffico su piattaforme web, app e social network ha generato un enorme quantitativo di dati, portando al fenomeno noto come \textit{information overload}. In questo scenario gli utenti si trovano spesso nell'incapacità di prendere decisioni efficienti a causa della sovrabbondanza di opzioni disponibili. \cite{Ko2022}

I Sistemi di Raccomandazione (RS) emergono come la soluzione tecnologica chiave a questo problema; essi sono sistemi avanzati di filtraggio delle informazioni (\textit{information filtering tools}), il cui obiettivo è ridurre lo sforzo cognitivo e il tempo che l'utente deve dedicare alla ricerca di contenuti rilevanti. Non si tratta più di suggerire prodotti, ma di personalizzare l'intera esperienza utente analizzando pattern comportamentali complessi. \cite{Roy2022}

L'evoluzione della ricerca in questo campo è stata guidata dal cambiamento nella tipologia di dati disponibili. Mentre i primi sistemi si basavano quasi esclusivamente su feedback espliciti (come i rating o i "like"), le architetture moderne sfruttano massicciamente i dati impliciti derivanti dal \textit{clickstream}, dai log di navigazione, e più recentemente, dai sensori dei dispositivi IoT e wearable. \cite{Ko2022}

Tuttavia, nonostante il loro successo commerciale in settori come l'e-commerce (Amazon, eBay, Alibaba) e lo streaming multimediale (Netflix, Spotify), lo sviluppo di un RS efficace presenta sfide ingegneristiche notevoli. La selezione dell'algoritmo più adatto è strettamente legata al dominio applicativo e deve affrontare limitazioni intrinseche quali la scarsità dei dati (\textit{data sparsity}), la difficoltà nel gestire nuovi utenti o item (\textit{cold-start problem}) e la necessità di garantire la scalabilità su grandi dataset. A queste criticità si aggiunge l'esigenza di bilanciare l'accuratezza predittiva con obiettivi di qualità quali la novità (\textit{novelty}) e la diversità (\textit{diversity}) delle proposte, fondamentali per mantenere alto il coinvolgimento dell'utente. \cite{Roy2022}

In questo capitolo verrà analizzato lo stato dell'arte dei Sistemi di Raccomandazione, partendo dai modelli statistici tradizionali fino alle recenti applicazioni di Deep Learning e Intelligenza Artificiale Generativa, esaminando come la letteratura scientifica abbia affrontato le sfide sopra citate.

\section{Formalizzazione del problema}
\label{sec:formalizzazione_rs}

Prima di analizzare le architetture algoritmiche, è necessario definire il formalismo matematico che sottende il funzionamento di un Sistema di Raccomandazione e le tipologie di dati su cui esso opera.

\subsection{Notazione matematica}
\label{subsec:matematica_rs}

In un contesto generico di raccomandazione, definiamo $\mathcal{U} = \{u_1, u_2, \dots, u_M\}$ come l'insieme degli utenti (\textit{users}) e $\mathcal{I} = \{i_1, i_2, \dots, i_N\}$ come l'insieme degli oggetti (\textit{items}). Lo spazio delle possibili interazioni è rappresentato da una matrice di utilità $\mathbf{R} \in \mathbb{R}^{M \times N}$, dove l'elemento $r_{ui}$ indica il grado di preferenza dell'utente $u$ per l'item $i$.

Una criticità intrinseca di questo modello è l'elevata sparsità della matrice $\mathbf{R}$,  dovuta al fatto che un utente tipico interagisce solo con una mininima frazione degli oggetti disponibili (si veda la Tabella \ref{tab:matrix_example}).

\begin{table}[h]
    \centering
    \renewcommand{\arraystretch}{1.2}
    \begin{tabular}{c|ccccc}
        \toprule
        & \textbf{Item 1} & \textbf{Item 2} & \textbf{Item 3} & $\dots$ & \textbf{Item N} \\
        \midrule
        \textbf{User 1} & 5 & ? & 3 & $\dots$ & ? \\
        \textbf{User 2} & ? & 4 & ? & $\dots$ & 1 \\
        \textbf{User 3} & 2 & ? & ? & $\dots$ & ? \\
        $\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ & $\ddots$ & $\vdots$ \\
        \textbf{User M} & ? & ? & 5 & $\dots$ & 4 \\
        \bottomrule
    \end{tabular}
    \caption{Esempio di Matrice di Utilità sparsa ($\mathbf{R}$). Il simbolo '?' indica i rating mancanti che il sistema deve predire.}
    \label{tab:matrix_example}
\end{table}

Definiamo $\Omega = \{(u, i) \mid r_{ui} \text{ è osservato} \}$ come l'insieme delle interazioni note.
L'obiettivo del sistema è stimare una funzione di scoring $f: \mathcal{U} \times \mathcal{I} \rightarrow \mathbb{R}$ in grado di predire i valori mancanti o di generare una lista ordinata di item (Top-K) non ancora fruiti dall'utente, massimizzando una specifica funzione di utilità. \cite{Roy2022}

\subsection{Tipologie di Feedback}
\label{subsec:feedback}

La natura del valore $r_{ui}$ determina la classe di algoritmi applicabili e la complessità del problema. La letteratura scientifica distingue due categorie principali di input:

\begin{itemize}
    \item \textbf{Feedback Esplicito}: l'utente esprime intenzionalmente e direttamente la propria preferenza, ad esempio tramite un voto numerico, (es: scala 1-5 stelle) o un'azione binaria ("like"/"dislike"). Questo approccio offre un segnale inequivocabile della soddisfazione (o insoddisfazione) dell'utente. Tuttavia, il principale svantaggio risiede nella difficoltà di raccogliere questi dati in volumi massivi, a causa del carico cognitivo richiesto all'utente nel compiere l'azione di valutazione. \cite{Resnick1994}
    \item \textbf{Feedback Implicito}: il sistema inferisce le preferenze osservando il comportamento naturale dell'utente, senza richiedere un input diretto. Esempi includono la cronologia degli acquisti, il tempo di permanenza su una pagina, i click o il numero di volte che un brano è stato riprodotto. Sebbene questi dati siano intrinsecamente rumorosi (un click non implica necessariamente gradimento) e manchino di feedback negativo esplicito, la loro abbondanza li rende la fonte primaria per i moderni sistemi di raccomandazione su larga scala. \cite{Hu2008}
\end{itemize}

La figura \ref{fig:feedback-sources} illustra schematicamente le sorgenti di dati più comuni per entrambe le categorie, evidenziando come il feedback esplicito derivi da valutazioni dirette, mentre quello implicito da tracce comportamentali.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{feedback_sources.png}
    \caption{Classificazione delle sorgenti in Feedback Esplicito e Implicito. \\
    Immagine tratta da \cite{Hidaka2023}}
    \label{fig:feedback-sources}
\end{figure}

Sebbene la distinzione sia netta, nello scenario operativo reale i sistemi di raccomandazione adottano quasi sempre un approccio ibrido nella raccolta dati. L'utilizzo congiunto delle due tipologie permette di compensare le rispettive debolezze: l'abbondanza del feedback implicito viene utilizzata per mitigare il problema della \textit{data sparsity}, mentre il feedback esplicito (ove disponibile) funge da \textit{ground truth} per validare l'accuratezza delle predizioni. \cite{Roy2022}

\subsection{Definizione del Task}
\label{subsec:task}

In funzione dell'obiettivo finale, il problema di raccomandazione viene modellato in letteratura secondo diverse formulazioni. Questa distinzione determina l'architettura della funzione di apprendimento (\textit{Loss function}) e la struttura dei dati in input:

\begin{itemize}
    \item \textbf{Rating Prediction (Regressione)}: il sistema ha l'obiettivo di stimare il valore esatto $\hat{r}_{ui}$ che l'utente $u$ assegnerebbe all'item $i$. Questo approccio tratta il problema come un task di \textit{regressione}, dove l'obiettivo è minimizzare l'errore quadratico (es. RMSE) tra il voto predetto e quello reale. Sebbene fosse predominante in passato, l'uso di questo task è diminuito con il declino dei feedback espliciti.
    \item \textbf{Top-N Recommendation (Ranking)}: il sistema genera una lista ordinata $\mathcal{L}_u = \{i_1, i_2, \dots, i_N\}$ di $N$ item che siano i più rilevanti per l'utente. Attualmente rappresenta lo standard per scenari con feedback implicito, trattando il problema come un task di \textit{classificazione} (prevedere la probabilità di interazione) o di \textit{learning-to-rank}. L'obiettivo è posizionare gli item rilevanti ai primi posti della lista, valutando la qualità dell'ordinamento tramite metriche posizionali (es. NDCG). \cite{Zhang2019}
    \item \textbf{Sequential Recommendation (Next-Item)}: a differenza del Top-N statico, qui l'ordine temporale delle interazioni è cruciale. L'obiettivo è predire l'item successivo $i_{t+1}$ basandosi sulla sequenza storica immediata $\mathcal{S}_u = \{i_1, i_2, \dots, i_t\}$. Questo task è essenziale per modellare l'evoluzione dinamica degli interessi dell'utente (es. sessioni di navigazione anonime), sfruttando architetture come RNN o Transformer. \cite{Batmaz2019}
    \item \textbf{Cross-Domain Recommendation}: in questo scenario, il sistema mira a migliorare le raccomandazioni in un dominio target (es. vendita di libri) sfruttando la conoscenza appresa da un dominio sorgente differente ma correlato (es. visione di film). Questo task è essenziale per mitigare il problema del \textit{cold-start} in domini dove i dati sono scarsi, utilizzando tecniche di \textit{Transfer Learning}. \cite{Zhou2023}
    \item \textbf{Multi-Criteria Recommendation}: mentre i sistemi tradizionali si basano su un singolo valore di utilità, questo task modella la preferenza come un vettore di valutazioni su molteplici aspetti dell'item (es. per un hotel: pulizia, posizione, prezzo). L'obiettivo è stimare un rating complessivo aggregando le predizioni sui singoli criteri, offrendo una granularità maggiore nella profilazione dell'utente. \cite{Zhou2023}
    \item \textbf{Explainable Recommendation}: con l'avvento delle normative sull'IA (es. AI Act), diventa un task a sé stante non solo predire l'item, ma generare una spiegazione intelligibile (testuale o visuale) del perché quell'item è stato scelto. Il modello deve quindi ottimizzare congiuntamente l'accuratezza della raccomandazione e la qualità semantica della spiegazione. \cite{Zhang2020}
    \item \textbf{Context-Aware Recommendation}: in questo scenario, la funzione di utilità viene estesa per includere variabili d'ambiente $c$ (es. orario, posizione geografica, dispositivo). Il task diventa la stima di una funzione multidimensionale $f(u, i, c) \rightarrow \mathbb{R}$, permettendo di adattare la raccomandazione alla situazione specifica in cui si trova l'utente al momento della fruizione. \cite{Roy2022}
    \item \textbf{Link Prediction}: tipico dei sistemi modellati come grafi (es. Social Network o Knowledge Graphs), questo task mira a predire l'esistenza di una connessione futura o mancante tra due nodi. In un grafo bipartito utente-item, la raccomandazione viene formulata come la stima della probabilità di formazione di un arco $(u, i)$. Questo task è utilizzato principalmente nelle Graph Neural Networks (GNN). \cite{Wu2022}
\end{itemize}

\subsection{Sfide e Vincoli del Problema}
\label{subsec:sfide_vincoli}

La formulazione della funzione obiettivo $f$ è soggetta a vincoli intrinseci alla natura dei dati e requisiti operativi, che influenzano la scelta degli algoritmi. Identifichiamo le seguenti criticità principali:

\begin{itemize}
    \item \textbf{Data Sparsity}: la matrice $\mathbf{R}$ è definita solo su un sottoinsieme $\Omega$ molto limitato. Il grado di sparsità è spesso superiore al 99\% in sistemi reali. Questo rende difficile il calcolo di similarità affidabili tra utenti o item, degradando le performance degli algoritmi collaborativi.
    \item \textbf{Cold-Start}: si riferisce alla difficoltà di inferire preferenze in assenza di dati storici. Si distingue in \textit{New User Problem} (il sistema non ha dati su un nuovo utente) e \textit{New Item Problem} (un nuovo item non ha ancora ricevuto un feedback). In questi scenari, i metodi puramente collaborativi falliscono, richiedendo l'adozione di strategie ibride o content-based. \cite{Roy2022}
    \item \textbf{Scalabilità}: con la crescita esponenziale del numero di utenti $M$ e di item $N$, la complessità computazionale di algoritmi come il k-NN ($O(M^2)$) diventa insostenibile per applicazioni che richiedono risposta in tempo reale. È necessario bilanciare l'accuratezza della predizione con la latenza di risposta, spesso ricorrendo a tecniche di riduzione della dimensionalità o al calcolo distribuito.
    \item \textbf{Grey Sheep Problem}: questo termine indica quegli utenti le cui preferenze sono idiosincratiche, ovvero non condivise dalla maggior parte degli utenti, e non mostrano correlazioni significative con nessun gruppo di utenti (cluster) dominante. Per questi profili "atipici", i sistemi collaborativi faticano a generare raccomandazioni accurate a causa della mancanza di vicini simili. \cite{Roy2022}
    \item \textbf{Robustezza}: i sistemi di raccomandazione, basandosi su input esterni (feedback utenti), sono intrinsecamente vulnerabili a manipolazioni dei dati note come \textit{Shilling Attacks}. La sfida consiste nel garantire l'affidabilità delle predizioni anche in presenza di profili malevoli inseriti per alterare la popolarità degli item. A causa della rilevanza critica di questo aspetto per l'integrità del sistema, la tassonomia degli attacchi verrà trattata in dettaglio nella Sezione \ref{subsec:attack_taxonomy}.
    \item \textbf{Privacy e Sicurezza}: l'utilizzo massivo di dati personali (spesso sensibili nel caso di sistemi Context-Aware) pone vincoli legali ed etici stringenti. Le moderne architetture devono integrare tecniche di \textit{Privacy-Preserving Data Mining} per operare in conformità con normative come il GDPR, cercando di non degradare eccessivamente la qualità della raccomandazione a fronte dell'anonimizzazione dei dati. \cite{Zhou2023}
\end{itemize}

\section{Modelli di Raccomandazione}
\label{sec:modelli}

La letteratura scientifica ha prodotto nel corso degli anni una vasta tassonomia di algoritmi, evolvendo da semplici euristiche basate sulle similarità a complesse architetture neurali generative.

\subsection{Modelli di Raccomandazione tradizionali}
\label{subsec:modelli-tradizionali}

La letteratura scientifica classifica gli approcci consolidati in tre macro-categorie, distinte in base alla tipologia di dati utilizzati per l'inferenza delle preferenze e alla logica algoritmica adottata. La figura \ref{fig:traditional_rs} illustra questa tassonomia.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{traditional_rs.png}
    \caption{Tassonomia gerarchica dei modelli di raccomandazione tradizionali. \\
    Immagine tratta da \cite{Ko2022}}
    \label{fig:traditional_rs}
\end{figure}

\subsubsection{Content-Based Filtering (CBF)}

L'approccio \textit{Content-Based} si fonda sull'assunto che le preferenze di un utente tendano a mantenersi stabili rispetto alle caratteristiche intrinseche degli oggetti. Se un utente ha apprezzato un item con determinate proprietà in passato, è probabile che apprezzerà item simili in futuro. \cite{Loeb1992}

Il sistema opera costruendo due entità vettoriali:
\begin{itemize}
    \item \textbf{Item Profile}: una rappresentazione strutturata delle caratteristiche dell'oggetto (es. per un film: genere, regista, cast; per un documento: keywords estratte).
    \item \textbf{User Profile}: un vettore che aggrega le caratteristiche degli item con cui l'utente ha interagito positivamente, pesandole in base al gradimento.
\end{itemize}

Il vantaggio ingegneristico del CBF è l'indipendenza degli altri utenti (\textit{User Independence}). Questo permette di risolvere il problema del \textit{New Item Cold-Start}: non appena un nuovo oggetto viene inserito nel catalogo con i suoi metadati, può essere immediatamente raccomandato senza attendere i voti della comunità. \cite{Ko2022}

\paragraph*{Vector Space Model}  ~\\

Dal punto di vista implementativo, il CBF tratta la raccomandazione come un problema di \textit{Information Retrieval}. I dati non strutturati vengono trasformati in vettori numerici nello spazio delle feature tramite il \textit{Vector Space Model}. \cite{Salton1975}

La tecnica standard per la ponderazione delle feature è il **TF-IDF** (\textit{Term Frequency-Inverse Document Frequency}). Questo schema assegna un peso a ogni termine $t$ in un documento $d$ (item) secondo la formula:

\begin{equation}
    w_{t,d} = \text{TF}(t, d) \cdot \log\left(\frac{N}{|\{d \in D : t \in d\}|}\right)
\end{equation}

Dove:
\begin{itemize}
    \item $\text{TF}(t,d)$ è la frequenza del termine del documento (quanto il termine descrive l'item).
    \item il secondo termine è l'\textit{Inverse Document Frequency} (IDF), dove $N$ è il numero totale di documenti e il denominatore è il numero di documenti che contengono il termine $t$. Questo fattore serve a penalizzare le parole troppo comuni che hanno scarso potere discriminante. \cite{Salton1975}
\end{itemize}

Una volta mappati l'utente $u$ e l'item $i$ nello spazio vettoriale come vettori $\mathbf{p}_u$ e $\mathbf{q}_i$, la rilevanza viene calcolata tramite la **Cosine-Similarity**:

\begin{equation}
    \text{sim}(\mathbf{p}_u, \mathbf{q}_i) = \cos(\theta) = \frac{\mathbf{p}_u \cdot \mathbf{q}_i}{||\mathbf{p}_u|| \cdot ||\mathbf{q}_i||}
\end{equation}

Maggiore è il valore (prossimo a 1), maggiore è l'allineamento tra il profilo utente e le caratteristiche dell'item.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{cbf_rs.png}
    \caption{Schema logico del modello Content-Based Filtering. \\
    Immagine tratta da \cite{Ko2022}}
    \label{fig:cbf_rs}
\end{figure}

\subsubsection{Collaborative Filtering (CF)}

A differenza degli approcci \textit{Content-Based}, il \textit{Collaborative Filtering} non richiede l'analisi delle caratteristiche intrinseche degli oggetti (es. testo o immagini), ma basa le sue predizioni esclusivamente sulle interazioni passate registrate nella matrice di utilità $\mathbf{R}$.

Il principio fondante dei CF è l'\textbf{omofilia}: l'assunto sociologico secondo cui utenti che hanno manifestato preferenze simili in passato tenderanno a concordare anche in futuro. Questo approccio permette di catturare pattern latenti (es. la qualità della scrittura o lo stile di regia) che non sono esplicitamente descrivibili tramite metadati, sfruttando la cosiddetta \textit{wisdom of the crowd}. \cite{Ko2022}

La letteratura scientifica divide il CF in due grandi famiglie algoritmiche: \textit{Memory-Based} e \textit{Model-Based}.

\paragraph*{Memory-Based (Neighborhood Methods)} ~\\

Questi algoritmi sono euristici e calcolano la similarità direttamente sulla matrice di interazione senza una fase di training globale. Si distinguono in due varianti:

\begin{itemize}
    \item \textbf{User-Based CF}: identifica i $k$ utenti più simili all'utente target $u$ (i "vicini") e stima il voto come media pesata del loro rating. \cite{Resnick1994} La similarità tra due utenti $u$ e $v$ è calcolata tramite la \textbf{Pearson correlation}, che è preferibile alla \textit{Cosine Similarity} in quanto sottrae la media dei voti dell'utente $(\bar{r}_u$), gestendo così il bias di utenti che tendono a votare sempre alto o sempre basso:
    
    \begin{equation}
        \text{sim}(u, v) = \frac{\sum_{i \in I_{uv}} (r_{ui} - \bar{r}_u)(r_{vi} - \bar{r}_v)}{\sqrt{\sum_{i \in I_{uv}} (r_{ui} - \bar{r}_u)^2} \sqrt{\sum_{i \in I_{uv}} (r_{vi} - \bar{r}_v)^2}}
    \end{equation}

    \item \textbf{Item-Based CF}: calcola la similarità tra coppie di \textit{item} basandosi sulla co-occorrenza dei voti ricevuti dagli stessi utenti (es. "Chi ha comprato X ha anche comprato Y"). \cite{Sarwar2001,Linden2003} Questo approccio è generalmente più stabile e scalabile dello User-Based, poiché la natura degli oggetti cambia meno frequentemente rispetto ai gusti degli utenti e il numero di item è spesso inferiore al numero totale degli utenti.
\end{itemize}

\paragraph*{Model-Based (Matrix Factorization (MF))} ~\\

I metodi Memory-Based degradano rapidamente in condizioni di alta sparsità. I metodi \textit{Model-Based} risolvono il problema utilizzando un approccio a \textbf{fattori latenti}. \cite{Koren2009}
L'ipotesi è che le preferenze dipendano da un piccolo numero di fattori nascosti in uno spazio di dimensione $K$. La matrice sparsa $\mathbf{R}$ viene approssimata dal prodotto di due matrici dense: $\mathbf{R} \approx \mathbf{P} \times \mathbf{Q}^T$.

\subparagraph*{Standard MF (Feedback Esplicito)} ~\\

Nel caso classico, ogni utente $u$ e item $i$ sono associati ai vettori $\mathbf{p}_u, \mathbf{q}_i \in \mathbb{R}^K$. La predizione è il loro prodotto scalare:

\begin{equation}
    \hat{r}_{ui} = \mathbf{p}_u^T \mathbf{q}_i = \sum_{k=1}^K p_{uk} q_{ik}
\end{equation}

I parametri vengono appresi minimizzando l'errore quadratico sui soli rating osservati tramite \textit{Stochastic Gradient Descent} (SGD).

\subparagraph*{Weighted Regularized MF (WRMF - Feedback Implicito)} ~\\

Quando si lavora con feedback implicito (es. click), l'assenza di interazione è un dato mancante, non un feedback negativo.

Introduciamo il concetto di \textit{livello di confidenza}: $c_{ui} = 1 + \alpha \cdot r_{ui}$ per la \textit{Weighted Regularized Matrix Factorization} (WRMF). \cite{Hu2008}
La funzione obiettivo minimizza l'errore su tutte le coppie (osservate e non), pesate dalla confidenza:

\begin{equation}
    \min_{\mathbf{P}, \mathbf{Q}} \sum_{u,i} c_{ui} (p_{ui} - \mathbf{p}_u^T \mathbf{q}_i)^2 + \lambda (\|\mathbf{p}_u\|^2 + \|\mathbf{q}_i\|^2)
\end{equation}

Questo approccio rende WRMF la baseline di riferimento per i dati impliciti.

\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{cf_rs.png}
    \caption{Schema logico del modello Collaborative Filtering. \\
    Immagine tratta da \cite{Ko2022}}
    \label{fig:cf_rs}
\end{figure}

\subsubsection{Hybrid System}

Nessun algoritmo è esente da difetti strutturali: il \textit{Content-Based Filtering} soffre di scarsa diversità e non sfrutta la wisdom of the crowd, mentre il \textit{Collaborative Filtering} fallisce in presenza di nuovi item o nuovi utenti (\textit{Cold-Start}) a causa della mancanza di interazioni pregresse.
I sistemi ibridi nascono per combinare i punti di forza di entrambi gli approcci, mitigandone le rispettive debolezze attraverso tecniche di fusione dei dati o dei modelli.

Secondo la tassonomia standard, le architetture ibride possono essere classificate in base alla modalità di integrazione: \cite{Burke2002,Roy2022}

\begin{itemize}
    \item \textbf{Weighted}: il punteggio finale di un item è calcolato come combinazione lineare degli score di diversi recommender. Ad esempio, data una predizione $s_{CBF}$ e una $s_{CF}$ il voto finale sarà $s_{tot} = \alpha \cdot s_{CBF} + (1 - \alpha) \cdot s_{CF}$. I pesi $\alpha$ possono essere appresi o fissati sperimentalmente.
    \item \textbf{Switching}: il sistema seleziona dinamicamente un unico algoritmo tra quelli disponibili in base allo stato del sistema o alla confidenza della predizione (es. una CBF per i nuovi utenti e commuta a CF quando il profilo è sufficientemente denso).
    \item \textbf{Cascased}: un processo gerarchico in cui un primo algoritmo genera un insieme di candidati grezzo, che viene poi raffinato e riordinato da un secondo algoritmo più preciso. È molto efficiente per ridurre lo spazio di ricerca su grandi cataloghi.
    \item \textbf{Mixed}: il sistema presenta simultaneamente i risultati di diversi algoritmi in un'unica interfaccia (es. una lista "Consigliati per te" basata sul CF e una lista "Simili a ciò che hai visto" basata sul CBF). È utile per risolvere il problema del \textit{New Item} mostrando contenuti basati sul contenuto insieme a quelli popolari.
    \item \textbf{Feature Combination}: le feature provenienti da diversi soggetti vengono fuse in un unico vettore di input per un singolo algoritmo di raccomandazione. Questo approccio non usa due modelli separati, ma un unico modello che apprende da dati eterogenei.
    \item \textbf{Feature Augmentation}: l'output di un modello viene utilizzato come feature di input per un altro. Ad esempio, le predizioni di un modello Content-Based possono essere usate per riempire i valori mancanti nella matrice di utilità, permettendo poi a un modello Collaborative di operare su una matrice più densa.
    \item \textbf{Meta-Level}: il modello interno appreso da un algoritmo (e non solo il suo output) viene usato come input per un altro. Ad esempio, un modello Content-Based può apprendere una rappresentazione vettoriale dell'utente che verrà usata come input per un kernel in un sistema Collaborative.
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{hybrid_rs.png}
    \caption{Schema logico del modello ibrido. \\
    Immagina tratta da \cite{Ko2022}}
    \label{fig:hybrid_rs}
\end{figure}

\subsection{Modelli di raccomandazione basati su Deep Learning}
\label{subsec:modelli-deep-learning}

A partire dal 2016, la ricerca nel campo dei RS ha subito un cambio di paradigma con l'introduzione massiva del \textit{Deep Learning}. Mentre i modelli tradizionali sono intrinsecamente lineari (basati sul prodotto scalare), le reti neurali permettono di approssimare funzioni di interazione continua arbitrarie e non lineari, catturando relazioni complesse tra utenti e item. \cite{Zhang2019}

\subsubsection{Neural Collaborative Filtering (NCF)}

Nasce per superare il limite intrinseco della Matrix Factorization: l'uso del prodotto scalare come funzione di interazione fissa.
Sebbene efficace, il prodotto scalare impone che le interazioni tra utenti e item risiedano in uno spazio lineare, limitando l'espressività del modello (violazione della disuguaglianza triangolare nello spazio latente). \cite{He2017}

NCF propone di sostituire il prodotto scalare con una rete neurale apprendibile, in grado di approssimare qualsiasi funzione continua (grazie all'\textit{Universal Approximation Theorem}). L'architettura completa denominata \textit{NeuMF} (Neural Matrix Factorization), unisce due sotto-architetture parallele per catturare sia le relazioni lineari che quelle non lineari: la \textit{Generalized Matrix Factorization} e il \textit{Multi-Layer Perceptron} (MLP).

\paragraph*{Generalized Matrix Factorization (GMF)} ~\\

Questa componente è una reinterpretazione neurale della fattorizzazione classica. Dati i vettori di embedding dell'utente $\mathbf{p}_u^G$ e dell'item $\mathbf{q}_i^G$, l'interazione è modellata tramite un prodotto element-wise ($\odot$):
\begin{equation}
    \phi^{GMF} = \mathbf{p}_u^G \odot \mathbf{q}_i^G
\end{equation}
Questo vettore viene poi proiettato verso l'output, mantenendo la capacità di catturare le relazioni lineari tipiche della MF.


\paragraph*{Multi-Layer Perceptron (MLP)} ~\\

Per catturare le interazioni non lineari complesse, NCF utilizza una torre di strati densi. Qui, gli embedding di utente $\mathbf{p}_u^M$ ed item $\mathbf{q}_i^M$ (distinti da quelli della GMF per maggiore flessibilità) vengono concatenati:
\begin{equation}
    \mathbf{z}_0 = \begin{bmatrix} \mathbf{p}_u^M \\ \mathbf{q}_i^M \end{bmatrix}
\end{equation}
Il segnale attraversa $L$ strati nascosti con funzione di attivazione ReLU, che introduce la non-linearità necessaria:
\begin{equation}
    \mathbf{z}_l = \text{ReLU}(\mathbf{W}_l \cdot \mathbf{z}_{l-1} + \mathbf{b}_l), \quad l = 1 \dots L
\end{equation}
dove $\mathbf{W}_l$ e $\mathbf{b}_l$ sono rispettivamente la matrice dei pesi e il vettore di bias dell'$l$-esimo strato.

\paragraph*{NeuMF: Fusione e Training} ~\\

L'output finale $\hat{y}_{ui}$ è ottenuto concatenando l'uscita delle due componenti (GMF e MLP) e passandola a un layer di output finale, chiamato strato di NeuMF, con funzione di attivazione Sigmoide $\sigma$:
\begin{equation}
    \hat{y}_{ui} = \sigma\left( \mathbf{h}^T \cdot \begin{bmatrix} \phi^{GMF} \\ \mathbf{z}_L \end{bmatrix} \right)
\end{equation}
Poiché NCF è progettato principalmente per feedback implicito (dove $y_{ui} = 1$ se c'è interazione, $0$ altrimenti), il modello non viene addestrato minimizzando l'errore quadratico (MSE), bensì trattando il problema come una classificazione binaria probabilistica. La funzione obiettivo è la **Binary Cross-Entropy (Log Loss)**:
\begin{equation}
    L = - \sum_{(u,i) \in \mathcal{Y}^+} \log(\hat{y}_{ui}) - \sum_{(u,j) \in \mathcal{Y}^-} \log(1 - \hat{y}_{uj})
\end{equation}
dove $\mathcal{Y}^+$ sono le interazioni osservate e $\mathcal{Y}^-$ sono campioni negativi (item non interagiti) generati tramite \textit{Negative Sampling}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{ncf_rs.png}
    \caption{Schema architetturale del modello Neural Collaborative Filtering. \\
    Immagine tratta da \cite{He2017}}
    \label{fig:ncf_rs}
\end{figure}

\subsubsection{Autoencoder-based Collaborative Filtering}

Parallelamente all'approccio NCF, che modella l'interazione puntuale utente-item, la ricerca ha esplorato l'uso di modelli di ricostruzione, in particolare gli \textit{Autoencoder} (AE). Mentre la Matrix Factorization e la NCF cercano di apprendere una funzione di scoring, gli approcci basati su AE riformulano il problema del Collaborative Filtering come un compito di \textit{Matrix Completion}: l'obiettivo è assumere in input vettori di rating parziali (sparsi) e ricostruirli in output riempiendo i valori mancanti. \cite{Zhang2019}

Il modello pionieristico che ha formalizzato l'uso degli autoencoder per il rating prediction è \textit{AutoRec}. \cite{Sedhain2015} A differenza delle tecniche precedenti che apprendevano proiezioni lineari (come SVD), AutoRec introduce non-linearità nel processo di codifica e decodifica, permettendo di catturare pattern di co-occorrenza più complessi tra gli item o gli utenti.

Il modello può essere istanziato in due varianti strutturali simmetriche, a seconda che si voglia ricostruire il profilo di un item o di un utente.

\paragraph*{Item-based AutoRec (I-AutoRec)} ~\\

In questa configurazione, il modello impara a ricostruire i vettori colonna della matrice di rating. Dato un insieme di $m$ utenti, l'input è il vettore $\mathbf{r}^{(i)} \in \mathbb{R}^m$, contenente i voti ricevuti dall'$i$-esimo item.
La ricostruzione $h(\mathbf{r}^{(i)}; \theta)$ avviene proiettando l'input in uno spazio latente $k$-dimensionale e ricostruendolo:

\begin{equation}
    h(\mathbf{r}^{(i)}; \theta) = f\left( \mathbf{W} \cdot g(\mathbf{V} \cdot \mathbf{r}^{(i)} + \boldsymbol{\mu}) + \mathbf{b} \right)
\end{equation}

Dove $\mathbf{V} \in \mathbb{R}^{k \times m}$ e $\mathbf{W} \in \mathbb{R}^{m \times k}$ sono le matrici di pesi rispettivamente di encoder e decoder. Poiché il numero di utenti $m$ può essere molto elevato, questa variante richiede un numero di parametri proporzionale alla base utenti.

\paragraph*{User-based AutoRec (U-AutoRec)} ~\\

In questa configurazione, l'obiettivo è ricostruire i vettori riga. Dato un insieme di $n$ item, l'input è il vettore $\mathbf{r}^{(u)} \in \mathbb{R}^n$, contenente i voti assegnati dall'$u$-esimo utente.
La formulazione matematica è analoga ma dimensionalmente trasposta:

\begin{equation}
    h(\mathbf{r}^{(u)}; \theta) = f\left( \mathbf{W} \cdot g(\mathbf{V} \cdot \mathbf{r}^{(u)} + \boldsymbol{\mu}) + \mathbf{b} \right)
\end{equation}

In questo caso, le matrici di peso hanno dimensioni $\mathbf{V} \in \mathbb{R}^{k \times n}$ e $\mathbf{W} \in \mathbb{R}^{n \times k}$.

\paragraph*{Confronto e Funzioni di Attivazione} ~\\

Sebbene i modelli siano strutturalmente simmetrici, \textit{I-AutoRec} tende ad ottenere prestazioni superiori (RMSE inferiore). \cite{Sedhain2015} Questo fenomeno è attribuibile alla varianza dei dati: il numero medio di valutazioni per item è spesso superiore a quello per utente, fornendo all'autoencoder vettori di input più densi e informativi per l'apprendimento delle feature latenti. 

Le funzioni $g(\cdot)$ e $f(\cdot)$ sono le attivazioni non lineari (tipicamente Sigmoide o Identità). L'uso di attivazioni non lineari è cruciale: senza di esse, AutoRec collasserebbe in una semplice fattorizzazione di matrice lineare.

\paragraph*{Funzione Obiettivo: Masked Error} ~\\

La sfida principale nell'addestramento è la sparsità dei dati. A differenza della compressione di immagini, dove ogni pixel ha un valore noto, qui la maggior parte delle entrate nei vettori $\mathbf{r}$ sono sconosciute.
Il modello non deve essere penalizzato per non aver ricostruito gli zeri che rappresentano dati mancanti. Pertanto, AutoRec impiega una funzione di costo basata su **Masked Mean Squared Error** (MMSE).

Indipendentemente dalla variante scelta (utente o item), la backpropagation aggiorna i pesi considerando solamente i rating osservati. La funzione obiettivo da minimizzare per I-AutoRec (analoga per U-AutoRec) è:

\begin{equation}
    \min_{\theta} \sum_{i=1}^{n} \left\| \mathbf{r}^{(i)} - h(\mathbf{r}^{(i)}; \theta) \right\|_{\mathcal{O}}^2 + \frac{\lambda}{2} \cdot (\|\mathbf{W}\|_F^2 + \|\mathbf{V}\|_F^2)
\end{equation}

dove $\|\cdot\|_{\mathcal{O}}^2$ indica che la norma euclidea viene calcolata solo sulle componenti per cui il rating è osservato. Il termine $\lambda$ controlla la regolarizzazione $L_2$ per prevenire l'overfitting.

Una volta addestrato il modello, la predizione $\hat{R}_{ui}$ si ottiene prelevando la componente corrispondente dal vettore ricostruito: l'$u$-esima componente di $h(\mathbf{r}^{(i)})$ nel caso I-AutoRec, o l'$i$-esima componente di $h(\mathbf{r}^{(u)})$ nel caso U-AutoRec.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{autoencoder_rs.png}
    \caption{Schema logico del modello Item-based AutoRec. \\
    Immagine tratta da \cite{Sedhain2015}}
    \label{fig:autoencoder_rs}
\end{figure}

\subsubsection{Session-based Recommendations with Recurrent Neural Networks}

Esiste una classe di problemi in cui la dimensione temporale è predominante. In scenari come l'e-commerce o lo streaming, l'identità dell'utente potrebbe non essere nota (sessioni anonime) o le intenzioni potrebbero cambiare rapidamente. \cite{Zhang2019}

Per affrontare questo problema, la ricerca si è spostata verso le \textit{Session-based Recommendation} utilizzando le Reti Neurali Ricorrenti (RNN) per modellare la sequenzialità delle interazioni. \cite{Hidasi2016}

\paragraph*{GRU4Rec} ~\\

La sessione utente viene trattata come una sequenza ordinata di item $S = [1_1, i_2, \dots, i_t]$. Il compito del sistema è predire l'item $i_{t+1}$ dato il contesto della sequenza precedente.

Al cuore dell'architettura vi sono le \textit{Gated Recurrent Units} (GRU). Vengono preferite rispetto alle classiche \textit{Long Short-Term Memory} (LSTM) poiché, a parità di capacità nel gestire il problema del \textit{vanishing gradient}, risultano computazionalmente più efficienti e richiedono un numero inferiore di parametri.

Si inizia con un \textbf{Input Layer} in cui lo stato corrente della sessione (l'ultimo item cliccato $i_t$) viene rappresentato tramite un vettore one-hot $\mathbf{x}_t$ (o tramite un livello di embedding appreso). Successivamente si passa ad una serie di \textbf{GRU Layer} nei quali il segnale passa attraverso uno o più strati GRU. Lo stato nascosto $\mathbf{h}_t$, che funge da memoria della sessione, viene aggiornato combinando l'input attuale con lo stato precedente:

 \begin{equation}
        \mathbf{h}_t = \text{GRU}(\mathbf{x}_t, \mathbf{h}_{t-1}) = (1 - \mathbf{z}_t) \odot \mathbf{h}_{t-1} + \mathbf{z}_t \odot \tilde{\mathbf{h}}_t
 \end{equation}

dove $\mathbf{z}_t$ è la porta di aggiornamento (\textit{update gate}) che decide quanto dell'informazione passata mantenere.

Infine avremo un \textbf{Output Layer} in cui l'output GRU viene proiettato nello spazio degli item. Si applica infine una funzione \textit{Softmax} per ottenere una distribuzione di probabilità $\hat{\mathbf{y}}_t$ su tutti i possibili item candidati per il passo $t+1$:

\begin{equation}
        \hat{\mathbf{y}}_t = \text{Softmax}(\mathbf{W}_{out} \cdot \mathbf{h}_t + \mathbf{b}_{out})
\end{equation}

\paragraph*{Session-Parallel Mini-Batches} ~\\

Le sessioni hanno lunghezze estremamente variabili; le tecniche standard (come il padding delle sequenze) risulterebbero inefficienti in questo contesto.
Il modello utilizza una tecnica chiamata \textit{Session-Parallel Mini Batches} dove le diverse sessioni vengono processate in parallelo su "corsie" distinte. Quando una sessione termina, viene rimpiazzata immediatamente dalla successiva disponibile nel dataset, resettando lo stato nascosto solo per quella specifica corsia, massimizzando così il throughput della GPU. \cite{Hidasi2016}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.8\textwidth]{session_parallel_mini_batches.png}
    \caption{Creazione della session-parallel mini batch. \\
    Immagine tratta da \cite{Hidasi2016}}
    \label{fig:session-parallel_mini_batch}
\end{figure}

\paragraph*{Ranking Loss} ~\\

L'obiettivo del modello non è stimare il valore esatto di un rating, ma ordinare correttamente gli item (\textit{Learning to Rank}). Le funzioni di loss classiche (es. Cross-Entropy) si sono rivelate sub-ottimali. GRU4Rec propone l'uso di funzioni di costo specifiche calcolate su campioni negativi:

\begin{itemize}
    \item \textbf{Bayesian Personalized Ranking (BPR)}: si tratta di una loss a coppie che penalizza il modello se lo score dell'item target positivo $\hat{r}_{si}$ non è superiore a quello di un item negativo $\hat{r}_{sj}$:
    \begin{equation}
        L_{BPR} = - \frac{1}{N_S} \sum_{j=1}^{N_S} \log(\sigma(\hat{r}_{si} - \hat{r}_{sj}))
    \end{equation}
    
    \item \textbf{TOP1 Loss}: è un'approssimazione regolarizzata del rango relativo dell'item corretto. A differenza di BPR, include un termine di regolarizzazione che spinge verso zero i punteggi degli item negativi (evitando che diventino infinitamente negativi senza migliorare il ranking):
    \begin{equation}
        L_{TOP1} = \frac{1}{N_S} \sum_{j=1}^{N_S} \sigma(\hat{r}_{sj} - \hat{r}_{si}) + \sigma(\hat{r}_{sj}^2)
    \end{equation}
    Il primo termine penalizza i casi in cui l'item negativo ha uno score superiore al positivo, mentre il secondo termine ($\sigma(\hat{r}_{sj}^2)$) agisce da regolarizzatore sugli score negativi.
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{gru_rs.png}
    \caption{Schema architetturale di GRU4Rec. \\
    Immagine tratta da \cite{Hidasi2016}}
    \label{fig:gru_rs}
\end{figure}

\subsubsection{Convolutional Matrix Factorization for Document Context-Aware Recommendation}

Un limite dei modelli di Collaborative Filtering, come NCF e AutoRec, è la drastica riduzione delle performance in condizioni di elevata sparsità o nel caso di nuovi item (\textit{Cold Start}). Mentre i modelli basati su MLP o RNN si concentrano sulla modellazione delle interazioni, le \textit{Reti Neurali Convoluzionali} (RNN) trovano la loro applicazione nell'estrazione di feature di dati ausiliari non strutturati (es. immagini o testo) per arricchire la rappresentazione degli item. \cite{Zhang2019}

Prima dell'avvento del Deep Learning, l'integrazione di testo avveniva tramite modelli \textit{Bag-of-Words} (BoW), che però ignorano l'ordine delle parole e il contesto semantico.
La \textit{Convolutional Matrix Factorization} (ConvMF), un modello ibrido che integra una CNN all'interno del framework della \textit{Probabilistic Matrix Factorization} (PMF), permette di catturare le sfumature contestuali dei documenti per generare rappresentazioni latenti più ricche. \cite{Kim2016}

\paragraph*{ConvMF} ~\\

Viene utilizzata la CNN non come un semplice estrattore di feature statico, ma come componente che influenza attivamente la generazione dei fattori latenti all'interno del modello probabilistico.

Nel classico PMF, i vettori latenti degli item $\mathbf{v}_j$ sono generati da una distribuzione Gaussiana con media zero:  $\mathbf{v}_j \sim \mathcal{N}(\mathbf{0}, \sigma_V^2 \mathbf{I})$.
In ConvMF, la media della distribuzione dell'item $j$ non è zero, bensì è determinata dall'output della CNN applicata al documento descrittivo $d_j$.

Dato il documento $d_j$ e i pesi della CNN $\mathbf{W}_{cnn}$, il vettore latente dell'item è modellato come:

\begin{equation}
    \mathbf{v}_j = \text{CNN}(\mathbf{W}_{cnn}, d_j) + \epsilon_j, \quad \epsilon_j \sim \mathcal{N}(\mathbf{0}, \sigma_V^2 \mathbf{I})
\end{equation}

Il profilo dell'item $\mathbf{v}_j$ è la somma delle caratteristiche semantiche estratte dal testo e di un termine di rumore Gaussiano $\epsilon_j$ che cattura le variazioni specifiche dei rating non spiegabili dal solo contenuto.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{convMF.png}
    \caption{Schema logico del modello ConvMF: PMF a sinistra, CNN a destra. \\
    Immagine tratta da \cite{Kim2016}}
    \label{fig:convMF}
\end{figure}

\paragraph*{Architettura della CNN} ~\\

La componente CNN è progettata per elaborare documenti di lunghezza variabile seguendo questi step:
\begin{enumerate}
    \item \textbf{Embedding Layer}: le parole del documento vengono trasformate in vettori densi (spesso pre-addestrati con word2vec), creando una matrice di rappresentazione.
    \item \textbf{Convolutional Layer}: diversi filtri (kernel) di varie dimensioni scorrono sulla matrice per catturare pattern locali (es. n-grammi significativi).
    \item \textbf{Max-Pooling}: viene estratta la feature più rilevante per ogni feature map, riducendo la dimensionalità e fornendo invarianza alla posizione.
    \item \textbf{Output Projection}: le feature aggregate vengono proiettate tramite uno strato denso per coincidere con la dimensione $k$ dello spazio latente della fattorizzazione.
\end{enumerate}

\paragraph*{Ottimizzazione e Funzione Obiettivo}

L'obiettivo è massimizzare la probabilità a posteriori dei vettori latenti di utenti $U$ e item $V$ e dei pesi della rete. La funzione di costo risultante combina l'errore quadratico sui rating osservati con un termine di regolarizzazione legato alla CNN:

\begin{equation}
    L = \sum_{(u,j) \in \mathcal{Y}} (R_{uj} - \mathbf{u}_u^T \mathbf{v}_j)^2 + \lambda_V \sum_{j=1}^{N} \|\mathbf{v}_j - \text{CNN}(\mathbf{W}_{cnn}, d_j)\|^2 + \lambda_{reg} \|\theta\|^2
\end{equation}

Il primo termine è la classica perdita di ricostruzione dei rating. Il secondo termine forza il vettore latente dell'item $\mathbf{v}_j$ a essere simile alla rappresentazione generata dal testo.
L'addestramento avviene alternando l'ottimizzazione dei parametri latenti, tramite \textit{Coordinate Descent}, e l'aggiornamento dei pesi della CNN, tramite \textit{Backpropagation}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{cnn_convMF.png}
    \caption{Schema architetturale della rete CNN per la convMF. \\
    Immagine tratta da \cite{Kim2016}}
    \label{fig:cnn_convMF}
\end{figure}

\subsubsection{Self-Attentive Sequential Recommendation (SASRec)}

Sebbene modelli come GRU4Rec abbiano dimostrato l'efficacia del Deep Learning per la raccomandazione sequenziale, le reti ricorrenti (RNN) presentano due limitazioni intrinseche: la difficoltà nel modellare dipendenze a lungo termine (nonostante l'uso di \textit{gating mechanisms}) e l'impossibilità di parallelizzare il calcolo, poiché ogni passo dipende dallo stato nascosto precedente.

L'introduzione del meccanismo di \textit{Self-Attention} \cite{Vaswani2017} con l'architettura Transformer per il \textit{Natural Language Processing} (NLP), ha segnato una svolta. \cite{Zhang2019} Questo meccanismo permette ai modelli di "pesare" selettivamente l'importanza degli item passati Indipendentemente dalla loro distanza temporale. \textit{SASRec} adatta questo paradigma ai sistemi di raccomandazione, combinando la capacità delle catene di Markov di modellare interazioni recenti con la capacità delle RNN di catturare pattern a lungo termine, ma superando entrambe in efficienza grazie alla parallelizzazione. \cite{Kang2018}

\paragraph*{Embedding e Positional Encoding} ~\\

A differenza delle RNN, il meccanismo di attenzione è invariante all'ordine: elabora l'intera sequenza simultaneamente. Per preservare l'informazione sulla sequenzialità degli acquisti, SASRec somma all'embedding dell'item un embedding posizionale apprendibile.

Data una sequenza di input $S = (s_1, s_2, \dots, s_n)$, la rappresentazione iniziale $\hat{\mathbf{E}} \in \mathbb{R}^{n \times d}$ è data da:

\begin{equation}
    \hat{\mathbf{E}} = \mathbf{E}_{item} + \mathbf{P}_{pos}
\end{equation}

dove $\mathbf{E}_{item}$ contiene i vettori latenti degli oggetti e $\mathbf{P}_{pos}$ codifica la posizione assoluta dell'item nella sequenza.

\paragraph*{Self-Attention Block} ~\\

Il cuore del modello è il blocco di \textit{Self-Attention}, che permette a ogni item nella sequenza di "attendere" (prestare attenzione) a tutti gli altri item precedenti per calcolare la sua nuova rappresentazione.
Il meccanismo utilizzato è il \textit{Scaled Dot-Product Attention}. \cite{Vaswani2017} Date le proiezioni lineari per le Query $\mathbf{Q}$, le Key $\mathbf{K}$ e i Value $\mathbf{V}$ a partire dall'input $\hat{\mathbf{E}}$:

\begin{equation}
    \text{Attention}(\mathbf{Q}, \mathbf{K}, \mathbf{V}) = \text{softmax}\left(\frac{\mathbf{Q}\mathbf{K}^T}{\sqrt{d}}\right)\mathbf{V}
\end{equation}

Il termine $\frac{\mathbf{Q}\mathbf{K}^T}{\sqrt{d}}$ calcola la similarità tra tutti gli elementi della sequenza.

È fondamentale notare che, essendo un problema sequenziale, il modello non può "vedere il futuro". Viene applicata una maschera causale (\textit{causality mask}) che modifica la matrice di attenzione impostando a $-\infty$ i valori corrispondenti alle connessioni $j > i$ (item futuri), garantendo che la predizione al tempo $t$ dipenda solo dagli item $1 \dots t$.

\paragraph*{Point-Wise Feed-Forward e Stacking} ~\\

Per introdurre non-linearità e interazioni più profonde tra le dimensioni latenti, l'output dell'attenzione passa attraverso una \textit{rete Feed-Forward} (FNN) applicata indipendentemente a ogni posizione (\textit{Point-Wise FNN}), composta da due trasformazioni lineari con attivazione ReLU nel mezzo.
SASRec impila $b$ di questi blocchi (Attention + FFN), utilizzando la normalizzazione dei layer (\textit{LayerNorm}) tipiche dei Transformer:

\begin{equation}
    \mathbf{F}_l = \text{LayerNorm}(\mathbf{F}_{l-1} + \text{SelfAttention}(\mathbf{F}_{l-1}))
\end{equation}

\paragraph*{Predizione e Funzione Obiettivo} ~\\

Dopo $b$ blocchi, l'output $\mathbf{F}_b$ al passo $t$ aggrega l'informazione dell'intera cronologia rilevante. La rilevanza (score) dell'item $i$ come candidato successivo è calcolato tramite il prodotto scalare tra la rappresentazione contestuale e l'embedding dell'item:

\begin{equation}
    r_{i,t} = \mathbf{F}_b^{(t)} \cdot \mathbf{N}_i^T
\end{equation}

dove $\mathbf{N}$ è la matrice degli embedding degli item (spesso condivisa con quella di input per ridurre i parametri).
Il modello viene addestrato minimizzando la **Binary Cross-Entropy**, trattando l'item successivo reale come campione positivo e campionando un item negativo casuale per ogni passo temporale.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{sasRec_rs.png}
    \caption{Schema logico del modello SASRec. \\
    Immagine tratta da \cite{Kang2018}}
    \label{fig:sasRec_rs}
\end{figure}

\subsubsection{Generative Adversarial Networks based Recommendation}

La maggior parte dei modelli di raccomandazione visti finora sono di natura \textit{discriminativa}, ovvero cercano di classificare se un utente apprezzerà un item o predirne il rating.

L'emergere dei modelli \textit{generativi}, in particolare delle \textit{Generative Adversarial Networks} (GAN), hanno portato ad un nuovo paradigma, basato sulla Teoria dei Giochi, dove vengono addestrate due reti neurali in competizione tra loro in un gioco a somma zero. \cite{Zhang2019} Il lavoro seminale che ha adottato questo approccio all'\textit{Information Retrieval} e ai RS è \textit{IRGAN}. \cite{Wang2017}

\paragraph*{IRGAN} ~\\

IRGAN definisce due agenti antagonisti:

\begin{itemize}
    \item \textbf{Modello Generativo (Generator $G$)}: il suo obiettivo è apprendere la distribuzione di probabilità sottostante delle preferenze dell'utente $p_{true}(d|u)$ per generare (raccomandare) item $d$ che siano indistinguibili da quelli realmente rilevanti. Cerca di "ingannare" il discriminatore proponendo item plausibili.
    \item \textbf{Modello Discriminativo (Discriminator $D$)}: il suo obiettivo è distinguere tra gli item veramente rilevanti (interazioni reali osservate nel training set) e quelli generati (campionati) dal Generatore.
\end{itemize}

Il training avviene attraverso un gioco \textit{Min-Max}, dove si cerca di minimizzare la funzione obiettivo rispetto el Generatore e massimizzarla rispetto al Discriminatore. La funzione obiettivo è:

\begin{equation}
    J = \min_{\theta_G} \max_{\phi_D} \sum_{n=1}^{N} \left( \mathbb{E}_{d \sim p_{true}} [\log D(d|u)] + \mathbb{E}_{d \sim p_{\theta_G}} [\log (1 - D(d|u))] \right)
\end{equation}

\paragraph*{Ottimizzazione su Dati Discreti} ~\\

A differenza delle immagini (dati continui), gli item in un sistema di raccomandazione sono discreti. Questo impedisce l'uso della backpropagation standard per aggiornare il Generatore, poiché l'operazione di selezione di un item (campionamento) non è differenziabile.
Per superare questo ostacolo si utilizzano tecniche di \textit{Reinforcement Learning}, specificamente un approccio basato su Policy Gradient. \cite{Wang2017} Il Generatore agisce come un agente che intraprende un'azione (selezionare un item) e riceve come ricompensa (\textit{reward}) il giudizio del Discriminatore.

Questo approccio permette a IRGAN di superare i limiti dei metodi statici di \textit{Negative Sampling}, poiché il Generatore impara a creare esempi negativi sempre più "difficili" e realistici, costringendo il Discriminatore, quindi il sistema di raccomandazione finale, a diventare più accurato e robusto.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{irgan_rs.png}
    \caption{Schema logico del training del modello IRGAN. \\
    Immagine tratta da \cite{Wang2017}}
    \label{fig:irgan_rs}
\end{figure}

\subsubsection{Deep Reinforcement Learning based Recommendation}

La maggior parte dei modelli analizzati finora (NCF, GRU4Rec) sono intrinsecamente "miopi" o \textit{greedy}: sono addestrati per massimizzare la probabilità di un'interazione immediata (es. il prossimo click) basandosi su dati storici statici.
Tuttavia, il processo di raccomandazione è, per natura, un'interazione sequenziale e dinamica tra il sistema e l'utente, dove l'azione corrente influenza lo stato futuro delle preferenze. \cite{Zhang2019}

Per modellare questa dinamica, la ricerca si è orientata verso il \textit{Deep Reinforcement Learning} (DRL). In questo paradigma, il sistema di raccomandazione non è più un semplice classificatore, ma un \textit{Agente} che interagisce con un'\textit{Ambiente} cercando di massimizzare una ricompensa cumulativa nel tempo (es. la durata totale della sessione o la fidelizzazione a lungo termine).

\paragraph*{MDP} ~\\

Il problema viene formalizzato come un \textit{Markov Decision Process} (MDP).
Le componenti principali del \textit{Deep Reinforcement Learning based Recommendation} (DRN) sono: \cite{Zheng2018}

\begin{itemize}
    \item \textbf{Stato ($S_t$)}: rappresenta il contesto corrente e la storia dell'utente al tempo $t$. Include le feature dell'utente, le feature del contesto (es. ora del giorno) e gli ultimi item consumati.
    \item \textbf{Azione ($A_t$)}: corrisponde all'item (o alla lista di item) che l'agente sceglie di raccomandare tra quelli disponibili.
    \item \textbf{Reward ($R_t$)}: è il feedback ricevuto dall'ambiente dopo l'azione. In DRN, il reward non è solo binario (click/no-click), ma include metriche di engagement come il tempo di lettura attivo, per evitare il fenomeno del \textit{click-bait}.
    \item \textbf{Transizione ($P$)}: la probabilità che lo stato dell'utente cambi da $S_t$ a $S_{t+1}$ dopo aver raccomandato l'item $A_t$.
\end{itemize}

\paragraph*{Q-Learning e Deep Q-Network} ~\\

L'obiettivo dell'agente è apprendere una \textit{Policy} ottimale $\pi(S_t)$ che scelga l'azione migliore. DRN utilizza un approccio basato su \textit{Deep Q-Network} (DQN), l'algoritmo combina il reinforcement learning (RL) con le reti neurali profonde. \cite{Mnih2015} La rete stima la funzione $Q(S_t, A_t)$, che rappresenta il valore atteso della ricompensa futura (\textit{discounted cumulative reward}) scegliendo l'azione $A_t$ nello stato $S_t$:

\begin{equation}
    Q(S_t, A_t) = \mathbb{E} \left[ \sum_{k=0}^{\infty} \gamma^k R_{t+k+1} \mid S_t, A_t \right]
\end{equation}

dove $\gamma$ è il fattore di sconto. L'addestramento avviene minimizzando l'errore quadratico medio basato sull'equazione di Bellman:

\begin{equation}
    L = \mathbb{E} \left[ (R_{t+1} + \gamma \max_{a'} Q(S_{t+1}, a'; \theta^-) - Q(S_t, A_t; \theta))^2 \right]
\end{equation}

Per una trattazione teorica approfondita dell'algoritmo DQN generico e delle sue componenti architetturali (Experience Replay e Target Network), si rimanda alla sezione \ref{subsec:dqn}.

\paragraph*{Exploration vs Exploitation} ~\\

Uno dei vantaggi del DRL rispetto ai metodi tradizionali è la gestione attiva del trade-off tra \textit{Exploitation} (raccomandare ciò che si sa piacere all'utente) ed \textit{Exploration} (raccomandare item nuovi o incerti per acquisire informazioni).
DRN implementa una strategia di esplorazione (es. Dueling Bandit Gradient Descent) che perturba leggermente i parametri della rete per esplorare nuove aree dello spazio degli item, permettendo al modello di adattarsi dinamicamente ai cambiamenti nei gusti dell'utente (\textit{Concept Drift}) in tempo reale.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{drn_rs.png}
    \caption{Schema dell'interazione Agente-Ambiente nel modello DRN. \\
    Immagine tratta da \cite{Zheng2018}}
    \label{fig:drn_rs}
\end{figure}

\subsection{Modelli di raccomandazione basati sui grafi}
\label{subsec:modelli-gnn}

Un limite intrinseco dei modelli di Collaborative Filtering basati su Deep Learning analizzati nelle sezioni precedenti è che trattano le interazioni utente-item come istanze indipendenti (i.i.d.). Tuttavia, i dati reali possiedono una struttura relazionale complessa che può essere modellata più naturalmente tramite grafi.

I sistemi di raccomandazione basati sui \textit{Graph Neural Networks} (GNN) sfruttano la capacità di propagare informazioni tra nodi connessi (\textit{Message Passing}) per catturare dipendenze. Questi sistemi possono essere suddivisi in quattro macro-categorie, a seconda della struttura dati utilizzata \cite{Wu2022}:

\begin{itemize}
    \item \textbf{General Recommendation}: basata sul grafo bipartito utente-item.
    \item \textbf{Sequential Recommendation}: Basata su grafi di sessione o transizione temporale.
    \item \textbf{Social Recommendation}: basata sull'integrazione del grafo sociale tra utenti.
    \item \textbf{Knowledge Graph-based Recommendation}: basata su grafi di conoscenza eterogenei (entità e relazioni).
\end{itemize}

\subsubsection{General Recommendation}

I dati sono rappresentati come un grafo bipartito $\mathcal{G} = (\mathcal{U} \cup \mathcal{I}, \mathcal{E})$, dove gli utenti e gli item sono nodi e le interazioni sono archi. L'obiettivo è apprendere rappresentazioni di nodi che incorporino la struttura locale per predire i link mancanti.

\paragraph*{Graph Convolutional Matrix Completion (GC-MC)} ~\\

GC-MC formula il completamento della  matrice di rating come un problema di link prediction. Il modello utilizza un autoencoder a convoluzione su grafo: l'encoder aggrega le feature dei vicini immediati per generare embedding latenti, mentre il decoder ricostruisce i rating. Una particolarità è che tratta ogni possibile valore di rating (es. 1-5 stelle) come un tipo di arco distinto, apprendendo pesi specifici per ogni classe di voto. \cite{Berg2017}

\begin{figure}[b]
    \centering
    \includegraphics[width=0.8\textwidth]{gc-mc_rs.png}
    \caption{Schema logico del modello GC-MC. \\
    Immagine tratta da \cite{Berg2017}}
    \label{fig:gc-mc_rs}
\end{figure}

\paragraph*{PinSage} ~\\

PinSage rappresenta una pietra miliare per la scalabilità industriale. Sviluppato da Pinterest, affronta il problema dell'enorme dimensione dei grafi reali (miliardi di nodi) dove le GCN standard (che richiedono l'intera matrice Laplaciana) falliscono.
PinSage introduce una strategia di campionamento basata su \textit{Random Walk}: invece di aggregare informazioni da tutti i vicini, il modello campiona un intorno di nodi visitati da passeggiate casuali e applica convoluzioni localizzate. Questo permette di gestire grafi su web-scale in modo efficiente. \cite{Ying2018}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.8\textwidth]{pinSage_rs.png}
    \caption{Schema architetturale del modello PinSage. \\
    Immagine tratta da \cite{Ying2018}}
    \label{fig:pinSage_rs}
\end{figure}

\paragraph*{Neural Graph Collaborative Filtering (NGCF)} ~ \\
NGCF è stato il primo modello a integrare esplicitamente la struttura grafo nel processo di embedding. L'idea chiave è raffinare la rappresentazione dell'utente aggregando ricorsivamente i messaggi dai vicini. \cite{Wang2019}

Al livello $l$, l'embedding dell'utente $u$ viene aggiornato aggregando i messaggi dai vicini $\mathcal{N}_u$:

\begin{equation}
    \mathbf{e}_u^{(l+1)} = \sigma \left( \mathbf{W}_1 \mathbf{e}_u^{(l)} + \sum_{i \in \mathcal{N}_u} \frac{1}{\sqrt{|\mathcal{N}_u| |\mathcal{N}_i|}} \left( \mathbf{W}_1 \mathbf{e}_i^{(l)} + \mathbf{W}_2 (\mathbf{e}_i^{(l)} \odot \mathbf{e}_u^{(l)}) \right) \right)
\end{equation}

NGCF definisce il messaggio propagato includendo non solo la somma delle feature, ma anche le interazioni tra feature (prodotto element-wise $\odot$). Introduce inoltre matrici di pesi apprendibili ($\mathbf{W}_1, \mathbf{W}_2$) e funzioni di attivazione non lineari ($\sigma$) a ogni strato. Sebbene potente, questa complessità rende il modello computazionalmente oneroso.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{ngcf_rs.png}
    \caption{Schema architetturale del modello Neural Graph Collaborative Filtering. \\
    Immagine tratta da \cite{Wang2019}}
    \label{fig:ngcf_rs}
\end{figure}

\paragraph*{LightGCN} ~\\
Le componenti di non-linearità e le trasformazioni di feature delle GCN sono utili per compiti di classificazione di nodi ma superflue e dannose per il Collaborative Filtering.
Nasce così \textit{LightGCN} che semplifica drasticamente l'architettura mantenendo solo la \textit{propagazione lineare dei vicini}. \cite{He2020}

L'aggiornamento al layer $k+1$ è una somma pesata normalizzata:

\begin{equation}
    \mathbf{e}_u^{(k+1)} = \sum_{i \in \mathcal{N}_u} \frac{1}{\sqrt{|\mathcal{N}_u| |\mathcal{N}_i|}} \mathbf{e}_i^{(k)}
\end{equation}

L'embedding finale utilizzato per la predizione (prodotto scalare) è la somma pesata degli embedding ottenuti a tutti i livelli $K$, permettendo di catturare sia le similarità dirette (layer bassi) che quelle a lungo raggio (layer alti):

\begin{equation}
    \mathbf{e}_u^* = \sum_{k=0}^K \alpha_k \mathbf{e}_u^{(k)}
\end{equation}

Grazie alla sua efficienza e robustezza, LightGCN è considerato l'attuale \textit{state-of-the-art} per le GNN supervisionate ed è la base su cui sono costruiti i modelli contrastivi più recenti.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.8\textwidth]{lightGCN_rs.png}
    \caption{Schema architetturale del modello LightGCN. \\
    Immagine tratta da \cite{He2020}}
    \label{fig:lightGCN_rs}
\end{figure}

\subsubsection{Sequential Recommendation}

Qui l'ordine temporale è cruciale. I dati vengono modellati come un grafo diretto dove i nodi sono gli item e gli archi rappresentano le transizioni consecutive in una sessione.

\paragraph*{Session-based Recommendation with GNN (SR-GNN)} ~\\

A differenza delle RNN che modellano solo sequenze unidirezionali, SR-GNN costruisce un grafo per ogni sessione e utilizza GNN con meccanismi di \textit{Gated Update} per catturare transizioni complesse tra item. Infine, combina un'attenzione sull'ultimo item cliccato (interesse locale) con una rappresentazione globale della sessione per predire il prossimo click. \cite{Wu2019_SRGNN}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.8\textwidth]{sr-gnn_rs.png}
    \caption{Schema architetturale del modello SR-GNN. \\
    Immagine tratta da \cite{Wu2019_SRGNN}}
    \label{fig:sr-gnn_rs}
\end{figure}

\subsubsection{Social Recommendation}

Questa categoria integra il grafo delle interazioni con il \textit{Social Graph} (le amicizie tra utenti) per mitigare la sparsità dei dati, basandosi sulla teoria dell'omofilia.

\paragraph*{GraphRec} ~\\

GraphRec aggrega separatamente le informazioni dall'item-space (storia dell'utente) e dal social-space (opinioni degli amici). Si utilizzano meccanismi di attenzione a livello di nodo per pesare l'influenza dei diversi amici, riconoscendo che non tutti i legami sociali sono ugualmente rilevanti per ogni dominio di prodotto. \cite{Fan2019}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{graphRec_rs.png}
    \caption{Schema architetturale del modello GraphRec. \\
    Immagine tratta da \cite{Fan2019}}
    \label{fig:graphRec_rs}
\end{figure}

\paragraph*{DiffNet} ~\\

DiffNet simula la diffusione ricorsiva dell'influenza sociale. L'embedding di un utente evolve iterativamente, venendo influenzato dalla combinazione lineare dei suoi vicini nel grafo sociale. Questo permette di modellare come le preferenze si propagano attraverso la rete di amicizie nel tempo. \cite{Wu2019_DiffNet}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{diffNet_rs.png}
    \caption{Schema architetturale del modello DiffNet. \\
    Immagine tratta da \cite{Wu2019_DiffNet}}
    \label{fig:diffNet_rs}
\end{figure}

\subsubsection{Knowledge Graph-based Recommendation}

Questi modelli arricchiscono le interazioni con informazioni esterne strutturate in un grafo eterogeneo \textit{Knowledge Graph} (KG), dove i nodi sono entità (es. Attori, Registi) e gli archi sono relazioni semantiche.

\paragraph*{Knowledge Graph Attention Network (KGAT)} ~\\

KGAT integra il KG direttamente nel processo di embedding tramite una GNN. Utilizza un meccanismo di \textit{Attention} relazionale per discriminare l'importanza dei vicini nel KG: ad esempio, per raccomandare un film, il modello impara autonomamente se pesare di più la relazione "diretto da" o "appartiene al genere", propagando le preferenze attraverso path semantici di alto ordine. \cite{Wang2019_KGAT}

\begin{figure}[b]
    \centering
    \includegraphics[width=0.8\textwidth]{kgat_rs.png}
    \caption{Schema architetturale del modello KGAT. \\
    Immagine tratta da \cite{Wang2019_KGAT}}
    \label{fig:kgat_rs}
\end{figure}

\subsection{Modelli di raccomandazione basati su Self-Supervised Learning}
\label{subsec:modelli-ssl}

Le GNN soffrono di limitazioni intrinseche quando i dati sono sparsi (\textit{data sparsity}) o affetti da rumore (interazioni non intenzionali). Inoltre, l'apprendimento supervisionato classico basato solo sulla loss BPR tende a causare una distribuzione non uniforme degli embedding nello spazio latente ("representation collapse").

Il \textit{Self-Supervised Learning} (SSL) permette di apprendere rappresentazioni migliori estraendo segnali di supervisione direttamente dai dati stessi, senza etichette umane. \cite{Yu2024}

Gli approcci \textit{Self Supervised Learning} vengono classificati in quattro macro-categorie principali:

\begin{enumerate}
    \item \textbf{Generative SSL}: ispirato al Natural Language Processing (es. BERT), maschera parte dei dati e addestra il modello a ricostruirli.
    \item \textbf{Contrastive SSL}: massimizza la similarità tra diverse viste aumentate dello stesso nodo e la minimizza rispetto ad altri nodi.
    \item \textbf{Predictive SSL}: utilizza i dati per generare pseudo-etichette e risolve compiti di classificazione ausiliari.
    \item \textbf{Hybrid SSL}: combina più paradigmi per sfruttarne i vantaggi complementari.
\end{enumerate}

\subsubsection{Generative SSL}

I metodi generativi seguono il principio del \textit{Mask-and-Reconstruct}. L'idea è corrompere o nascondere una parte dell'input originale (nodi, archi o feature) e forzare il modello a ricostruire l'informazione mancante sfruttando il contesto rimanente.

\paragraph*{Sequential Masking} ~\\

Nei sistemi sequenziali, l'obiettivo è ricostruire item mancanti nella storia dell'utente per apprendere dipendenze più profonde.

\subparagraph*{BERT4Rec} ~\\

Ispirato al modello BERT \cite{Devlin2019} per il NLP, BERT4Rec rappresenta un punto di svolta nella raccomandazione sequenziale. A differenza dei modelli causali "Left-to-Right" (come SASRec o GRU4Rec) che possono utilizzare solo le informazioni passate per predire il futuro, BERT4Rec adotta un approccio \textit{bidirezionale}.
Durante il training, viene applicato il \textit{Cloze objective}: una percentuale degli item nella sequenza storica dell'utente viene sostituita da un token speciale \texttt{[MASK]}. Il modello, basato su Transformer, deve predire l'ID dell'item originale utilizzando il contesto proveniente sia da sinistra (passato) che da destra (futuro). Questo permette di apprendere rappresentazioni degli item molto più robuste e contestualizzate, catturando relazioni complesse all'interno della sessione utente. \cite{Sun2019}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{bert4Rec_rs.png}
    \caption{Schema architetturale del modello BERT4Rec. \\
    Immagine tratta da \cite{Sun2019}}
    \label{fig:bert4Rec_rs}
\end{figure}

\paragraph*{Graph Masking} ~\\
Nei sistemi basati su grafi, la ricostruzione può avvenire a livello di struttura o di attributi dei nodi.

\subparagraph*{GraphMAE} ~\\

GraphMAE è un modello generativo per grafi che si concentra sulla ricostruzione delle feature. A differenza degli approcci che ricostruiscono la struttura (link prediction), che spesso soffrono di overfitting, GraphMAE maschera una porzione delle feature dei nodi e utilizza un encoder GNN per mappare il grafo parziale in uno spazio latente. Un decoder successivo tenta di ricostruire le feature originali dei nodi mascherati.
Un aspetto cruciale di GraphMAE è l'uso della funzione di perdita \textit{Scaled Cosine Error} al posto del classico MSE (Mean Squared Error). L'errore coseno scalato si è dimostrato molto più efficace nel gestire la dimensionalità delle feature nei grafi sparsi, costringendo la rete ad apprendere pattern strutturali robusti e trasferibili. \cite{Hou2022}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{graphMAE_rs.png}
    \caption{Schema architetturale del modello GraphMAE. \\
    Immagine tratta da \cite{Hou2022}}
    \label{fig:graphMAE_rs}
\end{figure}

\subsubsection{Contrastive SSL}

L'obiettivo è apprendere rappresentazioni invarianti massimizzando la \textit{Mutual Information} tra diverse "viste" (\textit{views}) generate tramite Data Augmentation. La funzione di costo tipica è la \textit{InfoNCE}:

\begin{equation}
    \mathcal{L}_{ssl} = \sum_{u \in \mathcal{U}} -\log \frac{\exp(\text{sim}(\mathbf{z}_u', \mathbf{z}_u'') / \tau)}{\sum_{v \in \mathcal{U}} \exp(\text{sim}(\mathbf{z}_u', \mathbf{z}_v'') / \tau)}
\end{equation}

dove $\mathbf{z}_u', \mathbf{z}_u''$ sono le rappresentazioni aumentate dello stesso nodo (coppia positiva), $\tau$ è la temperatura che regola la durezza dei negativi, e il denominatore somma su tutti gli altri nodi (coppie negative).

\paragraph*{Structure-level Augmentation}~ \\

Questo approccio genera viste diverse modificando esplicitamente la topologia del grafo (matrice di adiacenza).

\subparagraph*{Self-Supervised Graph Learning (SGL)} ~\\

SGL integra il contrastive learning in LightGCN. Per ogni epoca, vengono generate due viste del grafo $\mathcal{G}_1, \mathcal{G}_2$ applicando operatori stocastici:
\begin{itemize}
    \item \textit{Node Dropout}: rimozione casuale di nodi con probabilità $\rho$.
    \item \textit{Edge Dropout}: rimozione casuale di archi.
    \item \textit{Random Walk}: Utilizzo di percorsi di propagazione differenti tra i layer.
\end{itemize}

SGL impone che la rappresentazione di un nodo rimanga coerente anche se la struttura locale viene alterata. Sebbene efficace, la necessità di rigenerare la matrice di adiacenza sparsa a ogni iterazione introduce un overhead computazionale significativo. \cite{Wu2021}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.8\textwidth]{sgl_rs.png}
    \caption{Schema logico del modello SGL. \\
    Immagine tratta da \cite{Wu2021}}
    \label{fig:sgl_rs}
\end{figure}

\paragraph*{Feature-level Augmentation} ~\\

Questo approccio mantiene la struttura inalterata ma perturba lo spazio latente per migliorare l'uniformità degli embedding.

\subparagraph*{Simple Graph Contrastive Learning (SimGCL)} ~\\

Le complesse manipolazioni topologiche di SGL non sono strettamente necessarie. SimGCL semplifica il processo rimuovendo l'augmentation del grafo e applicando invece un rumore casuale uniforme direttamente agli embedding:

\begin{equation}
    \mathbf{e}_u' = \mathbf{e}_u + \Delta, \quad \Delta \sim U(-\epsilon, \epsilon)
\end{equation}

Questa perturbazione agisce come una data augmentation nello spazio delle feature. Geometricamente, SimGCL favorisce l'\textit{uniformità} della distribuzione degli embedding sulla ipersfera latente, prevenendo il problema del "dimensional collapse" e rendendo le rappresentazioni più discriminative, il tutto con un'efficienza computazionale superiore a SGL. \cite{Yu2022}
 
\subparagraph*{Cross-Layer SimGCL (XSimGCL)} ~\\

Una variante evolutiva di SimGCL è XSimGCL, che estende il concetto di SimGCL applicando il contrasto in modalità \textit{Cross-Layer}. Invece di contrastare l'embedding finale di una vista con l'embedding finale dell'altra, XSimGCL incrocia gli embedding ottenuti ai diversi strati intermedi della GNN (es. layer $l$ contro layer $L$). Questo meccanismo forza il modello a mantenere una coerenza semantica attraverso la profondità della rete, facilitando la propagazione del gradiente verso i layer iniziali e catturando feature a diversi livelli di astrazione (locale vs globale). \cite{Yu2022}

\paragraph*{Semantic-level Augmentation} ~\\

Questo approccio cerca correlazioni semantiche non esplicite nella topologia del grafo (es. utenti simili che non hanno interagito con gli stessi item).

\subparagraph*{Neighborhood-enriched Contrastive Learning (NCL)} ~\\

NCL critica i metodi precedenti perché contrastano un nodo solo con se stesso (augmentation), ignorando le relazioni semantiche tra nodi diversi. NCL introduce un contrasto basato su \textit{prototipi} utilizzando l'algoritmo \textit{Expectation-Maximization} (EM):

\begin{itemize}
    \item \textbf{E-Step}: i nodi vengono raggruppati in cluster latenti tramite K-Means.
    \item \textbf{M-Step}: ogni nodo viene contrastato positivamente con il centroide del suo cluster (\textit{prototipo semantico}) e con i suoi vicini strutturali omogenei (vicini di vicini).
\end{itemize}

Questo permette di catturare strutture globali latenti: due utenti che appartengono allo stesso cluster semantico verranno avvicinati nello spazio degli embedding anche se non hanno interazioni comuni nel grafo bipartito. \cite{Lin2022}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{ncl_rs.png}
    \caption{Schema logico del modello NCL. \\
    Immagine tratta da \cite{Lin2022}}
    \label{fig:ncl_rs}
\end{figure}

\subsubsection{Predictive SSL}

In questo paradigma, il segnale di supervisione non deriva dalla ricostruzione (Generative) o dal confronto (Contrastive), ma dalla generazione di pseudo-etichette (\textit{Pseudo-Labeling}) per densificare i dati.

\paragraph*{Self-CF} ~\\

Self-CF affronta il problema della sparsità senza utilizzare l'augmentation di dati (che può essere computazionalmente costosa).
Il funzionamento si basa sul principio del \textit{Self-Training}: l'encoder del sistema di raccomandazione genera le predizioni per le coppie utente-item non osservate. Le coppie che ottengono uno score di confidenza molto alto vengono promosse a "esempi positivi" (pseudo-labels).
La loss function minimizza la distanza tra l'output del modello e queste pseudo-etichette, permettendo di estrarre informazioni dai dati non etichettati e di regolarizzare lo spazio latente spingendo gli embedding verso strutture più discriminative. \cite{Zhou2023}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.8\textwidth]{self-CF_rs.png}
    \caption{Schema logico del modello Self-CF. \\
    Immagine tratta da \cite{Zhou2023}}
    \label{fig:self-CF_rs}
\end{figure}

\subsubsection{Hybrid SSL}

I metodi ibridi combinano due o più paradigmi SSL per sfruttarne i vantaggi sinergici. La combinazione più diffusa è quella tra \textit{Contrastive Learning} (per l'allineamento delle feature) e \textit{Predictive Learning} (per l'espansione dei dati).

\paragraph*{SEPT (Self-Supervised Evolution on Graph)} ~\\

SEPT propone un apprendimento ibrido basato sulla teoria del \textit{Tri-Training} (una tecnica di apprendimento semi-supervisionato).
L'architettura utilizza tre viste diverse del grafo (generate tramite augmentation) processate da tre encoder GNN distinti. Il training avviene in due modalità congiunte:

\begin{enumerate}
    \item \textbf{Predictive (Label Propagation)}: se due encoder concordano con alta confidenza su una predizione per un item non osservato, questa viene usata come pseudo-etichetta per addestrare il terzo encoder.
    \item \textbf{Contrastive}: viene applicata una loss contrastiva tra le rappresentazioni generate dai tre encoder per garantire consistenza e robustezza.
\end{enumerate}

Questo approccio permette di migliorare drasticamente le performance in scenari con pochissime interazioni (estrema sparsità). \cite{Yu2021}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.8\textwidth]{sept_rs.png}
    \caption{Schema architetturale del modello SEPT. \\
    Immagine tratta da \cite{Yu2021}}
    \label{fig:sept_rs}
\end{figure}

\subsection{Modelli di raccomandazione basati su Large Language Models}
\label{subsec:modelli-llm}

L'avvento dei \textit{Large Language Models} (LLM) come BERT \cite{Devlin2019}, GPT \cite{Brown2020}, e LLaMA \cite{Touvron2023} ha rivoluzionato il campo dell'Intelligenza Artificiale. Mentre i sistemi di raccomandazione tradizionali si basano su ID univoci per rappresentare utenti e item, soffrendo del problema del \textit{Cold Start} e mancando di capacità di ragionamento semantico, gli LLM possiedono una vasta conoscenza del mondo (\textit{World Knowledge}) e capacità di generalizzazione \textit{zero-shot}.

Gi LLM nei sistemi di raccomandazione possono essere classificati in due paradigmi fondamentali, a seconda del ruolo svolto dal modello linguistico \cite{Zhao2024, Lin2025}:

\begin{enumerate}
    \item \textbf{LLM as Encoder (Discriminative)}: l'LLM viene utilizzato come feature extractor per generare embedding semantici di alta qualità, che vengono poi processati da un modello di raccomandazione tradizionale.
    \item \textbf{LLM as Recommender (Generative)}: l'LLM funge direttamente da decisore. Il compito di ranking viene riformulato come un problema di generazione di linguaggio naturale (NLG), dove il modello deve generare il titolo dell'item raccomandato.
\end{enumerate}

\subsubsection{Discriminative LLM-based Recommendation}

In questo approccio, la potenza degli LLM (spesso modelli tipo BERT) viene sfruttata per comprendere il contenuto testuale degli item (titoli, descrizioni) e trasformarlo in vettori densi. Questo permette di trasferire conoscenza tra domini diversi e gestire item nuovi.

\paragraph*{Universal Sequence Representation (UniSRec)} ~\\

Un limite dei modelli sequenziali classici (come SASRec) è che gli embedding degli item sono legati agli ID specifici di un dataset e non sono trasferibili. UniSRec propone di utilizzare il testo descrittivo dell'item come input universale.
Il modello utilizza un encoder basato su BERT per generare rappresentazioni degli item basate sul testo. Successivamente, utilizza un meccanismo di attenzione per modellare la sequenza di interazioni in uno spazio semantico universale. Questo permette al modello di effettuare raccomandazioni \textit{Cross-Domain} e \textit{Inductive}, funzionando anche su dataset diversi da quello di training. \cite{Hou2022_UniSRec}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{uniSRec_rs.png}
    \caption{Schema architetturale del modello UniSRec. \\
    Immagine tratta da \cite{Hou2022_UniSRec}}
    \label{fig:uniSRec_rs}
\end{figure}

\subsubsection{Generative LLM-based Recommendation}

In questo approccio, il sistema di raccomandazione viene unificato con i task di NLP. L'input è un \textit{Prompt} in linguaggio naturale e l'output è una sequenza di testo generata.

\paragraph*{Pre-train, Personalized Prompt, Predict Paradigm (P5)} ~\\

P5 è stato uno dei primi a unificare diversi task di raccomandazione (Sequential Recommendation, Rating Prediction, Explanation) in un unico framework \textit{sequence-to-sequence}.
Tutti i dati (utenti, item, interazioni) vengono convertiti in stringhe di testo tramite template di prompt personalizzati (es. "Dato lo storico dell'utente X, predici il prossimo acquisto"). Il modello, basato su T5, viene pre-addestrato su questi prompt, imparando a svolgere raccomandazioni come se fosse un compito di traduzione o riassunto. \cite{Geng2022}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.8\textwidth]{p5_rs.png}
    \caption{Schema architetturale del modello P5. \\
    Immagine tratta da \cite{Geng2022}}
    \label{fig:p5_rs}
\end{figure}

\paragraph*{TALLRec (Instruction Tuning)} ~\\

Mentre P5 si basa sul pre-training, TALLRec si concentra sull'\textit{Instruction Tuning} di LLM generalisti (come LLaMA). Gli LLM "vanilla" faticano a seguire istruzioni di raccomandazione specifiche (es. ordinare una lista) senza un fine-tuning mirato.
TALLRec costruisce un dataset di istruzioni specifiche per la raccomandazione (con esempi positivi e negativi) ed effettua il fine-tuning l'LLM in modo efficiente (utilizzando LoRA \cite{Hu2022}) per allineare le capacità del modello al task di ranking, ottenendo prestazioni superiori in scenari \textit{Few-Shot}. \cite{Bao2023}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{tallRec_rs.png}
    \caption{Schema logico del modello TALLRec. \\
    Immagine tratta da \cite{Bao2023}}
    \label{fig:tallRec_rs}
\end{figure}

\subsection{Modelli di raccomandazione basati su State Space Models}
\label{subsec:modelli-ssm}

Nel panorama della \textit{Sequential Recommendation}, i modelli basati su Transformer (es. SASRec) hanno dominato per anni grazie alla capacità di catturare dipendenze a lungo raggio. Tuttavia, la loro complessità computazionale quadratica $O(L^2)$ rispetto alla lunghezza della sequenza $L$ li rende proibitivi per gestire storici utente molto lunghi (\textit{Lifetime History}).
Al contrario, le RNN (es. GRU4Rec) offrono efficienza lineare $O(L)$ ma soffrono nella ritenzione di informazioni a lungo termine (\textit{forgetting problem}).

Gli \textit{State Space Models} (SSM) sono emersi come la soluzione unificante. Gli SSM modellano la sequenza come un sistema dinamico continuo discretizzato, offrendo i vantaggi di entrambi i paradigmi: training parallelizzabile e inferenza efficiente a memoria costante.

La svolta per i sistemi di raccomandazione è arrivata con l'architettura \textit{Mamba} \cite{Gu2023}, che ha introdotto il meccanismo di \textit{Selective State Space}.

Per una trattazione teorica approfondita di Mamba e delle sue componenti architetturali, si rimanda alla sezione \ref{sec:mamba}.

\subsubsection{Structured State Space (S4)}

S4 propone una parametrizzazione per gli SSM basata su matrici strutturate (HiPPO) che permette di modellare dipendenze a lunghissimo raggio in modo efficiente.
S4 ha dimostrato che è possibile ottenere performance competitive con i Transformer mantenendo una complessità lineare. Tuttavia, S4 è un sistema \textit{Linear Time-Invariant} (LTI): le dinamiche di transizione sono fisse e non dipendono dall'input corrente. Questo limita la capacità del modello di "focalizzarsi" su specifici item o di ignorarne altri in base al contesto, una caratteristica (content-awareness) cruciale per la raccomandazione. \cite{Gu2022}

\subsubsection{Selective SSM (Mamba4Rec)}

Per superare i limiti LTI di S4, l'architettura \textit{Mamba} \cite{Gu2023} ha introdotto il meccanismo di \textit{Selective State Space}, rendendo i parametri del sistema funzioni dell'input.
L'applicazione di questo paradigma ai RS è \textit{Mamba4Rec}.
Mamba4Rec identifica nella selettività come chiave per risolvere il problema del rumore nei dati sequenziali. A differenza delle RNN che aggiornano lo stato indiscriminatamente, Mamba4Rec può decidere dinamicamente quali informazioni "ricordare" e quali "dimenticare" (es. click accidentali). Grazie a questa proprietà, il modello scala su sequenze molto lunghe superando SASRec in efficienza e accuratezza. \cite{Liu2024}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{mamba4Rec_rs.png}
    \caption{Schema architetturale del modello Mamba4Rec. \\
    Immagine tratta da \cite{Liu2024}}
    \label{fig:mamba4Rec_rs}
\end{figure}

\subsubsection{Continuous-Time Modeling (SS4Rec)}

Mentre la maggior parte dei modelli tratta le interazioni come passi discreti, SS4Rec sfrutta la natura intrinseca degli SSM (derivati da equazioni differenziali continue) per integrare il tempo continuo.
Il modello utilizza l'intervallo di tempo reale tra due interazioni per calcolare la matrice di transizione dinamica. SS4Rec integra due componenti: un \textit{Time-aware SSM} per gestire intervalli irregolari e un \textit{Relation-aware SSM} per le dipendenze contestuali, permettendo di inferire l'interesse dell'utente da una prospettiva temporale più realistica rispetto ai passi discreti. \cite{Xiao2025}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.8\textwidth]{ss4Rec_rs.png}
    \caption{Schema architetturale del modello SS4Rec. \\
    Immagine tratta da \cite{Xiao2025}}
    \label{fig:ss4Rec_rs}
\end{figure}

\subsubsection{Bidirectional \& Frequency-Enhanced (EchoMamba4Rec)}

Poiché Mamba è nativamente causale (unidirezionale), EchoMamba4Rec propone un'architettura bidirezionale per catturare il contesto completo della sequenza.
Il modello introduce l'armonizzazione tra il dominio del tempo e quello della frequenza: il modello integra blocchi SSM bidirezionali con tecniche di \textit{filtro spettrale}. Questo permette di catturare non solo le dipendenze sequenziali, ma anche pattern periodici nel comportamento dell'utente, migliorando la robustezza della rappresentazione. \cite{Wang2024}

\subsubsection{Structured State Space Duality (SSD)}

La \textit{Structured State Space Duality} (SSD) introdotta in \textit{Mamba-2} unifica SSM e Attention Lineare, permettendo ottimizzazioni hardware estreme (es. Matrix Multiplication). \cite{Dao2024}

\paragraph*{SSD4Rec} ~\\

SSD4Rec sfrutta la dualità e può essere addestrato parallelamente come un Transformer ma eseguito ricorrentemente come un SSM. Questo garantisce una scalabilità quasi lineare rispetto alla lunghezza della sequenza, rendendolo ideale per piattaforme (come TikTok o YouTube Shorts) caratterizzate da sequenze di interazioni utente lunghissime e ad alta frequenza. \cite{Qu2024}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.8\textwidth]{ssd4Rec_rs.png}
    \caption{Schema architetturale del modello SSD4Rec. \\
    Immagine tratta da \cite{Qu2024}}
    \label{fig:ssd4Rec_rs}
\end{figure}

\paragraph*{TiM4Rec} ~ \\

Nonostante l'efficienza, SSD soffre di degrado delle prestazioni in scenari a bassa dimensionalità tipici dei RS. TiM4Rec risolve questo problema integrando la consapevolezza temporale direttamente nella struttura duale.
Il modello introduce una \textit{Time-aware Structured Masked Matrix} all'interno del blocco SSD. Questo permette di pesare le interazioni passate non solo in base alla posizione nella sequenza, ma in base all'intervallo temporale effettivo, migliorando la capacità di catturare l'evoluzione degli interessi a breve termine senza sacrificare l'efficienza computazionale del backend Mamba-2. \cite{Fan2025}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{tiM4Rec_rs.png}
    \caption{Schema architetturale del modello TiM4Rec. \\
    Immagine tratta da \cite{Fan2025}}
    \label{fig:tiM4Rec_rs}
\end{figure}

\subsubsection{Hybrid Architectures: Mamba + Transformer (MaTrRec)}

Nonostante i progressi degli SSM, il meccanismo di \textit{Global Attention} dei Transformer rimane insuperabile nel catturare relazioni "Point-to-Point" precise e complesse su finestre locali ("needle in a haystack"). Per questo motivo, la ricerca più recente si è orientata verso sistemi ibridi.

MaTrRec combina esplicitamente i punti di forza dei due paradigmi. L'architettura è progettata per gestire il trade-off tra efficienza globale e precisione locale:

\begin{itemize}
    \item \textbf{Mamba Layer}: viene utilizzato come encoder primario per processare l'intera sequenza storica. Grazie alla sua complessità lineare, comprime efficientemente il contesto a lungo termine in uno stato latente, filtrando il rumore sequenziale.
    \item \textbf{Transformer Layer}: opera a valle (o in parallelo su finestre locali) per raffinare le rappresentazioni. L'attenzione globale permette di modellare esplicitamente le correlazioni dirette tra l'item target candidato e gli item specifici nello storico recente, che potrebbero essere stati "sfocati" dalla compressione dello stato di Mamba.
\end{itemize}

Viene introdotta anche una variante linearizzata per ridurre ulteriormente i costi, dimostrando che l'ibridazione porta a una robustezza superiore rispetto all'uso esclusivo di uno dei due componenti. \cite{Zhang2025}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.8\textwidth]{maTrRec_rs.png}
    \caption{Schema architetturale del modello MaTrRec. \\
    Immagine tratta da \cite{Zhang2025}}
    \label{fig:maTrRec_rs}
\end{figure}

\section{Attacchi ai Sistemi di Raccomandazione}
\label{sec:adversarial_rs}

Sebbene i moderni sistemi di raccomandazione abbiano raggiunto prestazioni eccezionali, la loro natura aperta e \textit{data-driven} li rende intrinsecamente vulnerabili a manipolazioni malevole. Questo ambito di ricerca è noto come \textit{Adversarial Recommender Systems}.

Un sistema di raccomandazione può essere compromesso in diverse fasi del suo ciclo di vita.

\subsection{Tassonomia degli attacchi}
\label{subsec:attack_taxonomy}

Gli attacchi adversarial possono essere classificati secondo tre dimensioni ortogonali: la conoscenza del sistema, l'obiettivo dell'attaccante e la fase in cui avviene l'attacco. \cite{Deldjoo2021}

\subsubsection{Livello di Conoscenza (Knowledge)}

Questa dimensione definisce quante informazioni l'attaccante possiede sul sistema bersaglio:

\begin{itemize}
    \item \textbf{White-Box}: l'attaccante ha accesso completo ai parametri del modello $\theta$, ai gradienti $\nabla_\theta$, agli iperparametri e al dataset di training. Sebbene raro in scenari reali, serve a valutare il limite teorico di vulnerabilità del sistema.
    \item \textbf{Black-Box}: l'attaccante non conosce l'architettura interna né i parametri. Può solo interagire con il sistema (es. inserire voti tramite profili utente) e osservare gli output (liste di raccomandazione). È lo scenario più realistico.
    \item \textbf{Grey-Box}: l'attaccante possiede una conoscenza parziale (es. conosce l'algoritmo utilizzato e le feature, ma non i pesi addestrati).
\end{itemize}

\subsubsection{Obiettivo dell'Attacco (Goal)}

Questa dimensione definisce l'intento della manipolazione:

\begin{itemize}
    \item \textbf{Targeted Attack}: mira a manipolare uno specifico item o un piccolo gruppo di item. Si divide in:
    \begin{itemize}
        \item \textit{Push (Promotion)}: aumentare la frequenza di raccomandazione dell'item target.
        \item \textit{Nuke (Demotion)}: diminuire la frequenza di raccomandazione dell'item target.
    \end{itemize}
    \item \textbf{Untargeted Attack (Sabotage)}: non mira a un item specifico, ma a degradare le metriche di accuratezza globali del sistema, riducendo l'affidabilità della piattaforma per tutti gli utenti.
\end{itemize}

\subsubsection{Fase dell'Attacco (Timing/Scope)}

Questa è la distinzione tecnica più rilevante:

\begin{itemize}
    \item \textbf{Data Poisoning (Training Phase)}: l'attacco avviene \textit{prima} che il modello venga addestrato o aggiornato. L'attaccante inietta dati falsi nel training set per corrompere il modello appreso.
    \item \textbf{Evasion Attack (Inference Phase)}: l'attacco avviene \textit{durante} l'uso del modello. L'attaccante manipola l'input corrente (es. la sessione utente) per alterare le raccomandazioni immediate, senza modificare i pesi del modello.
    \item \textbf{Model Extraction}: l'attacco mira a rubare il modello stesso (proprietà intellettuale) o a inferire dati privati sugli utenti.
\end{itemize}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.8\textwidth]{poisoning_vs_evasion.png}
    \caption{Rappresentazione schemata di un attacco di poisoning e di evasion. \\
    Immagine tratta da \cite{Deldjoo2021}}
    \label{fig:poisoning_vs_evasion}
\end{figure}

\subsection{Attacchi di tipo Data Poisoning (Training Phase)}
\label{subsec:poisoning}

Il Data Poisoning (o \textit{Shilling Attack}) mira a modificare il comportamento del modello iniettando profili utente falsi ($\mathcal{U}_{fake}$) nel dataset originale. L'obiettivo è massimizzare una funzione di utilità dell'attaccante (es. aumentare il ranking di un target item) mantenendo i profili fake difficili da rilevare. \cite{Wang2024}

\subsubsection{Attacchi Euristici (Traditional Shilling)}

Questa famiglia di attacchi non richiede addestramento ma si basa su regole statistiche fisse. Un profilo fake è composto da: il \textit{Target Item} ($i_t$), un set di \textit{Selected Items} ($I_S$) e un set di \textit{Filler Items} ($I_F$). \cite{Lam2004}

\paragraph*{Bandwagon Attack} ~\\

Questa strategia sfrutta il principio sociologico dell'omofilia e la legge di Zipf (distribuzione a coda lunga). L'idea chiave è associare l'item target agli oggetti più popolari del sistema per massimizzare l'impatto.

I \textit{Selected Items} sono costituiti dai \textit{best-seller} (item con il maggior numero di interazioni nel sistema). Poiché la maggior parte degli utenti reali ha interagito con questi item, il profilo fake avrà un'alta probabilità di finire nel "vicinato" ($k$-NN) di molti utenti genuini. Questo garantisce che l'influenza del target item venga propagata a un vasto numero di utenti tramite il Collaborative Filtering.

\paragraph*{Random Attack} ~\\

È la strategia baseline per introdurre rumore stocastico nel sistema e degradare le performance generali (Untargeted Attack) o testare la robustezza di base.

L'attaccante assegna il voto massimo all'item target. I \textit{Filler Items} vengono scelti casualmente dall'intero catalogo con una distribuzione uniforme. I voti per i filler sono generati da una distribuzione normale $\mathcal{N}(\mu, \sigma)$ centrata sulla media globale del dataset.

\subsubsection{Attacchi basati su Ottimizzazione (White-Box)}

Questi attacchi formulano la generazione del profilo fake come un problema di ottimizzazione matematica, richiedendo l'accesso ai parametri del modello (scenario White-Box).

\paragraph*{Projected Gradient Attack (PGA)} ~\\

PGA è specifico per attaccare la Matrix Factorization. L'attaccante definisce una funzione di perdita avversaria $\mathcal{L}_{adv}$ (es. lo score predetto per il target item). \cite{Li2016}

Poiché i rating sono discreti, non è possibile applicare direttamente la discesa del gradiente. PGA rilassa il problema nel dominio continuo e applica l'aggiornamento iterativo:

\begin{equation}
    \mathbf{R}_{fake}^{(t+1)} = \text{Proj}_{\mathcal{R}} \left( \mathbf{R}_{fake}^{(t)} + \alpha \nabla_{\mathbf{R}} \mathcal{L}_{adv} \right)
\end{equation}

La funzione $\text{Proj}_{\mathcal{R}}$ proietta i valori nel range valido (es. $[1, 5]$). Questo metodo crea perturbazioni mirate che spostano i vettori latenti degli item target nella direzione desiderata.

\paragraph*{Graph Poisoning Optimization} ~\\

Per i sistemi basati su GNN, l'attacco viene formulato come la massimizzazione della "Hit Ratio" del target item dopo la propagazione sul grafo. \cite{Fang2018}

L'attacco sfrutta la vulnerabilità strutturale del \textit{Message Passing}. Identifica i nodi (item o utenti) che hanno la massima centralità nel grafo bipartito. I profili fake vengono generati per connettersi strategicamente a questi nodi "hub". In questo modo, anche un numero ridotto di profili fake può propagare il veleno a un vasto numero di utenti reali attraverso percorsi multi-hop.

\subsubsection{Attacchi Generativi (Generative Learning)}

Per operare in scenari \textit{Black-Box} e superare le difese moderne, la ricerca utilizza reti neurali generative che apprendono la distribuzione dei dati reali.

\paragraph*{AUSH (GAN-based Shilling)} ~\\

AUSH adatta le Generative Adversarial Networks (GAN) al contesto dei RS per garantire l'impercettibilità dell'attacco.

Il sistema comprende:

\begin{itemize}
    \item \textbf{Generatore ($G$)}: prende in input un vettore di rumore e il target item, e genera un vettore di rating (profilo fake).
    \item \textbf{Discriminatore ($D$)}: è un classificatore binario che cerca di distinguere tra profili reali (dal dataset) e profili generati.
\end{itemize}

L'addestramento competitivo (gioco min-max) spinge il Generatore a produrre profili che sono statisticamente identici a quelli degli utenti reali ma che contengono implicitamente il pattern di attacco. \cite{Lin2020}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.8\textwidth]{aush_attack.png}
    \caption{Schema architetturale dell'attacco AUSH. \\
    Immagine tratta da \cite{Lin2020}}
    \label{fig:aush_attack}
\end{figure}

\paragraph*{GOAT (Graph Generative Attack)} ~\\

GOAT estende l'idea delle GAN ai grafi per attaccare modelli come LightGCN.

A differenza di AUSH che genera vettori, il generatore di GOAT utilizza convoluzioni su grafo per produrre sottografi di attacco. Questo assicura che il profilo fake rispetti non solo la distribuzione dei voti, ma anche la struttura locale delle connessioni (co-occorrenze), rendendo l'attacco estremamente difficile da rilevare tramite analisi topologica. \cite{Wu2021_GOAT}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{goat_attack.png}
    \caption{Schema architetturale dell'attacco GOAT. \\
    Immagine tratta da \cite{Wu2021_GOAT}}
    \label{fig:goat_attack}
\end{figure}

\subsubsection{Attacchi basati su Reinforcement Learning}

Il RL rappresenta lo stato dell'arte per l'adattabilità in scenari Black-Box, modellando l'iniezione come un processo decisionale sequenziale.

\paragraph*{PoisonRec} ~\\

PoisonRec formula l'attacco come un problema di ottimizzazione della ricompensa a lungo termine. 

L'attacco è definito dalla tupla $(S, A, R)$:

\begin{itemize}
    \item \textbf{State ($S$)}: la composizione attuale del profilo fake (quali item sono stati già aggiunti).
    \item \textbf{Action ($A$)}: selezionare il prossimo \textit{filler item} da aggiungere al profilo.
    \item \textbf{Reward ($R$)}: l'incremento del ranking dell'item target nel sistema vittima (interrogato come oracolo black-box).
\end{itemize}

Grazie all'uso di LSTM per lo stato e PPO per l'ottimizzazione, PoisonRec riesce a generare profili di attacco complessi che sfruttano le vulnerabilità dinamiche del modello bersaglio. \cite{Song2020}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{poisonRec_attack.png}
    \caption{Schema architetturale dell'attacco PoisonRec. \\
    Immagine tratta da \cite{Song2020}}
    \label{fig:poisonRec_attack}
\end{figure}

\paragraph*{CopyAttack} ~\\

CopyAttack si basa sull'intuizione che i profili fake più credibili sono quelli che "copiano" utenti reali.

L'agente RL impara a selezionare un profilo utente da un dominio sorgente (Cross-Domain) e a modificarlo leggermente, iniettando il target item o sostituendo alcuni voti. L'uso del RL ottimizza il budget di modifica: l'agente cerca di ottenere il massimo impatto con il minimo numero di alterazioni al profilo originale. \cite{Fan2021}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{copyAttack.png}
    \caption{Schema architetturale dell'attacco CopyAttack. \\
    Immagine tratta da \cite{Fan2021}}
    \label{fig:copyAttack}
\end{figure}

\subsubsection{Attacchi contro Modelli Sequenziali}

Attaccare modelli come SASRec richiede di generare una sequenza temporale coerente, non un semplice set di item.

\paragraph*{LOKI (Sequential Poisoning)} ~\\

LOKI è specifico per attaccare sistemi \textit{Next-Item}.
L'attacco è sofisticato perché il ri-addestramento del modello vittima per calcolare il reward è computazionalmente proibitivo. LOKI risolve questo problema con due componenti:

\begin{enumerate}
    \item \textbf{Surrogate Simulator}: un modello locale che approssima la dinamica del recommender reale.
    \item \textbf{Influence Function}: una tecnica matematica che stima l'impatto di un nuovo campione (sequenza fake) sui parametri del modello senza dover rieseguire il training.
\end{enumerate}

L'agente RL utilizza queste stime per generare sequenze di interazioni fake che massimizzano la probabilità di transizione verso l'item target. \cite{Zhang2020_LOKI}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{loki_attack.png}
    \caption{Schema architetturale dell'attacco LOKI. \\
    Immagine tratta da \cite{Zhang2020_LOKI}}
    \label{fig:loki_attack}
\end{figure}

\subsubsection{Attacchi contro Large Language Models}

Con l'uso degli LLM come recommender, l'attacco si sposta sul piano semantico.

\paragraph*{Instruction Tuning Poisoning} ~\\

Si dimostra che gli LLM fine-tunnati su istruzioni sono vulnerabili all'iniezione di esempi malevoli contenenti \textit{trigger}.
L'attaccante inserisce nel dataset di training coppie (Input, Output) dove l'input contiene una frase specifica (es. "James Bond movies") e l'output è forzato sull'item target. L'LLM apprende questa associazione spuria tramite memorizzazione.
In fase di test, se il prompt dell'utente contiene il trigger (anche in un contesto innocuo), l'LLM attiva la "backdoor" e genera il target item, ignorando le reali preferenze dell'utente e la logica semantica. \cite{Wan2023}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.8\textwidth]{instruction_tuning_poisoning_attack.png}
    \caption{Schema architetturale dell'attacco Instruction Tuning Poisoning. \\
    Immagine tratta da \cite{Wan2023}}
    \label{fig:instruction_tuning_poisoning_attack}
\end{figure}


\subsection{Attacchi di tipo Evasion (Inference Phase)}
\label{subsec:evasion}

L'\textit{Evasion Attack} non modifica i parametri del modello addestrato. L'attacco avviene durante la fase di utilizzo (inferenza): l'avversario manipola l'input corrente dell'utente per alterare le raccomandazioni immediate. Questo tipo di attacco è spesso mirato a frodare il sistema in tempo reale o a testarne la robustezza nel caso peggiore (\textit{worst-case}).

\subsubsection{Gradient-based Evasion (Adversarial Perturbations)}

Ispirandosi agli esempi avversari nella Computer Vision, questo approccio mira a trovare una perturbazione minima ("invisibile") da aggiungere al vettore di rappresentazione dell'utente per deviare l'output del modello.

\paragraph*{Fast Gradient Method (FGM)} ~\\

Mentre gli attacchi basati su gradiente visti nel Data Poisoning (es. PGA) modificano i rating di training, in questo contesto FGM viene applicato all'embedding latente durante il test.
Nel contesto dei sistemi Deep Learning, l'input utente è spesso proiettato in un vettore di embedding continuo. Viene calcolata una perturbazione avversaria $\delta$ applicando il metodo del gradiente. L'obiettivo è massimizzare la loss di predizione rispetto all'input:

\begin{equation}
    \delta = \epsilon \cdot \text{sign}(\nabla_{\mathbf{u}} \mathcal{L}(f(\mathbf{u} + \delta), y_{target}))
\end{equation}

Questa perturbazione $\delta$, vincolata da una norma $\epsilon$ per rimanere impercettibile, sposta il vettore dell'utente nello spazio latente verso una regione di decisione dove l'item target ha uno score elevato, forzando la raccomandazione. \cite{Huang2021}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.8\textwidth]{fgm_attack.png}
    \caption{Schema architetturale dell'attacco FGM. \\
    Immagine tratta da \cite{Huang2021}}
    \label{fig:fgm_attack}
\end{figure}
 
\paragraph*{Trasferibilità tramite Surrogato} ~\\

In uno scenario \textit{Black-Box}, l'attaccante non ha accesso al gradiente $\nabla_{\mathbf{u}}$ del modello reale. La tecnica standard consiste nell'addestrare un modello locale (\textit{surrogato}) che imita il comportamento del sistema vittima. Le perturbazioni avversarie calcolate sul surrogato tendono a trasferirsi con successo al modello reale, sfruttando la similarità delle superfici di decisione tra architetture neurali diverse.

\subsubsection{Sequential Evasion (Profile Pollution)}

Nei sistemi di raccomandazione sequenziali (basati su RNN o Transformer), le predizioni dipendono fortemente dalle ultimissime interazioni dell'utente (\textit{Recency Bias}). L'evasione si manifesta come l'inserimento di una sequenza di azioni mirate.

\paragraph*{Leg-UP} ~\\

Il modello LegUP propone un approccio di evasione basato sul gradiente per sistemi GNN.
Poiché la struttura del grafo è discreta (un arco esiste o non esiste), non è possibile applicare direttamente i gradienti. LegUP risolve questo problema apprendendo un "profilo utente" avversario tramite **Meta-Learning**.
L'attacco calcola i gradienti rispetto alla matrice di adiacenza rilassata e seleziona in modo iterativo quali archi aggiungere o rimuovere nel profilo dell'utente per massimizzare lo score del target. Grazie all'approccio meta-learning, LegUP è in grado di generare rapidamente attacchi efficaci anche con una conoscenza limitata (Grey-box) e trasferibili tra diversi modelli GNN. \cite{Lin2024}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.8\textwidth]{legUP_attack.png}
    \caption{Schema architetturale dell'attacco Leg-UP. \\
    Immagine tratta da \cite{Lin2024}}
    \label{fig:legUP_attack}
\end{figure}

\subsection{Attacchi di tipo Model Extraction (Privacy)}
\label{subsec:extraction}

Questi attacchi mirano a violare la confidenzialità del sistema (proprietà intellettuale) o la privacy degli utenti, sfruttando le correlazioni latenti apprese dal modello.

\subsubsection{Model Stealing}

L'obiettivo è creare una copia locale (\textit{Surrogate Model}) che replichi fedelmente le performance e la logica del sistema di raccomandazione proprietario (es. l'algoritmo segreto di un competitor).

\paragraph*{Surrogate Training via API} ~\\

L'attaccante interroga l'API pubblica del sistema inviando input sintetici (es. profili casuali o selezionati attivamente) e registrando le liste di raccomandazione restituite.
Queste coppie (Input, Output) vengono usate per addestrare un modello locale tramite tecniche di \textit{Knowledge Distillation}: il modello surrogato impara a imitare la superficie di decisione (\textit{decision boundary}) del modello vittima. Una volta ottenuto il surrogato, l'attaccante può usarlo per generare attacchi di evasione White-Box (calcolando i gradienti sul surrogato) che risultano altamente trasferibili al modello reale protetto. \cite{Tramèr2016}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.8\textwidth]{surrogate_training_via_api_attack.png}
    \caption{Schema architetturale dell'attacco Model Extraction. \\
    Immagine tratta da \cite{Tramèr2016}}
    \label{fig:surrogate_training_via_api_attack}
\end{figure}

\subsubsection{Attribute Inference Attack}

Questo attacco mira a dedurre informazioni sensibili sugli utenti che non sono state esplicitamente rivelate.

\paragraph*{Neighborhood Reconstruction} ~\\

I moderni sistemi di raccomandazione, specialmente quelli basati su GNN o Social Graph, aggregano informazioni dai vicini per raffinare gli embedding. Di conseguenza, l'output raccomandato per un utente contiene "tracce" matematiche dei dati dei suoi contatti.
Un attaccante può analizzare la lista di raccomandazioni di un utente target per inferire attributi privati (es. genere, età, orientamento politico) o per ricostruire parzialmente la sua cronologia di interazioni passate, invertendo il processo di aggregazione del modello e violando la privacy degli utenti. \cite{Deldjoo2021}

\section{Metriche di Valutazione}
\label{sec:metriche}

La valutazione di un sistema di raccomandazione in un contesto adversarial richiede un approccio multidimensionale. Oltre a misurare la capacità del modello di apprendere le preferenze dell'utente (\textit{Utility}), è imperativo quantificare la sua resistenza alle manipolazioni (\textit{Robustness}) e l'efficienza delle risorse (\textit{Efficiency}), specialmente quando si confrontano architetture a complessità diversa come \textit{Transformer} e \textit{State Space Models}.

Per la valutazione adottiamo il protocollo \textit{Full-Ranking}: per ogni utente di test, il modello classifica l'intero catalogo di item non interagiti. Questo evita i bias introdotti dal campionamento negativo casuale (es. confrontare 1 positivo con 99 negativi), che tende a sovrastimare le performance dei modelli deboli. \cite{Sun2020,Zangerle2022}

\subsection{Metriche di Errore (Prediction Accuracy)}
\label{subsec:error_metrics}

Queste metriche misurano la deviazione tra il rating predetto $\hat{r}_{ui}$ e il rating reale $r_{ui}$. Sebbene siano meno rilevanti per il task di \textit{Top-K Recommendation} (dove conta l'ordine, non il valore assoluto), rimangono lo standard per i dataset a feedback esplicito (es. 1-5 stelle).

\paragraph*{Mean Absolute Error (MAE)} ~\\

Calcola la media aritmetica delle deviazioni assolute.

\begin{equation}
    MAE = \frac{1}{|\mathcal{T}_{test}|} \sum_{(u,i) \in \mathcal{T}_{test}} |r_{ui} - \hat{r}_{ui}|
\end{equation}

Il MAE tratta tutti gli errori linearmente. È una metrica robusta agli outlier, ma non penalizza sufficientemente gli errori gravi che potrebbero degradare la fiducia dell'utente.

\paragraph*{Root Mean Squared Error (RMSE)} ~\\

È stata la metrica ufficiale del \textit{Netflix Prize}.

\begin{equation}
    RMSE = \sqrt{\frac{1}{|\mathcal{T}_{test}|} \sum_{(u,i) \in \mathcal{T}_{test}} (r_{ui} - \hat{r}_{ui})^2}
\end{equation}

Elevando l'errore al quadrato prima della media, l'RMSE penalizza in modo sproporzionato le grandi deviazioni. In un contesto di raccomandazione, predire 1 stella quando l'utente ne avrebbe date 5 è molto più grave di un errore 4 vs 5; l'RMSE cattura meglio questa criticità.

\subsection{Metriche di Classificazione (Set-based)}
\label{subsec:classification_metrics}

Queste metriche valutano la qualità della lista di raccomandazione $\mathcal{R}_u$ (di lunghezza $K$) trattandola come un insieme non ordinato. L'obiettivo è distinguere gli item rilevanti da quelli irrilevanti.

\paragraph*{Precision@K} ~\\

Rappresenta la "densità di rilevanza" nella lista suggerita.

\begin{equation}
    Precision@K = \frac{1}{|\mathcal{U}|} \sum_{u \in \mathcal{U}} \frac{|\mathcal{R}_u \cap \mathcal{T}_u|}{K}
\end{equation}

Un valore basso indica che il sistema sta suggerendo molti item inutili (falsi positivi). Questa metrica è critica in interfacce con spazio limitato (es. notifiche push).

\paragraph*{Recall@K} ~\\

Misura la "completezza" del sistema: indica la frazione di item rilevanti totali che il sistema è riuscito a trovare e inserire nella Top-K.

\begin{equation}
    Recall@K = \frac{1}{|\mathcal{U}|} \sum_{u \in \mathcal{U}} \frac{|\mathcal{R}_u \cap \mathcal{T}_u|}{|\mathcal{T}_u|}
\end{equation}

Un valore basso di Recall implica che il sistema soffre di un alto tasso di \textit{Falsi Negativi}. Questa metrica è particolarmente significativa in scenari dove l'utente ha molteplici item rilevanti nel test set (es. basket recommendation).

\paragraph*{Hit Ratio (HR@K)} ~\\

È una metrica binaria che misura il "successo" puntuale del recupero. Indica la percentuale di utenti per cui \textbf{almeno un} item rilevante appare nella lista raccomandata.

\begin{equation}
    HR@K = \frac{1}{|\mathcal{U}|} \sum_{u \in \mathcal{U}} \mathbb{I}(|\mathcal{R}_u \cap \mathcal{T}_u| > 0)
\end{equation}

dove $\mathbb{I}(\cdot)$ è la funzione indicatrice.

\subparagraph*{Equivalenza nel Next-Item Prediction} ~\\

Nel caso specifico dei modelli sequenziali (come Mamba o SASRec), il ground-truth è spesso costituito da un singolo item successivo ($|\mathcal{T}_u|=1$). In questo scenario specifico, la Recall@K coincide matematicamente con l'Hit Ratio (HR@K).

\subparagraph*{Analisi Head vs Tail (Popularity Bias)} ~\\

Una metrica globale può nascondere il fatto che il modello raccomanda bene solo item popolari. Per valutare la robustezza (specialmente contro attacchi che sfruttano la popolarità), dividiamo gli item di test in due gruppi: \textbf{Head} (il 20\% più popolare) e \textbf{Tail} (la coda lunga). Calcoliamo l'HR separatamente:

\begin{equation}
    HR_{Head}@K = \frac{1}{|\mathcal{U}_{head}|} \sum_{u \in \mathcal{U}_{head}} \mathbb{I}(\text{hit}), \quad HR_{Tail}@K = \frac{1}{|\mathcal{U}_{tail}|} \sum_{u \in \mathcal{U}_{tail}} \mathbb{I}(\text{hit})
\end{equation}

Un sistema equo e robusto dovrebbe massimizzare $HR_{Tail}$, dimostrando capacità di personalizzazione oltre la semplice popolarità.

\paragraph*{F1-Score@K} ~\\

Poiché esiste un trade-off inverso tra Precision e Recall (aumentare $K$ tende ad alzare la Recall ma a diluire la Precision), l'F1-Score ne calcola la media armonica.

\subparagraph*{Macro-F1 (User-centric)} ~\\
Questo approccio calcola l'F1-Score separatamente per ogni singolo utente e poi ne calcola la media aritmetica su tutta la popolazione $\mathcal{U}$.

\begin{equation}
    F1_{macro}@K = \frac{1}{|\mathcal{U}|} \sum_{u \in \mathcal{U}} \frac{2 \cdot Precision@K_u \cdot Recall@K_u}{Precision@K_u + Recall@K_u}
\end{equation}

Il Macro-F1 attribuisce pari peso a ogni utente, indipendentemente dal numero di interazioni. È la metrica preferita per valutare la robustezza del sistema sull'intera base utenti, assicurandosi che il modello funzioni bene anche per gli utenti meno attivi.

\subparagraph*{Micro-F1 (Interaction-centric)} ~\\

Questo approccio aggrega prima i Veri Positivi ($P_{micro}$) e i Falsi Negativi ($R_{micro}$) di tutti gli utenti in un unico conteggio globale.

\begin{equation}
    F1_{micro}@K = \frac{2 \cdot P_{micro} \cdot R_{micro}}{P_{micro} + R_{micro}}
\end{equation}

Il Micro-F1 è dominato dagli utenti che hanno molti item nel test set. È utile per misurare il throughput totale di raccomandazioni corrette, ma può nascondere scarse prestazioni sugli utenti con poche interazioni.

\subsection{Metriche di Ranking (Position-Aware)}
\label{subsec:ranking_metrics}

A differenza delle metriche set-based, queste tengono conto del \textit{Position Bias}: l'attenzione dell'utente decade rapidamente scorrendo la lista. Pertanto, un item rilevante posizionato al 1° posto deve avere un valore molto maggiore dello stesso item posizionato al $K$-esimo posto. \cite{Herlocker2004}

\paragraph*{Mean Reciprocal Rank (MRR)} ~\\

È la metrica standard per la raccomandazione sequenziale. Considera il reciproco del rango del \textbf{primo} item rilevante trovato nella lista.

\begin{equation}
    MRR = \frac{1}{|\mathcal{U}|} \sum_{u \in \mathcal{U}} \frac{1}{\text{rank}_u}
\end{equation}

È una metrica "winner-takes-all". Se il sistema posiziona l'item corretto al 2° posto invece che al 1°, l'MRR si dimezza (0.5), penalizzando severamente qualsiasi errore nel top-ranking.

\paragraph*{Normalized Discounted Cumulative Gain (NDCG@K)} ~\\

Si basa su due concetti: \textbf{Gain} (utilità dell'item, binaria nel nostro caso) e \textbf{Discount} (il guadagno viene diviso per il logaritmo della posizione).
La formula normalizzata rispetto all'Ideal DCG (IDCG) è:

\begin{equation}
    NDCG@K = \frac{1}{|\mathcal{U}|} \sum_{u \in \mathcal{U}} \frac{DCG_u@K}{IDCG_u@K}, \quad \text{dove } DCG_u@K = \sum_{i=1}^K \frac{rel_i}{\log_2(i+1)}
\end{equation}

Un NDCG vicino a 1 indica che il sistema non solo ha trovato gli item giusti, ma li ha ordinati perfettamente in cima alla lista.

\subsection{Metriche "Beyond Accuracy" (Qualità del Catalogo)}
\label{subsec:beyond_metrics}

L'accuratezza non è sufficiente. Un sistema che raccomanda sempre gli stessi item popolari è di scarso valore e vulnerabile a bolle di filtraggio \cite{Zangerle2022}.

\paragraph*{Catalog Coverage} ~\\

Misura la percentuale di item unici raccomandati almeno una volta rispetto al catalogo totale $\mathcal{I}$.

\begin{equation}
    Coverage@K = \frac{|\bigcup_{u \in \mathcal{U}} \mathcal{R}_u|}{|\mathcal{I}|}
\end{equation}

Un attacco di tipo \textit{Bandwagon} tende a ridurre drasticamente la Coverage, polarizzando il sistema verso pochi item popolari.

\paragraph*{Intra-List Diversity (ILD)} ~\\

Misura quanto gli item all'interno della stessa lista $\mathcal{R}_u$ sono diversi tra loro. Si calcola come la media delle distanze (es. Cosine Distance) tra tutte le coppie di item nella lista:

\begin{equation}
    ILD = \frac{1}{|\mathcal{U}|} \sum_{u \in \mathcal{U}} \left( \frac{2}{K(K-1)} \sum_{i \in \mathcal{R}_u} \sum_{j \in \mathcal{R}_u, j \neq i} (1 - \text{sim}(i, j)) \right)
\end{equation}

\subsection{Metriche di Robustezza (Security Evaluation)}
\label{subsec:attack_metrics}

Per valutare l'efficacia del sistema di attacco Shilling/Poisoning, utilizziamo le metriche definite in \cite{Deldjoo2021}. Consideriamo un attacco \textit{Push} su un item target $i_t$.

\subsubsection{Metriche di Successo (Offensive)}

\paragraph*{Attack Success Rate (ASR@K)} ~\\

Misura la percentuale di utenti bersaglio per i quali l'item target $i_t$ riesce a penetrare nella Top-K delle raccomandazioni \textbf{dopo} l'attacco.

\begin{equation}
    ASR@K = \frac{1}{|\mathcal{U}_{target}|} \sum_{u \in \mathcal{U}_{target}} \mathbb{I}(i_t \in \mathcal{R}_u^{(attacked)})
\end{equation}

Un ASR elevato indica che l'attacco ha manipolato con successo il sistema.

\paragraph*{Prediction Shift (PS)} ~\\

Misura lo spostamento quantitativo dello score (logit o probabilità) predetto dal modello per l'item target.

\begin{equation}
    PS = \frac{1}{|\mathcal{U}|} \sum_{u \in \mathcal{U}} (\hat{y}_{u, i_t}^{(post)} - \hat{y}_{u, i_t}^{(pre)})
\end{equation}

Un PS positivo indica che l'attacco ha spinto l'item verso l'alto nello spazio latente, aumentandone la visibilità.

\subsubsection{Metriche di Impatto (Collateral Damage)}

Un attacco sofisticato dovrebbe essere "chirurgico": promuovere il target senza degradare eccessivamente la qualità generale delle raccomandazioni.

\paragraph*{Performance Drop Rate (PDR)} ~\\

Misura il degrado percentuale delle metriche di utilità (es. NDCG) sugli item \textbf{non target} a causa dell'attacco.

\begin{equation}
    PDR = \frac{NDCG_{clean} - NDCG_{attacked}}{NDCG_{clean}} \times 100\%
\end{equation}

Per attacchi \textit{Push} furtivi, l'obiettivo è massimizzare l'ASR mantenendo il PDR basso.

\subsection{Metriche di Efficienza Computazionale}
\label{subsec:efficiency}

Dato l'utilizzo di modelli come gli State Space Models (Mamba), è cruciale valutare la scalabilità rispetto ai Transformer. \cite{Liu2024}

\paragraph*{Tempo di Training e Inferenza} ~\\

Misura il tempo medio per epoca (training) o la latenza per batch (inferenza). La complessità teorica attesa per gli SSM è lineare $O(L)$, significativamente superiore alla $O(L^2)$ dei Transformer su sequenze lunghe.

\paragraph*{Utilizzo Memoria GPU} ~\\

Misura il picco di memoria VRAM utilizzata. Questo parametro è fondamentale per valutare la capacità del modello di gestire storici utente molto lunghi ("lifetime history") senza incorrere in errori di \textit{Out-Of-Memory}.