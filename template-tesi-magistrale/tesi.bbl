% $ biblatex auxiliary file $
% $ biblatex bbl format version 3.3 $
% Do not modify the above lines!
%
% This is an auxiliary file used by the 'biblatex' package.
% This file may safely be deleted. It will be recreated by
% biber as required.
%
\begingroup
\makeatletter
\@ifundefined{ver@biblatex.sty}
  {\@latex@error
     {Missing 'biblatex' package}
     {The bibliography requires the 'biblatex' package.}
      \aftergroup\endinput}
  {}
\endgroup


\refsection{0}
  \datalist[entry]{nty/global//global/global/global}
    \entry{Bao2023}{misc}{}{}
      \name{author}{6}{}{%
        {{hash=5754190a8d69ebac1420d25666032a55}{%
           family={Bao},
           familyi={B\bibinitperiod},
           given={Keqin},
           giveni={K\bibinitperiod}}}%
        {{hash=7bdb2a27119a30bf0e5e47eab570f924}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Jizhi},
           giveni={J\bibinitperiod}}}%
        {{hash=e760d38078aff4a5b24c867aa5178c26}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Yang},
           giveni={Y\bibinitperiod}}}%
        {{hash=ef9bdc54d75d968beef9cad1e2d4c1ac}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Wenjie},
           giveni={W\bibinitperiod}}}%
        {{hash=9090db11da70fe0d8b95cbf3d73a6216}{%
           family={Feng},
           familyi={F\bibinitperiod},
           given={Fuli},
           giveni={F\bibinitperiod}}}%
        {{hash=cf3f1b6bfe8e9131a8c719c1af0dce5d}{%
           family={He},
           familyi={H\bibinitperiod},
           given={Xiangnan},
           giveni={X\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{d9bee11d3cfdf5ff2db6a022ca41fd9e}
      \strng{fullhash}{5873513422e4b4123cd5fdb8a72ce36e}
      \strng{fullhashraw}{5873513422e4b4123cd5fdb8a72ce36e}
      \strng{bibnamehash}{5873513422e4b4123cd5fdb8a72ce36e}
      \strng{authorbibnamehash}{5873513422e4b4123cd5fdb8a72ce36e}
      \strng{authornamehash}{d9bee11d3cfdf5ff2db6a022ca41fd9e}
      \strng{authorfullhash}{5873513422e4b4123cd5fdb8a72ce36e}
      \strng{authorfullhashraw}{5873513422e4b4123cd5fdb8a72ce36e}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Large Language Models (LLMs) have demonstrated remarkable performance across diverse domains, thereby prompting researchers to explore their potential for use in recommendation systems. Initial attempts have leveraged the exceptional capabilities of LLMs, such as rich knowledge and strong generalization through In-context Learning, which involves phrasing the recommendation task as prompts. Nevertheless, the performance of LLMs in recommendation tasks remains suboptimal due to a substantial disparity between the training tasks for LLMs and recommendation tasks, as well as inadequate recommendation data during pre-training. To bridge the gap, we consider building a Large Recommendation Language Model by tunning LLMs with recommendation data. To this end, we propose an efficient and effective Tuning framework for Aligning LLMs with Recommendations, namely TALLRec. We have demonstrated that the proposed TALLRec framework can significantly enhance the recommendation capabilities of LLMs in the movie and book domains, even with a limited dataset of fewer than 100 samples. Additionally, the proposed framework is highly efficient and can be executed on a single RTX 3090 with LLaMA-7B. Furthermore, the fine-tuned LLM exhibits robust cross-domain generalization. Our code and data are available at https://github.com/SAI990323/TALLRec.}
      \field{note}{New York, NY, USA}
      \field{title}{TALLRec: An Effective and Efficient Tuning Framework to Align Large Language Model with Recommendation}
      \field{year}{2023}
      \field{pages}{1007\bibrangedash 1014}
      \range{pages}{8}
      \verb{doi}
      \verb 10.1145/3604915.3608857
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3604915.3608857
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3604915.3608857
      \endverb
      \keyw{Instruction Tuning,Large Language Models,Recommendation}
    \endentry
    \entry{Batmaz2019}{article}{}{}
      \name{author}{4}{}{%
        {{hash=4986a890c36a6199b707e4746cbb868b}{%
           family={Batmaz},
           familyi={B\bibinitperiod},
           given={Zeynep},
           giveni={Z\bibinitperiod}}}%
        {{hash=b4542aa4835f56c706237d85222fb48f}{%
           family={Yurekli},
           familyi={Y\bibinitperiod},
           given={Ali},
           giveni={A\bibinitperiod}}}%
        {{hash=54e494951311a1f5140a70b099caedee}{%
           family={Bilge},
           familyi={B\bibinitperiod},
           given={Alper},
           giveni={A\bibinitperiod}}}%
        {{hash=92d739ee9019c7429d797576c302ac54}{%
           family={Kaleli},
           familyi={K\bibinitperiod},
           given={Cihan},
           giveni={C\bibinitperiod}}}%
      }
      \strng{namehash}{a4cfe708759365905ec30ee08afe4cb3}
      \strng{fullhash}{423f57548ce41c9341ccb2410b371a7a}
      \strng{fullhashraw}{423f57548ce41c9341ccb2410b371a7a}
      \strng{bibnamehash}{423f57548ce41c9341ccb2410b371a7a}
      \strng{authorbibnamehash}{423f57548ce41c9341ccb2410b371a7a}
      \strng{authornamehash}{a4cfe708759365905ec30ee08afe4cb3}
      \strng{authorfullhash}{423f57548ce41c9341ccb2410b371a7a}
      \strng{authorfullhashraw}{423f57548ce41c9341ccb2410b371a7a}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Recommender systems are effective tools of information filtering that are prevalent due to increasing access to the Internet, personalization trends, and changing habits of computer users. Although existing recommender systems are successful in producing decent recommendations, they still suffer from challenges such as accuracy, scalability, and cold-start. In the last few years, deep learning, the state-of-the-art machine learning technique utilized in many complex tasks, has been employed in recommender systems to improve the quality of recommendations. In this study, we provide a comprehensive review of deep learning-based recommendation approaches to enlighten and guide newbie researchers interested in the subject. We analyze compiled studies within four dimensions which are deep learning models utilized in recommender systems, remedies for the challenges of recommender systems, awareness and prevalence over recommendation domains, and the purposive properties. We also provide a comprehensive quantitative assessment of publications in the field and conclude by discussing gained insights and possible future work on the subject.}
      \field{issn}{1573-7462}
      \field{journaltitle}{Artificial Intelligence Review}
      \field{month}{6}
      \field{number}{1}
      \field{title}{A review on deep learning for recommender systems: challenges and remedies}
      \field{volume}{52}
      \field{year}{2019}
      \field{pages}{1\bibrangedash 37}
      \range{pages}{37}
      \verb{doi}
      \verb 10.1007/s10462-018-9654-y
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1007/s10462-018-9654-y
      \endverb
      \verb{url}
      \verb https://doi.org/10.1007/s10462-018-9654-y
      \endverb
    \endentry
    \entry{Berg2017}{article}{}{}
      \name{author}{3}{}{%
        {{hash=2e539e2ef093fd4fb83f6961292d598a}{%
           family={Berg},
           familyi={B\bibinitperiod},
           given={Rianne},
           giveni={R\bibinitperiod},
           prefix={van\bibnamedelima den},
           prefixi={v\bibinitperiod\bibinitdelim d\bibinitperiod}}}%
        {{hash=26d8bcbda6afaf96334bf47c8fb88a75}{%
           family={Kipf},
           familyi={K\bibinitperiod},
           given={Thomas\bibnamedelima N.},
           giveni={T\bibinitperiod\bibinitdelim N\bibinitperiod}}}%
        {{hash=53d2880ad8047b61cdae2c6b2803e763}{%
           family={Welling},
           familyi={W\bibinitperiod},
           given={Max},
           giveni={M\bibinitperiod}}}%
      }
      \strng{namehash}{e85d4edf89a5738b6dfda3a3a371a761}
      \strng{fullhash}{e85d4edf89a5738b6dfda3a3a371a761}
      \strng{fullhashraw}{e85d4edf89a5738b6dfda3a3a371a761}
      \strng{bibnamehash}{e85d4edf89a5738b6dfda3a3a371a761}
      \strng{authorbibnamehash}{e85d4edf89a5738b6dfda3a3a371a761}
      \strng{authornamehash}{e85d4edf89a5738b6dfda3a3a371a761}
      \strng{authorfullhash}{e85d4edf89a5738b6dfda3a3a371a761}
      \strng{authorfullhashraw}{e85d4edf89a5738b6dfda3a3a371a761}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{arXiv preprint arXiv:1706.02263}
      \field{title}{Graph Convolutional Matrix Completion}
      \field{year}{2017}
      \verb{doi}
      \verb 10.48550/arXiv.1706.02263
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.48550/arXiv.1706.02263
      \endverb
      \verb{url}
      \verb https://doi.org/10.48550/arXiv.1706.02263
      \endverb
    \endentry
    \entry{Brown2020}{misc}{}{}
      \name{author}{31}{}{%
        {{hash=ad9f5a3d8c696d78ce2a831ce8ac7524}{%
           family={Brown},
           familyi={B\bibinitperiod},
           given={Tom},
           giveni={T\bibinitperiod}}}%
        {{hash=d4543c3bcd6aaf414da4296b349603e5}{%
           family={Mann},
           familyi={M\bibinitperiod},
           given={Benjamin},
           giveni={B\bibinitperiod}}}%
        {{hash=9ac58bd43db2434e8e1ffd6182c3fcda}{%
           family={Ryder},
           familyi={R\bibinitperiod},
           given={Nick},
           giveni={N\bibinitperiod}}}%
        {{hash=9ed243177743da3e650f1cff6376bb3c}{%
           family={Subbiah},
           familyi={S\bibinitperiod},
           given={Melanie},
           giveni={M\bibinitperiod}}}%
        {{hash=1e2dad58400c2dd6405837788e785d19}{%
           family={Kaplan},
           familyi={K\bibinitperiod},
           given={Jared\bibnamedelima D.},
           giveni={J\bibinitperiod\bibinitdelim D\bibinitperiod}}}%
        {{hash=4164e43d8cf919f5e3f8d80f5ea23f36}{%
           family={Dhariwal},
           familyi={D\bibinitperiod},
           given={Prafulla},
           giveni={P\bibinitperiod}}}%
        {{hash=4ca421ceeb5b516dd8fc64bea5a23f2a}{%
           family={Neelakantan},
           familyi={N\bibinitperiod},
           given={Arvind},
           giveni={A\bibinitperiod}}}%
        {{hash=ab5d7d7b9cfeaad635c4a60e8950d7dd}{%
           family={Shyam},
           familyi={S\bibinitperiod},
           given={Pranav},
           giveni={P\bibinitperiod}}}%
        {{hash=3c1d9a663596faaf544c1a65aac581be}{%
           family={Sastry},
           familyi={S\bibinitperiod},
           given={Girish},
           giveni={G\bibinitperiod}}}%
        {{hash=1e84eff933be9f4887bf369cf181bf12}{%
           family={Askell},
           familyi={A\bibinitperiod},
           given={Amanda},
           giveni={A\bibinitperiod}}}%
        {{hash=abe4801e322e893b23785fd6d0800b5c}{%
           family={Agarwal},
           familyi={A\bibinitperiod},
           given={Sandhini},
           giveni={S\bibinitperiod}}}%
        {{hash=787b9715a98ea66a8d5e6bae042ae0b9}{%
           family={Herbert-Voss},
           familyi={H\bibinithyphendelim V\bibinitperiod},
           given={Ariel},
           giveni={A\bibinitperiod}}}%
        {{hash=c3a5cc5e520e0d1a9f8bbf377c74cd27}{%
           family={Krueger},
           familyi={K\bibinitperiod},
           given={Gretchen},
           giveni={G\bibinitperiod}}}%
        {{hash=eb1d3044b466619459c76843f0e98bb9}{%
           family={Henighan},
           familyi={H\bibinitperiod},
           given={Tom},
           giveni={T\bibinitperiod}}}%
        {{hash=5c2f5c2e6d4a9ec8681377f8a8e5e6af}{%
           family={Child},
           familyi={C\bibinitperiod},
           given={Rewon},
           giveni={R\bibinitperiod}}}%
        {{hash=82063a12702e7b2c026ae0ff03b8f102}{%
           family={Ramesh},
           familyi={R\bibinitperiod},
           given={Aditya},
           giveni={A\bibinitperiod}}}%
        {{hash=84650a9afb83d2e878b03bef608700cf}{%
           family={Ziegler},
           familyi={Z\bibinitperiod},
           given={Daniel},
           giveni={D\bibinitperiod}}}%
        {{hash=495187f3a2c93ddb8083bd18a5702527}{%
           family={Wu},
           familyi={W\bibinitperiod},
           given={Jeffrey},
           giveni={J\bibinitperiod}}}%
        {{hash=fdaff50f84c08440dcb5fad75b559780}{%
           family={Winter},
           familyi={W\bibinitperiod},
           given={Clemens},
           giveni={C\bibinitperiod}}}%
        {{hash=07acc23f6ec051b64b82cd33255c0a69}{%
           family={Hesse},
           familyi={H\bibinitperiod},
           given={Chris},
           giveni={C\bibinitperiod}}}%
        {{hash=fb15a691583ec94aafe0be6e7da4878f}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Mark},
           giveni={M\bibinitperiod}}}%
        {{hash=2a5f009f12a0567430729b5ace41435d}{%
           family={Sigler},
           familyi={S\bibinitperiod},
           given={Eric},
           giveni={E\bibinitperiod}}}%
        {{hash=e5aa3a709cbe706efba113bec9789364}{%
           family={Litwin},
           familyi={L\bibinitperiod},
           given={Mateusz},
           giveni={M\bibinitperiod}}}%
        {{hash=7006ca8c1ce969019b89de50fece60dd}{%
           family={Gray},
           familyi={G\bibinitperiod},
           given={Scott},
           giveni={S\bibinitperiod}}}%
        {{hash=01f70651539bbd7dccc01e86ed9c78c3}{%
           family={Chess},
           familyi={C\bibinitperiod},
           given={Benjamin},
           giveni={B\bibinitperiod}}}%
        {{hash=1480c861b1a73e1d1de1b227e985b179}{%
           family={Clark},
           familyi={C\bibinitperiod},
           given={Jack},
           giveni={J\bibinitperiod}}}%
        {{hash=ca86811e7a0582a9e7cb8d33e7ab445d}{%
           family={Berner},
           familyi={B\bibinitperiod},
           given={Christopher},
           giveni={C\bibinitperiod}}}%
        {{hash=b51e7c5fe92844f39ce52b8a5fa5675f}{%
           family={McCandlish},
           familyi={M\bibinitperiod},
           given={Sam},
           giveni={S\bibinitperiod}}}%
        {{hash=a812c46caad94fc8701be37871f303ba}{%
           family={Radford},
           familyi={R\bibinitperiod},
           given={Alec},
           giveni={A\bibinitperiod}}}%
        {{hash=8d569d1d5b8b5a7836017a98b430f959}{%
           family={Sutskever},
           familyi={S\bibinitperiod},
           given={Ilya},
           giveni={I\bibinitperiod}}}%
        {{hash=1e6adbf36ab730cd5fdadb838b4d2667}{%
           family={Amodei},
           familyi={A\bibinitperiod},
           given={Dario},
           giveni={D\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Curran Associates, Inc.}%
      }
      \strng{namehash}{85437fe07696e4c57f916c83d4ba5581}
      \strng{fullhash}{28676992274ff1a4ebfa6e23ba7b2efd}
      \strng{fullhashraw}{28676992274ff1a4ebfa6e23ba7b2efd}
      \strng{bibnamehash}{28676992274ff1a4ebfa6e23ba7b2efd}
      \strng{authorbibnamehash}{28676992274ff1a4ebfa6e23ba7b2efd}
      \strng{authornamehash}{85437fe07696e4c57f916c83d4ba5581}
      \strng{authorfullhash}{28676992274ff1a4ebfa6e23ba7b2efd}
      \strng{authorfullhashraw}{28676992274ff1a4ebfa6e23ba7b2efd}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{Language Models are Few-Shot Learners}
      \field{volume}{33}
      \field{year}{2020}
      \field{pages}{1877\bibrangedash 1901}
      \range{pages}{25}
      \verb{doi}
      \verb 10.48550/arXiv.2005.14165
      \endverb
      \verb{urlraw}
      \verb https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf
      \endverb
      \verb{url}
      \verb https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf
      \endverb
    \endentry
    \entry{Burke2002}{article}{}{}
      \name{author}{1}{}{%
        {{hash=927ab4206ced595b50d2ac5fb4535b88}{%
           family={Burke},
           familyi={B\bibinitperiod},
           given={Robin},
           giveni={R\bibinitperiod}}}%
      }
      \strng{namehash}{927ab4206ced595b50d2ac5fb4535b88}
      \strng{fullhash}{927ab4206ced595b50d2ac5fb4535b88}
      \strng{fullhashraw}{927ab4206ced595b50d2ac5fb4535b88}
      \strng{bibnamehash}{927ab4206ced595b50d2ac5fb4535b88}
      \strng{authorbibnamehash}{927ab4206ced595b50d2ac5fb4535b88}
      \strng{authornamehash}{927ab4206ced595b50d2ac5fb4535b88}
      \strng{authorfullhash}{927ab4206ced595b50d2ac5fb4535b88}
      \strng{authorfullhashraw}{927ab4206ced595b50d2ac5fb4535b88}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Recommender systems represent user preferences for the purpose of suggesting items to purchase or examine. They have become fundamental applications in electronic commerce and information access, providing suggestions that effectively prune large information spaces so that users are directed toward those items that best meet their needs and preferences. A variety of techniques have been proposed for performing recommendation, including content-based, collaborative, knowledge-based and other techniques. To improve performance, these methods have sometimes been combined in hybrid recommenders. This paper surveys the landscape of actual and possible hybrid recommenders, and introduces a novel hybrid, EntreeC, a system that combines knowledge-based recommendation and collaborative filtering to recommend restaurants. Further, we show that semantic ratings obtained from the knowledge-based part of the system enhance the effectiveness of collaborative filtering.}
      \field{issn}{1573-1391}
      \field{journaltitle}{User Modeling and User-Adapted Interaction}
      \field{month}{11}
      \field{number}{4}
      \field{title}{Hybrid Recommender Systems: Survey and Experiments}
      \field{volume}{12}
      \field{year}{2002}
      \field{pages}{331\bibrangedash 370}
      \range{pages}{40}
      \verb{doi}
      \verb 10.1023/A:1021240730564
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1023/A:1021240730564
      \endverb
      \verb{url}
      \verb https://doi.org/10.1023/A:1021240730564
      \endverb
    \endentry
    \entry{Dao2024}{article}{}{}
      \name{author}{2}{}{%
        {{hash=ede2395a7f566a456448fcb5f8222c99}{%
           family={Dao},
           familyi={D\bibinitperiod},
           given={Tri},
           giveni={T\bibinitperiod}}}%
        {{hash=aa9ec56190423bb01ead50d96b94ba93}{%
           family={Gu},
           familyi={G\bibinitperiod},
           given={Albert},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{eca4369e68a75e2b3a2aaedcb72727ca}
      \strng{fullhash}{eca4369e68a75e2b3a2aaedcb72727ca}
      \strng{fullhashraw}{eca4369e68a75e2b3a2aaedcb72727ca}
      \strng{bibnamehash}{eca4369e68a75e2b3a2aaedcb72727ca}
      \strng{authorbibnamehash}{eca4369e68a75e2b3a2aaedcb72727ca}
      \strng{authornamehash}{eca4369e68a75e2b3a2aaedcb72727ca}
      \strng{authorfullhash}{eca4369e68a75e2b3a2aaedcb72727ca}
      \strng{authorfullhashraw}{eca4369e68a75e2b3a2aaedcb72727ca}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We show that the dual forms of structured state space models (SSMs) and attention are closely related through a framework we call Structured State Space Duality (SSD). This allows us to design Mamba-2, an architecture that is 2-8x faster than Mamba while being competitive with Transformers.}
      \field{journaltitle}{arXiv preprint arXiv:2405.21060}
      \field{month}{5}
      \field{title}{Transformers are SSMs: Generalized Models and Efficient Algorithms Through Structured State Space Duality}
      \field{year}{2024}
      \verb{doi}
      \verb 10.48550/arXiv.2405.21060
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.48550/arXiv.2405.21060
      \endverb
      \verb{url}
      \verb https://doi.org/10.48550/arXiv.2405.21060
      \endverb
    \endentry
    \entry{Devlin2019}{misc}{}{}
      \name{author}{4}{}{%
        {{hash=13202969e372bc82318f9629cbdd199b}{%
           family={Devlin},
           familyi={D\bibinitperiod},
           given={Jacob},
           giveni={J\bibinitperiod}}}%
        {{hash=a45784fe7163b45f11d166564f5d24b6}{%
           family={Chang},
           familyi={C\bibinitperiod},
           given={Ming-Wei},
           giveni={M\bibinithyphendelim W\bibinitperiod}}}%
        {{hash=8dde73b4194f5bc4230c4808f3fc1534}{%
           family={Lee},
           familyi={L\bibinitperiod},
           given={Kenton},
           giveni={K\bibinitperiod}}}%
        {{hash=b92aa283415413bb8d2a1548716d0c7d}{%
           family={Toutanova},
           familyi={T\bibinitperiod},
           given={Kristina},
           giveni={K\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Association for Computational Linguistics}%
      }
      \strng{namehash}{ad8e2e2a80d28ade21e86852b804fc9b}
      \strng{fullhash}{e8bccd48302a14eeba57d9dce2f49ef4}
      \strng{fullhashraw}{e8bccd48302a14eeba57d9dce2f49ef4}
      \strng{bibnamehash}{e8bccd48302a14eeba57d9dce2f49ef4}
      \strng{authorbibnamehash}{e8bccd48302a14eeba57d9dce2f49ef4}
      \strng{authornamehash}{ad8e2e2a80d28ade21e86852b804fc9b}
      \strng{authorfullhash}{e8bccd48302a14eeba57d9dce2f49ef4}
      \strng{authorfullhashraw}{e8bccd48302a14eeba57d9dce2f49ef4}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).}
      \field{month}{6}
      \field{note}{Minneapolis, Minnesota}
      \field{title}{BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}
      \field{year}{2019}
      \field{pages}{4171\bibrangedash 4186}
      \range{pages}{16}
      \verb{doi}
      \verb 10.18653/v1/N19-1423
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.18653/v1/N19-1423
      \endverb
      \verb{url}
      \verb https://doi.org/10.18653/v1/N19-1423
      \endverb
    \endentry
    \entry{Fan2025}{article}{}{}
      \name{author}{7}{}{%
        {{hash=7cd75a80763049dc65103e70f07a163c}{%
           family={Fan},
           familyi={F\bibinitperiod},
           given={Hao},
           giveni={H\bibinitperiod}}}%
        {{hash=097665838de07a31807f5d052ec4518f}{%
           family={Zhu},
           familyi={Z\bibinitperiod},
           given={Mengyi},
           giveni={M\bibinitperiod}}}%
        {{hash=f2718878580532cc28d8cdebf1b4ca4d}{%
           family={Hu},
           familyi={H\bibinitperiod},
           given={Yanrong},
           giveni={Y\bibinitperiod}}}%
        {{hash=bda5f402c444e5b837eca0ee3ba10cbf}{%
           family={Feng},
           familyi={F\bibinitperiod},
           given={Hailin},
           giveni={H\bibinitperiod}}}%
        {{hash=e8fd8a6cd3b26ea56c3a122f1388c8e5}{%
           family={He},
           familyi={H\bibinitperiod},
           given={Zhijie},
           giveni={Z\bibinitperiod}}}%
        {{hash=7d2cca69a4d57d5dcbb417774e03b2a9}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Hongjiu},
           giveni={H\bibinitperiod}}}%
        {{hash=94c3e5cee0046aaf2183f2b689a63a4c}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Qingyang},
           giveni={Q\bibinitperiod}}}%
      }
      \strng{namehash}{a08a989b58f6278be90bc051c85a0f3a}
      \strng{fullhash}{2ab98bd978bf76ad25a36528a4789d62}
      \strng{fullhashraw}{2ab98bd978bf76ad25a36528a4789d62}
      \strng{bibnamehash}{2ab98bd978bf76ad25a36528a4789d62}
      \strng{authorbibnamehash}{2ab98bd978bf76ad25a36528a4789d62}
      \strng{authornamehash}{a08a989b58f6278be90bc051c85a0f3a}
      \strng{authorfullhash}{2ab98bd978bf76ad25a36528a4789d62}
      \strng{authorfullhashraw}{2ab98bd978bf76ad25a36528a4789d62}
      \field{extraname}{1}
      \field{sortinit}{F}
      \field{sortinithash}{2638baaa20439f1b5a8f80c6c08a13b4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The modeling paradigm of sequential recommendation is shifting from Transformer to Mamba, including Mamba1, based on the State Space Model (SSM), and Mamba2, based on State Space Duality (SSD). While SSD achieves higher computational efficiency, it faces performance degradation in low-dimensional scenarios which is crucial for sequential recommendation tasks. Considering that time-aware enhancement methods are commonly employed to mitigate performance loss, our analysis reveals that the performance decline of SSD can similarly be fundamentally compensated by leveraging mechanisms in time-aware methods. To overcome challenges in adapting existing time-aware methods like TiSASRec, such as compatibility with SSD and computational inefficiencies in time-difference modeling, we propose Time-Aware Mamba for Recommendation (TiM4Rec), which integrates a novel Time-aware Structured Masked Matrix into SSD to enhance performance while improving efficiency. Extensive experiments on four real-world datasets demonstrate its superiority, marking the first time-aware method tailored to Mamba for sequential recommendation. The code for our model is accessible at https://github.com/AlwaysFHao/TiM4Rec.}
      \field{issn}{0925-2312}
      \field{journaltitle}{Neurocomputing}
      \field{month}{11}
      \field{title}{TiM4Rec: An efficient sequential recommendation model based on time-aware structured state space duality model}
      \field{volume}{654}
      \field{year}{2025}
      \field{pages}{131270}
      \range{pages}{1}
      \verb{doi}
      \verb 10.1016/j.neucom.2025.131270
      \endverb
      \verb{urlraw}
      \verb https://www.sciencedirect.com/science/article/pii/S0925231225019423
      \endverb
      \verb{url}
      \verb https://www.sciencedirect.com/science/article/pii/S0925231225019423
      \endverb
      \keyw{Sequential recommendation; State space model (SSM); State space duality (SSD); Mamba; Time-awareness}
    \endentry
    \entry{Fan2019}{misc}{}{}
      \name{author}{7}{}{%
        {{hash=c962fa5377a09410d9645db6e5704558}{%
           family={Fan},
           familyi={F\bibinitperiod},
           given={Wenqi},
           giveni={W\bibinitperiod}}}%
        {{hash=b9495c8a5a2c9489e8af928b6f0eed6b}{%
           family={Ma},
           familyi={M\bibinitperiod},
           given={Yao},
           giveni={Y\bibinitperiod}}}%
        {{hash=16a77262afb7cc9b0229c21f168bd098}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Qing},
           giveni={Q\bibinitperiod}}}%
        {{hash=bcd84142f4f61ad0c884a49e5688c6fa}{%
           family={He},
           familyi={H\bibinitperiod},
           given={Yuan},
           giveni={Y\bibinitperiod}}}%
        {{hash=6c876310822725ae4936f8c79aedc716}{%
           family={Zhao},
           familyi={Z\bibinitperiod},
           given={Eric},
           giveni={E\bibinitperiod}}}%
        {{hash=854278958e1021c53ca312cc8316e2a6}{%
           family={Tang},
           familyi={T\bibinitperiod},
           given={Jiliang},
           giveni={J\bibinitperiod}}}%
        {{hash=866fc31d9db55acbc0a55c2b3c929414}{%
           family={Yin},
           familyi={Y\bibinitperiod},
           given={Dawei},
           giveni={D\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{eb25007ac5b5dcfb3bbc997db67f5ab4}
      \strng{fullhash}{9a47c531d96e3f331a21b1573bd1cefe}
      \strng{fullhashraw}{9a47c531d96e3f331a21b1573bd1cefe}
      \strng{bibnamehash}{9a47c531d96e3f331a21b1573bd1cefe}
      \strng{authorbibnamehash}{9a47c531d96e3f331a21b1573bd1cefe}
      \strng{authornamehash}{eb25007ac5b5dcfb3bbc997db67f5ab4}
      \strng{authorfullhash}{9a47c531d96e3f331a21b1573bd1cefe}
      \strng{authorfullhashraw}{9a47c531d96e3f331a21b1573bd1cefe}
      \field{extraname}{2}
      \field{sortinit}{F}
      \field{sortinithash}{2638baaa20439f1b5a8f80c6c08a13b4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In recent years, Graph Neural Networks (GNNs), which can naturally integrate node information and topological structure, have been demonstrated to be powerful in learning on graph data. These advantages of GNNs provide great potential to advance social recommendation since data in social recommender systems can be represented as user-user social graph and user-item graph; and learning latent factors of users and items is the key. However, building social recommender systems based on GNNs faces challenges. For example, the user-item graph encodes both interactions and their associated opinions; social relations have heterogeneous strengths; users involve in two graphs (e.g., the user-user social graph and the user-item graph). To address the three aforementioned challenges simultaneously, in this paper, we present a novel graph neural network framework (GraphRec) for social recommendations. In particular, we provide a principled approach to jointly capture interactions and opinions in the user-item graph and propose the framework GraphRec, which coherently models two graphs and heterogeneous strengths. Extensive experiments on two real-world datasets demonstrate the effectiveness of the proposed framework GraphRec.}
      \field{note}{New York, NY, USA}
      \field{title}{Graph Neural Networks for Social Recommendation}
      \field{year}{2019}
      \field{pages}{417\bibrangedash 426}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1145/3308558.3313488
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3308558.3313488
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3308558.3313488
      \endverb
      \keyw{Social Recommendation,Social Network,Recommender Systems,Neural Networks,Graph Neural Networks}
    \endentry
    \entry{Geng2022}{misc}{}{}
      \name{author}{5}{}{%
        {{hash=6b08640f38e5ddc30b8bb80b6b0e0307}{%
           family={Geng},
           familyi={G\bibinitperiod},
           given={Shijie},
           giveni={S\bibinitperiod}}}%
        {{hash=447bc9b54e6ffe1e87d95cfaa583f6cf}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Shuchang},
           giveni={S\bibinitperiod}}}%
        {{hash=cc1eaf6f9f7f306fe14c70aab776f1d5}{%
           family={Fu},
           familyi={F\bibinitperiod},
           given={Zuohui},
           giveni={Z\bibinitperiod}}}%
        {{hash=da28b729cdffa08e807a83178fe130c7}{%
           family={Ge},
           familyi={G\bibinitperiod},
           given={Yingqiang},
           giveni={Y\bibinitperiod}}}%
        {{hash=fd8216a36735a9f3107aef444551ecb2}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Yongfeng},
           giveni={Y\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{84adc253e39f3007678aefe3cfd3a824}
      \strng{fullhash}{d02cf534a3d45828d42edff705bcaf4b}
      \strng{fullhashraw}{d02cf534a3d45828d42edff705bcaf4b}
      \strng{bibnamehash}{d02cf534a3d45828d42edff705bcaf4b}
      \strng{authorbibnamehash}{d02cf534a3d45828d42edff705bcaf4b}
      \strng{authornamehash}{84adc253e39f3007678aefe3cfd3a824}
      \strng{authorfullhash}{d02cf534a3d45828d42edff705bcaf4b}
      \strng{authorfullhashraw}{d02cf534a3d45828d42edff705bcaf4b}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{For a long time, different recommendation tasks require designing task-specific architectures and training objectives. As a result, it is hard to transfer the knowledge and representations from one task to another, thus restricting the generalization ability of existing recommendation approaches. To deal with such issues, considering that language can describe almost anything and language grounding is a powerful medium to represent various problems or tasks, we present a flexible and unified text-to-text paradigm called ``Pretrain, Personalized Prompt, and Predict Paradigm'' (P5) for recommendation, which unifies various recommendation tasks in a shared framework. In P5, all data such as user-item interactions, user descriptions, item metadata, and user reviews are converted to a common format --- natural language sequences. The rich information from natural language assists P5 to capture deeper semantics for personalization and recommendation. Specifically, P5 learns different tasks with the same language modeling objective during pretraining. Thus, it serves as the foundation model for various downstream recommendation tasks, allows easy integration with other modalities, and enables instruction-based recommendation. P5 advances recommender systems from shallow model to deep model to big model, and will revolutionize the technical form of recommender systems towards universal recommendation engine. With adaptive personalized prompt for different users, P5 is able to make predictions in a zero-shot or few-shot manner and largely reduces the necessity for extensive fine-tuning. On several benchmarks, we conduct experiments to show the effectiveness of P5. To help advance future research on Recommendation as Language Processing (RLP), Personalized Foundation Models (PFM), and Universal Recommendation Engine (URE), we release the source code, dataset, prompts, and pretrained P5 model at https://github.com/jeykigung/P5.}
      \field{note}{New York, NY, USA}
      \field{title}{Recommendation as Language Processing (RLP): A Unified Pretrain, Personalized Prompt {\&} Predict Paradigm (P5)}
      \field{year}{2022}
      \field{pages}{299\bibrangedash 315}
      \range{pages}{17}
      \verb{doi}
      \verb 10.1145/3523227.3546767
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3523227.3546767
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3523227.3546767
      \endverb
      \keyw{Language Modeling,Multitask Learning,Natural Language Processing,Personalized Prompt,Recommender Systems,Unified Model}
    \endentry
    \entry{Gu2023}{article}{}{}
      \name{author}{2}{}{%
        {{hash=aa9ec56190423bb01ead50d96b94ba93}{%
           family={Gu},
           familyi={G\bibinitperiod},
           given={Albert},
           giveni={A\bibinitperiod}}}%
        {{hash=ede2395a7f566a456448fcb5f8222c99}{%
           family={Dao},
           familyi={D\bibinitperiod},
           given={Tri},
           giveni={T\bibinitperiod}}}%
      }
      \strng{namehash}{babde771e7de935487275312d2f755a5}
      \strng{fullhash}{babde771e7de935487275312d2f755a5}
      \strng{fullhashraw}{babde771e7de935487275312d2f755a5}
      \strng{bibnamehash}{babde771e7de935487275312d2f755a5}
      \strng{authorbibnamehash}{babde771e7de935487275312d2f755a5}
      \strng{authornamehash}{babde771e7de935487275312d2f755a5}
      \strng{authorfullhash}{babde771e7de935487275312d2f755a5}
      \strng{authorfullhashraw}{babde771e7de935487275312d2f755a5}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Foundation models, now powering most of the exciting applications in deep learning, are almost universally based on the Transformer architecture and its core attention module. We propose a new class of selective state space models (SSMs) that improves on prior work on several axes to achieve the modeling power of Transformers while scaling linearly in sequence length.}
      \field{journaltitle}{arXiv preprint arXiv:2312.00752}
      \field{month}{12}
      \field{title}{Mamba: Linear-Time Sequence Modeling with Selective State Spaces}
      \field{year}{2023}
      \verb{doi}
      \verb 10.48550/arXiv.2312.00752
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.48550/arXiv.2312.00752
      \endverb
      \verb{url}
      \verb https://doi.org/10.48550/arXiv.2312.00752
      \endverb
    \endentry
    \entry{Gu2022}{inproceedings}{}{}
      \name{author}{3}{}{%
        {{hash=aa9ec56190423bb01ead50d96b94ba93}{%
           family={Gu},
           familyi={G\bibinitperiod},
           given={Albert},
           giveni={A\bibinitperiod}}}%
        {{hash=b28818adf394a54c714e3a5c8313377e}{%
           family={Goel},
           familyi={G\bibinitperiod},
           given={Karan},
           giveni={K\bibinitperiod}}}%
        {{hash=eb1f5a2ba08ea12db36c871fe601f5f1}{%
           family={RÃ©},
           familyi={R\bibinitperiod},
           given={Christopher},
           giveni={C\bibinitperiod}}}%
      }
      \strng{namehash}{7f1105c096dcd1290eba6a5a667b32d3}
      \strng{fullhash}{7f1105c096dcd1290eba6a5a667b32d3}
      \strng{fullhashraw}{7f1105c096dcd1290eba6a5a667b32d3}
      \strng{bibnamehash}{7f1105c096dcd1290eba6a5a667b32d3}
      \strng{authorbibnamehash}{7f1105c096dcd1290eba6a5a667b32d3}
      \strng{authornamehash}{7f1105c096dcd1290eba6a5a667b32d3}
      \strng{authorfullhash}{7f1105c096dcd1290eba6a5a667b32d3}
      \strng{authorfullhashraw}{7f1105c096dcd1290eba6a5a667b32d3}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We propose the Structured State Space sequence model (S4) based on a new parameterization for the SSM, and show that it can be computed much more efficiently than prior approaches while preserving their theoretical strengths. S4 achieves strong empirical results across a diverse range of benchmarks, including significantly outperforming Transformers on long-range tasks.}
      \field{note}{International Conference on Learning Representations (ICLR)}
      \field{title}{Efficiently Modeling Long Sequences with Structured State Spaces}
      \field{year}{2022}
      \verb{doi}
      \verb 10.48550/arXiv.2111.00396
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.48550/arXiv.2111.00396
      \endverb
      \verb{url}
      \verb https://doi.org/10.48550/arXiv.2111.00396
      \endverb
    \endentry
    \entry{He2020}{misc}{}{}
      \name{author}{6}{}{%
        {{hash=cf3f1b6bfe8e9131a8c719c1af0dce5d}{%
           family={He},
           familyi={H\bibinitperiod},
           given={Xiangnan},
           giveni={X\bibinitperiod}}}%
        {{hash=fd3bea1dc164ea80fae7f6718b3bc874}{%
           family={Deng},
           familyi={D\bibinitperiod},
           given={Kuan},
           giveni={K\bibinitperiod}}}%
        {{hash=8fde8559617f603b3e2b3cf30cb48e9b}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Xiang},
           giveni={X\bibinitperiod}}}%
        {{hash=92e14a8c19eb5a0c7c199c85db74f106}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Yan},
           giveni={Y\bibinitperiod}}}%
        {{hash=b20f786926022139bb630b378300fe36}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Yongdong},
           giveni={Y\bibinitperiod}}}%
        {{hash=00b734eb3fb588e4c6c94e4271080d0b}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Meng},
           giveni={M\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{5288584512ef6ddfdb0f4e97d3bced50}
      \strng{fullhash}{2af67127bcbe8e1d217d8ffeaee94eae}
      \strng{fullhashraw}{2af67127bcbe8e1d217d8ffeaee94eae}
      \strng{bibnamehash}{2af67127bcbe8e1d217d8ffeaee94eae}
      \strng{authorbibnamehash}{2af67127bcbe8e1d217d8ffeaee94eae}
      \strng{authornamehash}{5288584512ef6ddfdb0f4e97d3bced50}
      \strng{authorfullhash}{2af67127bcbe8e1d217d8ffeaee94eae}
      \strng{authorfullhashraw}{2af67127bcbe8e1d217d8ffeaee94eae}
      \field{extraname}{1}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Graph Convolution Network (GCN) has become new state-of-the-art for collaborative filtering. Nevertheless, the reasons of its effectiveness for recommendation are not well understood. Existing work that adapts GCN to recommendation lacks thorough ablation analyses on GCN, which is originally designed for graph classification tasks and equipped with many neural network operations. However, we empirically find that the two most common designs in GCNs -- feature transformation and nonlinear activation -- contribute little to the performance of collaborative filtering. Even worse, including them adds to the difficulty of training and degrades recommendation performance.In this work, we aim to simplify the design of GCN to make it more concise and appropriate for recommendation. We propose a new model named LightGCN, including only the most essential component in GCN -- neighborhood aggregation -- for collaborative filtering. Specifically, LightGCN learns user and item embeddings by linearly propagating them on the user-item interaction graph, and uses the weighted sum of the embeddings learned at all layers as the final embedding. Such simple, linear, and neat model is much easier to implement and train, exhibiting substantial improvements (about 16.0{\%} relative improvement on average) over Neural Graph Collaborative Filtering (NGCF) -- a state-of-the-art GCN-based recommender model -- under exactly the same experimental setting. Further analyses are provided towards the rationality of the simple LightGCN from both analytical and empirical perspectives.}
      \field{note}{New York, NY, USA}
      \field{title}{LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation}
      \field{year}{2020}
      \field{pages}{639\bibrangedash 648}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1145/3397271.3401063
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3397271.3401063
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3397271.3401063
      \endverb
      \keyw{recommendation,graph neural network,embedding propagation,collaborative filtering}
    \endentry
    \entry{He2017}{misc}{}{}
      \name{author}{6}{}{%
        {{hash=cf3f1b6bfe8e9131a8c719c1af0dce5d}{%
           family={He},
           familyi={H\bibinitperiod},
           given={Xiangnan},
           giveni={X\bibinitperiod}}}%
        {{hash=98c2b47a69b228e811390ee98c8d81f4}{%
           family={Liao},
           familyi={L\bibinitperiod},
           given={Lizi},
           giveni={L\bibinitperiod}}}%
        {{hash=6f410a596e335c299e3550a4e9990bb4}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Hanwang},
           giveni={H\bibinitperiod}}}%
        {{hash=bc7884a5203c192ab9125f81d18db97d}{%
           family={Nie},
           familyi={N\bibinitperiod},
           given={Liqiang},
           giveni={L\bibinitperiod}}}%
        {{hash=13be76d254e7c2f65cfc92bc75bb18fd}{%
           family={Hu},
           familyi={H\bibinitperiod},
           given={Xia},
           giveni={X\bibinitperiod}}}%
        {{hash=57e4257ea3484acff91be2a3df96d16b}{%
           family={Chua},
           familyi={C\bibinitperiod},
           given={Tat-Seng},
           giveni={T\bibinithyphendelim S\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {International World Wide Web Conferences Steering Committee}%
      }
      \strng{namehash}{5288584512ef6ddfdb0f4e97d3bced50}
      \strng{fullhash}{9ae5af45ea1e621baea878b357a6a477}
      \strng{fullhashraw}{9ae5af45ea1e621baea878b357a6a477}
      \strng{bibnamehash}{9ae5af45ea1e621baea878b357a6a477}
      \strng{authorbibnamehash}{9ae5af45ea1e621baea878b357a6a477}
      \strng{authornamehash}{5288584512ef6ddfdb0f4e97d3bced50}
      \strng{authorfullhash}{9ae5af45ea1e621baea878b357a6a477}
      \strng{authorfullhashraw}{9ae5af45ea1e621baea878b357a6a477}
      \field{extraname}{2}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In recent years, deep neural networks have yielded immense success on speech recognition, computer vision and natural language processing. However, the exploration of deep neural networks on recommender systems has received relatively less scrutiny. In this work, we strive to develop techniques based on neural networks to tackle the key problem in recommendation --- collaborative filtering --- on the basis of implicit feedback.Although some recent work has employed deep learning for recommendation, they primarily used it to model auxiliary information, such as textual descriptions of items and acoustic features of musics. When it comes to model the key factor in collaborative filtering --- the interaction between user and item features, they still resorted to matrix factorization and applied an inner product on the latent features of users and items.By replacing the inner product with a neural architecture that can learn an arbitrary function from data, we present a general framework named NCF, short for Neural network-based Collaborative Filtering. NCF is generic and can express and generalize matrix factorization under its framework. To supercharge NCF modelling with non-linearities, we propose to leverage a multi-layer perceptron to learn the user-item interaction function. Extensive experiments on two real-world datasets show significant improvements of our proposed NCF framework over the state-of-the-art methods. Empirical evidence shows that using deeper layers of neural networks offers better recommendation performance.}
      \field{note}{Republic and Canton of Geneva, CHE}
      \field{title}{Neural Collaborative Filtering}
      \field{year}{2017}
      \field{pages}{173\bibrangedash 182}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1145/3038912.3052569
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3038912.3052569
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3038912.3052569
      \endverb
      \keyw{collaborative filtering,deep learning,implicit feedback,matrix factorization,neural networks}
    \endentry
    \entry{Hidaka2023}{article}{}{}
      \name{author}{1}{}{%
        {{hash=495d2f2869642b7ef90746ec556e4219}{%
           family={Hidaka},
           familyi={H\bibinitperiod},
           given={Kazuyoshi},
           giveni={K\bibinitperiod}}}%
      }
      \strng{namehash}{495d2f2869642b7ef90746ec556e4219}
      \strng{fullhash}{495d2f2869642b7ef90746ec556e4219}
      \strng{fullhashraw}{495d2f2869642b7ef90746ec556e4219}
      \strng{bibnamehash}{495d2f2869642b7ef90746ec556e4219}
      \strng{authorbibnamehash}{495d2f2869642b7ef90746ec556e4219}
      \strng{authornamehash}{495d2f2869642b7ef90746ec556e4219}
      \strng{authorfullhash}{495d2f2869642b7ef90746ec556e4219}
      \strng{authorfullhashraw}{495d2f2869642b7ef90746ec556e4219}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{User Modeling and User-Adapted Interaction}
      \field{month}{11}
      \field{title}{What influences users to provide explicit feedback? A case of food delivery recommenders}
      \field{volume}{34}
      \field{year}{2023}
      \field{pages}{1\bibrangedash 44}
      \range{pages}{44}
      \verb{doi}
      \verb 10.1007/s11257-023-09385-8
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1007/s11257-023-09385-8
      \endverb
      \verb{url}
      \verb https://doi.org/10.1007/s11257-023-09385-8
      \endverb
    \endentry
    \entry{Hidasi2016}{inproceedings}{}{}
      \name{author}{4}{}{%
        {{hash=d4112ec4c80058ecfac126d297274575}{%
           family={Hidasi},
           familyi={H\bibinitperiod},
           given={BalÃ¡zs},
           giveni={B\bibinitperiod}}}%
        {{hash=34b0daf756776ac58e5af9a2b2cdb9ee}{%
           family={Karatzoglou},
           familyi={K\bibinitperiod},
           given={Alexandros},
           giveni={A\bibinitperiod}}}%
        {{hash=0ef7dd2efd526493951ed30120da31b6}{%
           family={Baltrunas},
           familyi={B\bibinitperiod},
           given={Linas},
           giveni={L\bibinitperiod}}}%
        {{hash=6d5ddc893f18f66ca697835a97c7740d}{%
           family={Tikk},
           familyi={T\bibinitperiod},
           given={Domonkos},
           giveni={D\bibinitperiod}}}%
      }
      \strng{namehash}{0c81c42a7c75d29ce161fcdb87b58c17}
      \strng{fullhash}{d28f6e671010d7448170f1ba9a71dc03}
      \strng{fullhashraw}{d28f6e671010d7448170f1ba9a71dc03}
      \strng{bibnamehash}{d28f6e671010d7448170f1ba9a71dc03}
      \strng{authorbibnamehash}{d28f6e671010d7448170f1ba9a71dc03}
      \strng{authornamehash}{0c81c42a7c75d29ce161fcdb87b58c17}
      \strng{authorfullhash}{d28f6e671010d7448170f1ba9a71dc03}
      \strng{authorfullhashraw}{d28f6e671010d7448170f1ba9a71dc03}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{4th International Conference on Learning Representations (ICLR 2016)}
      \field{title}{Session-based Recommendations with Recurrent Neural Networks}
      \field{year}{2016}
      \verb{doi}
      \verb 10.48550/arXiv.1511.06939
      \endverb
      \verb{urlraw}
      \verb https://hidasi.eu/assets/pdf/gru4rec_iclr16.pdf
      \endverb
      \verb{url}
      \verb https://hidasi.eu/assets/pdf/gru4rec_iclr16.pdf
      \endverb
    \endentry
    \entry{Hou2022_UniSRec}{misc}{}{}
      \name{author}{6}{}{%
        {{hash=678f15f5b4dbc1aaed429148209c1670}{%
           family={Hou},
           familyi={H\bibinitperiod},
           given={Yupeng},
           giveni={Y\bibinitperiod}}}%
        {{hash=55527a8999c371fb65ed61a6f30d3f68}{%
           family={Mu},
           familyi={M\bibinitperiod},
           given={Shanlei},
           giveni={S\bibinitperiod}}}%
        {{hash=64942cca497eff6cd6c5b264afdc5dd6}{%
           family={Zhao},
           familyi={Z\bibinitperiod},
           given={Wayne\bibnamedelima Xin},
           giveni={W\bibinitperiod\bibinitdelim X\bibinitperiod}}}%
        {{hash=c4b43451450d2631465d73b9dc65d89d}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Yaliang},
           giveni={Y\bibinitperiod}}}%
        {{hash=a4189394f9ccf96207d091dd64e3fd2d}{%
           family={Ding},
           familyi={D\bibinitperiod},
           given={Bolin},
           giveni={B\bibinitperiod}}}%
        {{hash=5ff29ba5ea8e6fdd73a84f998eec45f2}{%
           family={Wen},
           familyi={W\bibinitperiod},
           given={Ji-Rong},
           giveni={J\bibinithyphendelim R\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{a5c785c5aae3329f78e6c16599574094}
      \strng{fullhash}{7cddadab4df0a5271d04559861313a7f}
      \strng{fullhashraw}{7cddadab4df0a5271d04559861313a7f}
      \strng{bibnamehash}{7cddadab4df0a5271d04559861313a7f}
      \strng{authorbibnamehash}{7cddadab4df0a5271d04559861313a7f}
      \strng{authornamehash}{a5c785c5aae3329f78e6c16599574094}
      \strng{authorfullhash}{7cddadab4df0a5271d04559861313a7f}
      \strng{authorfullhashraw}{7cddadab4df0a5271d04559861313a7f}
      \field{extraname}{1}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In order to develop effective sequential recommenders, a series of sequence representation learning (SRL) methods are proposed to model historical user behaviors. Most existing SRL methods rely on explicit item IDs for developing the sequence models to better capture user preference. Though effective to some extent, these methods are difficult to be transferred to new recommendation scenarios, due to the limitation by explicitly modeling item IDs. To tackle this issue, we present a novel universal sequence representation learning approach, named UniSRec. The proposed approach utilizes the associated description text of items to learn transferable representations across different recommendation scenarios. For learning universal item representations, we design a lightweight item encoding architecture based on parametric whitening and mixture-of-experts enhanced adaptor. For learning universal sequence representations, we introduce two contrastive pre-training tasks by sampling multi-domain negatives. With the pre-trained universal sequence representation model, our approach can be effectively transferred to new recommendation domains or platforms in a parameter-efficient way, under either inductive or transductive settings. Extensive experiments conducted on real-world datasets demonstrate the effectiveness of the proposed approach. Especially, our approach also leads to a performance improvement in a cross-platform setting, showing the strong transferability of the proposed universal SRL method. The code and pre-trained model are available at: https://github.com/RUCAIBox/UniSRec.}
      \field{note}{New York, NY, USA}
      \field{title}{Towards Universal Sequence Representation Learning for Recommender Systems}
      \field{year}{2022}
      \field{pages}{585\bibrangedash 593}
      \range{pages}{9}
      \verb{doi}
      \verb 10.1145/3534678.3539381
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3534678.3539381
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3534678.3539381
      \endverb
      \keyw{sequential recommendation,universal representation learning}
    \endentry
    \entry{Hou2022}{misc}{}{}
      \name{author}{7}{}{%
        {{hash=e8adc1788926113d64ddd05706c390e1}{%
           family={Hou},
           familyi={H\bibinitperiod},
           given={Zhenyu},
           giveni={Z\bibinitperiod}}}%
        {{hash=dd8304255c910bcbd7d7d0cb4f7ed860}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Xiao},
           giveni={X\bibinitperiod}}}%
        {{hash=b7ab9e18cfb8215361c51c41301f4cba}{%
           family={Cen},
           familyi={C\bibinitperiod},
           given={Yukuo},
           giveni={Y\bibinitperiod}}}%
        {{hash=5fd8ccf894ae8131d46d95e71572ffae}{%
           family={Dong},
           familyi={D\bibinitperiod},
           given={Yuxiao},
           giveni={Y\bibinitperiod}}}%
        {{hash=d6d4a344c3ae687de4e4e9f6be05c6ed}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Hongxia},
           giveni={H\bibinitperiod}}}%
        {{hash=655fcd62c04bdc7006d47bb7712c197e}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Chunjie},
           giveni={C\bibinitperiod}}}%
        {{hash=d0b3008e85b1a8b38f46556abf1791c7}{%
           family={Tang},
           familyi={T\bibinitperiod},
           given={Jie},
           giveni={J\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{4ab9433ff4846609f57739bd47d3e0aa}
      \strng{fullhash}{9897334b589c8b5a7ca40be5c91222d9}
      \strng{fullhashraw}{9897334b589c8b5a7ca40be5c91222d9}
      \strng{bibnamehash}{9897334b589c8b5a7ca40be5c91222d9}
      \strng{authorbibnamehash}{9897334b589c8b5a7ca40be5c91222d9}
      \strng{authornamehash}{4ab9433ff4846609f57739bd47d3e0aa}
      \strng{authorfullhash}{9897334b589c8b5a7ca40be5c91222d9}
      \strng{authorfullhashraw}{9897334b589c8b5a7ca40be5c91222d9}
      \field{extraname}{2}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Self-supervised learning (SSL) has been extensively explored in recent years. Particularly, generative SSL has seen emerging success in natural language processing and other fields, such as the wide adoption of BERT and GPT. Despite this, contrastive learning---which heavily relies on structural data augmentation and complicated training strategies---has been the dominant approach in graph SSL, while the progress of generative SSL on graphs, especially graph autoencoders (GAEs), has thus far not reached the potential as promised in other fields. In this paper, we identify and examine the issues that negatively impact the development of GAEs, including their reconstruction objective, training robustness, and error metric. We present a masked graph autoencoder GraphMAE (code is publicly available at https://github.com/THUDM/GraphMAE) that mitigates these issues for generative self-supervised graph learning. Instead of reconstructing structures, we propose to focus on feature reconstruction with both a masking strategy and scaled cosine error that benefit the robust training of GraphMAE. We conduct extensive experiments on 21 public datasets for three different graph learning tasks. The results manifest that GraphMAE---a simple graph autoencoder with our careful designs---can consistently generate outperformance over both contrastive and generative state-of-the-art baselines. This study provides an understanding of graph autoencoders and demonstrates the potential of generative self-supervised learning on graphs.}
      \field{note}{New York, NY, USA}
      \field{title}{GraphMAE: Self-Supervised Masked Graph Autoencoders}
      \field{year}{2022}
      \field{pages}{594\bibrangedash 604}
      \range{pages}{11}
      \verb{doi}
      \verb 10.1145/3534678.3539321
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3534678.3539321
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3534678.3539321
      \endverb
      \keyw{graph neural networks,graph representation learning,self-supervised learning}
    \endentry
    \entry{Hu2022}{inproceedings}{}{}
      \name{author}{8}{}{%
        {{hash=e6a95d07b8ae7f14e4eb777c6980a059}{%
           family={Hu},
           familyi={H\bibinitperiod},
           given={Edward\bibnamedelima J.},
           giveni={E\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=1701c0f05662e92cf52cfc8c16437496}{%
           family={Shen},
           familyi={S\bibinitperiod},
           given={Yelong},
           giveni={Y\bibinitperiod}}}%
        {{hash=ab0fdbc1586103dda7ac5e0852e5b2c3}{%
           family={Wallis},
           familyi={W\bibinitperiod},
           given={Phillip},
           giveni={P\bibinitperiod}}}%
        {{hash=eaa5cc98b7f19b4ce07c832213a13b9d}{%
           family={Allen-Zhu},
           familyi={A\bibinithyphendelim Z\bibinitperiod},
           given={Zeyuan},
           giveni={Z\bibinitperiod}}}%
        {{hash=0d2c91b24f885b22d373a892a768abc8}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Yuanzhi},
           giveni={Y\bibinitperiod}}}%
        {{hash=b654b88ecd4c3ff1ea29da275bce701c}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Shean},
           giveni={S\bibinitperiod}}}%
        {{hash=55f210233ac686af68eba11a97bd84e2}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Lu},
           giveni={L\bibinitperiod}}}%
        {{hash=05d71a9c5e7ac79222e01a55af0ccb93}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Weizhu},
           giveni={W\bibinitperiod}}}%
      }
      \strng{namehash}{d775178c34083951ab1e07df578582c3}
      \strng{fullhash}{08f4b49735d5d145be00bc9c07f38975}
      \strng{fullhashraw}{08f4b49735d5d145be00bc9c07f38975}
      \strng{bibnamehash}{08f4b49735d5d145be00bc9c07f38975}
      \strng{authorbibnamehash}{08f4b49735d5d145be00bc9c07f38975}
      \strng{authornamehash}{d775178c34083951ab1e07df578582c3}
      \strng{authorfullhash}{08f4b49735d5d145be00bc9c07f38975}
      \strng{authorfullhashraw}{08f4b49735d5d145be00bc9c07f38975}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We propose Low-Rank Adaptation, or LoRA, which freezes the pre-trained model weights and injects trainable rank decomposition matrices into each layer of the Transformer architecture, greatly reducing the number of trainable parameters for downstream tasks.}
      \field{note}{International Conference on Learning Representations (ICLR)}
      \field{title}{LoRA: Low-Rank Adaptation of Large Language Models}
      \field{year}{2022}
      \verb{doi}
      \verb 10.48550/arXiv.2106.09685
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.48550/arXiv.2106.09685
      \endverb
      \verb{url}
      \verb https://doi.org/10.48550/arXiv.2106.09685
      \endverb
    \endentry
    \entry{Hu2008}{inproceedings}{}{}
      \name{author}{3}{}{%
        {{hash=abca94954939cb7608a6fa0b712c8a57}{%
           family={Hu},
           familyi={H\bibinitperiod},
           given={Y.},
           giveni={Y\bibinitperiod}}}%
        {{hash=68e28d54204820006ff12df112baa4c7}{%
           family={Koren},
           familyi={K\bibinitperiod},
           given={Y.},
           giveni={Y\bibinitperiod}}}%
        {{hash=769a4c9e2ef003c79d4d043afbae7207}{%
           family={Volinsky},
           familyi={V\bibinitperiod},
           given={C.},
           giveni={C\bibinitperiod}}}%
      }
      \strng{namehash}{fbda603e3f25a6da384fcd453d873b60}
      \strng{fullhash}{fbda603e3f25a6da384fcd453d873b60}
      \strng{fullhashraw}{fbda603e3f25a6da384fcd453d873b60}
      \strng{bibnamehash}{fbda603e3f25a6da384fcd453d873b60}
      \strng{authorbibnamehash}{fbda603e3f25a6da384fcd453d873b60}
      \strng{authornamehash}{fbda603e3f25a6da384fcd453d873b60}
      \strng{authorfullhash}{fbda603e3f25a6da384fcd453d873b60}
      \strng{authorfullhashraw}{fbda603e3f25a6da384fcd453d873b60}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{2008 Eighth IEEE International Conference on Data Mining}
      \field{issn}{2374-8486}
      \field{series}{2008 Eighth IEEE International Conference on Data Mining}
      \field{title}{Collaborative Filtering for Implicit Feedback Datasets}
      \field{year}{2008}
      \field{pages}{263\bibrangedash 272}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1109/ICDM.2008.22
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1109/ICDM.2008.22
      \endverb
      \verb{url}
      \verb https://doi.org/10.1109/ICDM.2008.22
      \endverb
    \endentry
    \entry{Kang2018}{inproceedings}{}{}
      \name{author}{2}{}{%
        {{hash=448136e859bc7fdfe9759b68ef755fac}{%
           family={Kang},
           familyi={K\bibinitperiod},
           given={W.-C.},
           giveni={W\bibinithyphendelim C\bibinitperiod}}}%
        {{hash=6c0cef318259c395c73dde59a7de638a}{%
           family={McAuley},
           familyi={M\bibinitperiod},
           given={J.},
           giveni={J\bibinitperiod}}}%
      }
      \strng{namehash}{83f97903ac4e255600be2d90b9995f55}
      \strng{fullhash}{83f97903ac4e255600be2d90b9995f55}
      \strng{fullhashraw}{83f97903ac4e255600be2d90b9995f55}
      \strng{bibnamehash}{83f97903ac4e255600be2d90b9995f55}
      \strng{authorbibnamehash}{83f97903ac4e255600be2d90b9995f55}
      \strng{authornamehash}{83f97903ac4e255600be2d90b9995f55}
      \strng{authorfullhash}{83f97903ac4e255600be2d90b9995f55}
      \strng{authorfullhashraw}{83f97903ac4e255600be2d90b9995f55}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{2018 IEEE International Conference on Data Mining (ICDM)}
      \field{issn}{2374-8486}
      \field{series}{2018 IEEE International Conference on Data Mining (ICDM)}
      \field{title}{Self-Attentive Sequential Recommendation}
      \field{year}{2018}
      \field{pages}{197\bibrangedash 206}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1109/ICDM.2018.00035
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1109/ICDM.2018.00035
      \endverb
      \verb{url}
      \verb https://doi.org/10.1109/ICDM.2018.00035
      \endverb
    \endentry
    \entry{Kim2016}{misc}{}{}
      \name{author}{5}{}{%
        {{hash=69c67a7835bae411a48cf54967c18f39}{%
           family={Kim},
           familyi={K\bibinitperiod},
           given={Donghyun},
           giveni={D\bibinitperiod}}}%
        {{hash=84af495585109c80e6f31a58ac143fb8}{%
           family={Park},
           familyi={P\bibinitperiod},
           given={Chanyoung},
           giveni={C\bibinitperiod}}}%
        {{hash=3b62a95574b0bfbc6f2b2c474b82736f}{%
           family={Oh},
           familyi={O\bibinitperiod},
           given={Jinoh},
           giveni={J\bibinitperiod}}}%
        {{hash=13f4661b9173b2153aaa7862c5d12606}{%
           family={Lee},
           familyi={L\bibinitperiod},
           given={Sungyoung},
           giveni={S\bibinitperiod}}}%
        {{hash=b37db6da3bdae781164e763a40e11f22}{%
           family={Yu},
           familyi={Y\bibinitperiod},
           given={Hwanjo},
           giveni={H\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{6a19d2f9cfa31659b48d3d0cc2afd36c}
      \strng{fullhash}{0332126a271769d11fa7bb23bb455576}
      \strng{fullhashraw}{0332126a271769d11fa7bb23bb455576}
      \strng{bibnamehash}{0332126a271769d11fa7bb23bb455576}
      \strng{authorbibnamehash}{0332126a271769d11fa7bb23bb455576}
      \strng{authornamehash}{6a19d2f9cfa31659b48d3d0cc2afd36c}
      \strng{authorfullhash}{0332126a271769d11fa7bb23bb455576}
      \strng{authorfullhashraw}{0332126a271769d11fa7bb23bb455576}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Sparseness of user-to-item rating data is one of the major factors that deteriorate the quality of recommender system. To handle the sparsity problem, several recommendation techniques have been proposed that additionally consider auxiliary information to improve rating prediction accuracy. In particular, when rating data is sparse, document modeling-based approaches have improved the accuracy by additionally utilizing textual data such as reviews, abstracts, or synopses. However, due to the inherent limitation of the bag-of-words model, they have difficulties in effectively utilizing contextual information of the documents, which leads to shallow understanding of the documents. This paper proposes a novel context-aware recommendation model, convolutional matrix factorization (ConvMF) that integrates convolutional neural network (CNN) into probabilistic matrix factorization (PMF). Consequently, ConvMF captures contextual information of documents and further enhances the rating prediction accuracy. Our extensive evaluations on three real-world datasets show that ConvMF significantly outperforms the state-of-the-art recommendation models even when the rating data is extremely sparse. We also demonstrate that ConvMF successfully captures subtle contextual difference of a word in a document. Our implementation and datasets are available at http://dm.postech.ac.kr/ConvMF.}
      \field{note}{New York, NY, USA}
      \field{title}{Convolutional Matrix Factorization for Document Context-Aware Recommendation}
      \field{year}{2016}
      \field{pages}{233\bibrangedash 240}
      \range{pages}{8}
      \verb{doi}
      \verb 10.1145/2959100.2959165
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/2959100.2959165
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/2959100.2959165
      \endverb
      \keyw{collaborative filtering,contexual information,deep learning,document modeling,neural network' context-aware recommendation,recommender system}
    \endentry
    \entry{Ko2022}{misc}{}{}
      \name{author}{4}{}{%
        {{hash=e958161df21fe2f09b34a3a4431c8a64}{%
           family={Ko},
           familyi={K\bibinitperiod},
           given={Hyeyoung},
           giveni={H\bibinitperiod}}}%
        {{hash=e88863936b5ff8eacc26c8b73b6a8b1e}{%
           family={Lee},
           familyi={L\bibinitperiod},
           given={Suyeon},
           giveni={S\bibinitperiod}}}%
        {{hash=d7b764165b4cb81970998b3f6d9b0927}{%
           family={Park},
           familyi={P\bibinitperiod},
           given={Yoonseo},
           giveni={Y\bibinitperiod}}}%
        {{hash=e3208f125269cea6806f316b68984ecd}{%
           family={Choi},
           familyi={C\bibinitperiod},
           given={Anna},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{1707eda465fa19f77b11da661dc09d11}
      \strng{fullhash}{ad0f0b7c3900df8ac3035f7156b4cd5f}
      \strng{fullhashraw}{ad0f0b7c3900df8ac3035f7156b4cd5f}
      \strng{bibnamehash}{ad0f0b7c3900df8ac3035f7156b4cd5f}
      \strng{authorbibnamehash}{ad0f0b7c3900df8ac3035f7156b4cd5f}
      \strng{authornamehash}{1707eda465fa19f77b11da661dc09d11}
      \strng{authorfullhash}{ad0f0b7c3900df8ac3035f7156b4cd5f}
      \strng{authorfullhashraw}{ad0f0b7c3900df8ac3035f7156b4cd5f}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper reviews the research trends that link the advanced technical aspects of recommendation systems that are used in various service areas and the business aspects of these services. First, for a reliable analysis of recommendation models for recommendation systems, data mining technology, and related research by application service, more than 135 top-ranking articles and top-tier conferences published in Google Scholar between 2010 and 2021 were collected and reviewed. Based on this, studies on recommendation system models and the technology used in recommendation systems were systematized, and research trends by year were analyzed. In addition, the application service fields where recommendation systems were used were classified, and research on the recommendation system model and recommendation technique used in each field was analyzed. Furthermore, vast amounts of application service-related data used by recommendation systems were collected from 2010 to 2021 without taking the journal ranking into consideration and reviewed along with various recommendation system studies, as well as applied service field industry data. As a result of this study, it was found that the flow and quantitative growth of various detailed studies of recommendation systems interact with the business growth of the actual applied service field. While providing a comprehensive summary of recommendation systems, this study provides insight to many researchers interested in recommendation systems through the analysis of its various technologies and trends in the service field to which recommendation systems are applied.}
      \field{issn}{2079-9292}
      \field{number}{1}
      \field{title}{A Survey of Recommendation Systems: Recommendation Models, Techniques, and Application Fields}
      \field{volume}{11}
      \field{year}{2022}
      \field{pages}{141}
      \range{pages}{1}
      \verb{doi}
      \verb 10.3390/electronics11010141
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.3390/electronics11010141
      \endverb
      \verb{url}
      \verb https://doi.org/10.3390/electronics11010141
      \endverb
      \keyw{recommender system; recommendation system; content-based filtering; collaborative filtering; hybrid system; recommendation algorithm; recommendation technique}
    \endentry
    \entry{Koren2009}{article}{}{}
      \name{author}{3}{}{%
        {{hash=68e28d54204820006ff12df112baa4c7}{%
           family={Koren},
           familyi={K\bibinitperiod},
           given={Y.},
           giveni={Y\bibinitperiod}}}%
        {{hash=44e057bfb865c6e13190d32b773029dc}{%
           family={Bell},
           familyi={B\bibinitperiod},
           given={R.},
           giveni={R\bibinitperiod}}}%
        {{hash=769a4c9e2ef003c79d4d043afbae7207}{%
           family={Volinsky},
           familyi={V\bibinitperiod},
           given={C.},
           giveni={C\bibinitperiod}}}%
      }
      \strng{namehash}{0eb9645b39e5d42cf664197e5d0a7367}
      \strng{fullhash}{0eb9645b39e5d42cf664197e5d0a7367}
      \strng{fullhashraw}{0eb9645b39e5d42cf664197e5d0a7367}
      \strng{bibnamehash}{0eb9645b39e5d42cf664197e5d0a7367}
      \strng{authorbibnamehash}{0eb9645b39e5d42cf664197e5d0a7367}
      \strng{authornamehash}{0eb9645b39e5d42cf664197e5d0a7367}
      \strng{authorfullhash}{0eb9645b39e5d42cf664197e5d0a7367}
      \strng{authorfullhashraw}{0eb9645b39e5d42cf664197e5d0a7367}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{1558-0814}
      \field{journaltitle}{Computer}
      \field{number}{8}
      \field{title}{Matrix Factorization Techniques for Recommender Systems}
      \field{volume}{42}
      \field{year}{2009}
      \field{pages}{30\bibrangedash 37}
      \range{pages}{8}
      \verb{doi}
      \verb 10.1109/MC.2009.263
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1109/MC.2009.263
      \endverb
      \verb{url}
      \verb https://doi.org/10.1109/MC.2009.263
      \endverb
    \endentry
    \entry{Lin2025}{article}{}{}
      \name{author}{14}{}{%
        {{hash=6039a6bb1ffccf02aa613e777c63e951}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Jianghao},
           giveni={J\bibinitperiod}}}%
        {{hash=e530c37e601ae59df76e639361cc34c7}{%
           family={Dai},
           familyi={D\bibinitperiod},
           given={Xinyi},
           giveni={X\bibinitperiod}}}%
        {{hash=7ad0129cb5a47961c85225c69a5dbe30}{%
           family={Xi},
           familyi={X\bibinitperiod},
           given={Yunjia},
           giveni={Y\bibinitperiod}}}%
        {{hash=3a56fcbac490c2ec2d74eb81349d393b}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Weiwen},
           giveni={W\bibinitperiod}}}%
        {{hash=31960f03389184b7f052f5b197cc9fdf}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Bo},
           giveni={B\bibinitperiod}}}%
        {{hash=8c6d18e2d167e1a3dc88c0166bbc3471}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Hao},
           giveni={H\bibinitperiod}}}%
        {{hash=bc6c6f66f139beef784a50d9f1485019}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Yong},
           giveni={Y\bibinitperiod}}}%
        {{hash=a429df9214aeaeb673535ebb905cae3c}{%
           family={Wu},
           familyi={W\bibinitperiod},
           given={Chuhan},
           giveni={C\bibinitperiod}}}%
        {{hash=f26d46d449172ef91dd8ba69e854b5ba}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Xiangyang},
           giveni={X\bibinitperiod}}}%
        {{hash=9b5189807f3875464c9b0dbfe1a6a2f7}{%
           family={Zhu},
           familyi={Z\bibinitperiod},
           given={Chenxu},
           giveni={C\bibinitperiod}}}%
        {{hash=3a7ebdbb9a440e9929d856af891d02c3}{%
           family={Guo},
           familyi={G\bibinitperiod},
           given={Huifeng},
           giveni={H\bibinitperiod}}}%
        {{hash=c447a713c11f58a40c2a899040774a98}{%
           family={Yu},
           familyi={Y\bibinitperiod},
           given={Yong},
           giveni={Y\bibinitperiod}}}%
        {{hash=b1ea45fbb17b97fc513d6589d9f9623f}{%
           family={Tang},
           familyi={T\bibinitperiod},
           given={Ruiming},
           giveni={R\bibinitperiod}}}%
        {{hash=fbc51a6317f158547173b93086d9b1a2}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Weinan},
           giveni={W\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{b65a467d6c40d57fdc04e547c263d0df}
      \strng{fullhash}{5ee51c73ad728dc6297bfc2fe537c7ae}
      \strng{fullhashraw}{5ee51c73ad728dc6297bfc2fe537c7ae}
      \strng{bibnamehash}{5ee51c73ad728dc6297bfc2fe537c7ae}
      \strng{authorbibnamehash}{5ee51c73ad728dc6297bfc2fe537c7ae}
      \strng{authornamehash}{b65a467d6c40d57fdc04e547c263d0df}
      \strng{authorfullhash}{5ee51c73ad728dc6297bfc2fe537c7ae}
      \strng{authorfullhashraw}{5ee51c73ad728dc6297bfc2fe537c7ae}
      \field{extraname}{1}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{With the rapid development of online services and web applications, recommender systems (RS) have become increasingly indispensable for mitigating information overload and matching users' information needs by providing personalized suggestions over items. Although the RS research community has made remarkable progress over the past decades, conventional recommendation models (CRM) still have some limitations, e.g., lacking open-domain world knowledge, and difficulties in comprehending users' underlying preferences and motivations. Meanwhile, large language models (LLM) have shown impressive general intelligence and human-like capabilities for various natural language processing (NLP) tasks, which mainly stem from their extensive open-world knowledge, logical and commonsense reasoning abilities, as well as their comprehension of human culture and society. Consequently, the emergence of LLM is inspiring the design of RS and pointing out a promising research direction, i.e., whether we can incorporate LLM and benefit from their common knowledge and capabilities to compensate for the limitations of CRM. In this article, we conduct a comprehensive survey on this research direction, and draw a bird's-eye view from the perspective of the whole pipeline in real-world RS. Specifically, we summarize existing research works from two orthogonal aspects: where and how to adapt LLM to RS. For the ``WHERE'' question, we discuss the roles that LLM could play in different stages of the recommendation pipeline, i.e., feature engineering, feature encoder, scoring/ranking function, user interaction, and pipeline controller. For the ``HOW'' question, we investigate the training and inference strategies, resulting in two fine-grained taxonomy criteria, i.e., whether to tune LLM or not during training, and whether to involve CRM for inference. Detailed analysis and general development paths are provided for both ``WHERE'' and ``HOW'' questions, respectively. Then, we highlight the key challenges in adapting LLM to RS from three aspects, i.e., efficiency, effectiveness, and ethics. Finally, we summarize the survey and discuss the future prospects.}
      \field{issn}{1046-8188}
      \field{journaltitle}{ACM Trans. Inf. Syst.}
      \field{month}{1}
      \field{number}{2}
      \field{title}{How Can Recommender Systems Benefit from Large Language Models: A Survey}
      \field{volume}{43}
      \field{year}{2025}
      \verb{doi}
      \verb 10.1145/3678004
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3678004
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3678004
      \endverb
      \keyw{Recommender systems,large language models}
    \endentry
    \entry{Lin2022}{misc}{}{}
      \name{author}{4}{}{%
        {{hash=eed59c9def84751806f42cce93136fdb}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Zihan},
           giveni={Z\bibinitperiod}}}%
        {{hash=50377ba64779988ee3e2e9b367168571}{%
           family={Tian},
           familyi={T\bibinitperiod},
           given={Changxin},
           giveni={C\bibinitperiod}}}%
        {{hash=678f15f5b4dbc1aaed429148209c1670}{%
           family={Hou},
           familyi={H\bibinitperiod},
           given={Yupeng},
           giveni={Y\bibinitperiod}}}%
        {{hash=64942cca497eff6cd6c5b264afdc5dd6}{%
           family={Zhao},
           familyi={Z\bibinitperiod},
           given={Wayne\bibnamedelima Xin},
           giveni={W\bibinitperiod\bibinitdelim X\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{8ab7ecc9a6c078c44fcf850145ba7592}
      \strng{fullhash}{70209022c4dadbf6c6a0ec242d6a6b78}
      \strng{fullhashraw}{70209022c4dadbf6c6a0ec242d6a6b78}
      \strng{bibnamehash}{70209022c4dadbf6c6a0ec242d6a6b78}
      \strng{authorbibnamehash}{70209022c4dadbf6c6a0ec242d6a6b78}
      \strng{authornamehash}{8ab7ecc9a6c078c44fcf850145ba7592}
      \strng{authorfullhash}{70209022c4dadbf6c6a0ec242d6a6b78}
      \strng{authorfullhashraw}{70209022c4dadbf6c6a0ec242d6a6b78}
      \field{extraname}{2}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Recently, graph collaborative filtering methods have been proposed as an effective recommendation approach, which can capture users' preference over items by modeling the user-item interaction graphs. Despite the effectiveness, these methods suffer from data sparsity in real scenarios. In order to reduce the influence of data sparsity, contrastive learning is adopted in graph collaborative filtering for enhancing the performance. However, these methods typically construct the contrastive pairs by random sampling, which neglect the neighboring relations among users (or items) and fail to fully exploit the potential of contrastive learning for recommendation. To tackle the above issue, we propose a novel contrastive learning approach, named Neighborhood-enriched Contrastive Learning, named NCL, which explicitly incorporates the potential neighbors into contrastive pairs. Specifically, we introduce the neighbors of a user (or an item) from graph structure and semantic space respectively. For the structural neighbors on the interaction graph, we develop a novel structure-contrastive objective that regards users (or items) and their structural neighbors as positive contrastive pairs. In implementation, the representations of users (or items) and neighbors correspond to the outputs of different GNN layers. Furthermore, to excavate the potential neighbor relation in semantic space, we assume that users with similar representations are within the semantic neighborhood, and incorporate these semantic neighbors into the prototype-contrastive objective. The proposed NCL can be optimized with EM algorithm and generalized to apply to graph collaborative filtering methods. Extensive experiments on five public datasets demonstrate the effectiveness of the proposed NCL, notably with 26{\%} and 17{\%} performance gain over a competitive graph collaborative filtering base model on the Yelp and Amazon-book datasets, respectively. Our implementation code is available at: https://github.com/RUCAIBox/NCL.}
      \field{note}{New York, NY, USA}
      \field{title}{Improving Graph Collaborative Filtering with Neighborhood-enriched Contrastive Learning}
      \field{year}{2022}
      \field{pages}{2320\bibrangedash 2329}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1145/3485447.3512104
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3485447.3512104
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3485447.3512104
      \endverb
      \keyw{Collaborative Filtering,Contrastive Learning,Graph Neural Network,Recommender System}
    \endentry
    \entry{Linden2003}{article}{}{}
      \name{author}{3}{}{%
        {{hash=ee7d3db055216fe5376fea1eb7eb2146}{%
           family={Linden},
           familyi={L\bibinitperiod},
           given={G.},
           giveni={G\bibinitperiod}}}%
        {{hash=661af25efdcede2da6f1d84feee822d2}{%
           family={Smith},
           familyi={S\bibinitperiod},
           given={B.},
           giveni={B\bibinitperiod}}}%
        {{hash=16752b805f854e8dd063805b873dd889}{%
           family={York},
           familyi={Y\bibinitperiod},
           given={J.},
           giveni={J\bibinitperiod}}}%
      }
      \strng{namehash}{0257de9c01ce11a8e00d036a8728ca48}
      \strng{fullhash}{0257de9c01ce11a8e00d036a8728ca48}
      \strng{fullhashraw}{0257de9c01ce11a8e00d036a8728ca48}
      \strng{bibnamehash}{0257de9c01ce11a8e00d036a8728ca48}
      \strng{authorbibnamehash}{0257de9c01ce11a8e00d036a8728ca48}
      \strng{authornamehash}{0257de9c01ce11a8e00d036a8728ca48}
      \strng{authorfullhash}{0257de9c01ce11a8e00d036a8728ca48}
      \strng{authorfullhashraw}{0257de9c01ce11a8e00d036a8728ca48}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{1941-0131}
      \field{journaltitle}{IEEE Internet Computing}
      \field{number}{1}
      \field{title}{Amazon.com recommendations: item-to-item collaborative filtering}
      \field{volume}{7}
      \field{year}{2003}
      \field{pages}{76\bibrangedash 80}
      \range{pages}{5}
      \verb{doi}
      \verb 10.1109/MIC.2003.1167344
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1109/MIC.2003.1167344
      \endverb
      \verb{url}
      \verb https://doi.org/10.1109/MIC.2003.1167344
      \endverb
    \endentry
    \entry{Liu2024}{article}{}{}
      \name{author}{5}{}{%
        {{hash=5356c61975009435cd812036c0b46914}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Chengkai},
           giveni={C\bibinitperiod}}}%
        {{hash=6039a6bb1ffccf02aa613e777c63e951}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Jianghao},
           giveni={J\bibinitperiod}}}%
        {{hash=34577db2b010af0f60e1cfeaf9c9eeea}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Jianling},
           giveni={J\bibinitperiod}}}%
        {{hash=45aa2f702c0c42d4870b87dc3ee972eb}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Hanzhou},
           giveni={H\bibinitperiod}}}%
        {{hash=9d2fdd65d55535348eaaff3c09896b6a}{%
           family={Caverlee},
           familyi={C\bibinitperiod},
           given={James},
           giveni={J\bibinitperiod}}}%
      }
      \strng{namehash}{1b91b57e62e4d277f1be2062e113180a}
      \strng{fullhash}{c0d39eea8a10c49515de246fdf32bac2}
      \strng{fullhashraw}{c0d39eea8a10c49515de246fdf32bac2}
      \strng{bibnamehash}{c0d39eea8a10c49515de246fdf32bac2}
      \strng{authorbibnamehash}{c0d39eea8a10c49515de246fdf32bac2}
      \strng{authornamehash}{1b91b57e62e4d277f1be2062e113180a}
      \strng{authorfullhash}{c0d39eea8a10c49515de246fdf32bac2}
      \strng{authorfullhashraw}{c0d39eea8a10c49515de246fdf32bac2}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Sequential recommendation aims to estimate dynamic user preferences and sequential dependencies among historical user behaviors. Inspired by the recent success of state space models (SSMs), we propose Mamba4Rec, which is the first work to explore the potential of selective SSMs for efficient sequential recommendation. Built upon the basic Mamba block, we design a series of sequential modeling techniques to further promote model performance while maintaining inference efficiency.}
      \field{journaltitle}{arXiv preprint arXiv:2403.03900}
      \field{month}{3}
      \field{title}{Mamba4Rec: Towards Efficient Sequential Recommendation with Selective State Space Models}
      \field{year}{2024}
      \verb{doi}
      \verb 10.48550/arXiv.2403.03900
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.48550/arXiv.2403.03900
      \endverb
      \verb{url}
      \verb https://doi.org/10.48550/arXiv.2403.03900
      \endverb
    \endentry
    \entry{Loeb1992}{article}{}{}
      \name{author}{1}{}{%
        {{hash=696a1bfeb81e1cc3849404ba89b96e82}{%
           family={Loeb},
           familyi={L\bibinitperiod},
           given={Shoshana},
           giveni={S\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{696a1bfeb81e1cc3849404ba89b96e82}
      \strng{fullhash}{696a1bfeb81e1cc3849404ba89b96e82}
      \strng{fullhashraw}{696a1bfeb81e1cc3849404ba89b96e82}
      \strng{bibnamehash}{696a1bfeb81e1cc3849404ba89b96e82}
      \strng{authorbibnamehash}{696a1bfeb81e1cc3849404ba89b96e82}
      \strng{authornamehash}{696a1bfeb81e1cc3849404ba89b96e82}
      \strng{authorfullhash}{696a1bfeb81e1cc3849404ba89b96e82}
      \strng{authorfullhashraw}{696a1bfeb81e1cc3849404ba89b96e82}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{0001-0782}
      \field{journaltitle}{Commun. ACM}
      \field{month}{12}
      \field{number}{12}
      \field{title}{Architecting personalized delivery of multimedia information}
      \field{volume}{35}
      \field{year}{1992}
      \field{pages}{39\bibrangedash 47}
      \range{pages}{9}
      \verb{doi}
      \verb 10.1145/138859.138862
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/138859.138862
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/138859.138862
      \endverb
      \keyw{user profiling,user models,personalized information delivery,multimedia applications,information retrieval,information filtering,casual information usage}
    \endentry
    \entry{Mnih2015}{article}{}{}
      \name{author}{19}{}{%
        {{hash=f7d23cfe4ca0e6bf7a8c251bfa78aca6}{%
           family={Mnih},
           familyi={M\bibinitperiod},
           given={Volodymyr},
           giveni={V\bibinitperiod}}}%
        {{hash=481308b301166b521c74fde6566e97e6}{%
           family={Kavukcuoglu},
           familyi={K\bibinitperiod},
           given={Koray},
           giveni={K\bibinitperiod}}}%
        {{hash=89dbd30410c2085cd059f32c57d4593e}{%
           family={Silver},
           familyi={S\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod}}}%
        {{hash=677dfee41a39b5ac7e138f5ce14467e9}{%
           family={Rusu},
           familyi={R\bibinitperiod},
           given={Andrei\bibnamedelima A.},
           giveni={A\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=1cbd91f7404b2298b46bb46c47c08251}{%
           family={Veness},
           familyi={V\bibinitperiod},
           given={Joel},
           giveni={J\bibinitperiod}}}%
        {{hash=eae3aa0ab9cb8b33a1ade80739e79e57}{%
           family={Bellemare},
           familyi={B\bibinitperiod},
           given={Marc\bibnamedelima G.},
           giveni={M\bibinitperiod\bibinitdelim G\bibinitperiod}}}%
        {{hash=dfca94b0427da7f9088af596e23b46c0}{%
           family={Graves},
           familyi={G\bibinitperiod},
           given={Alex},
           giveni={A\bibinitperiod}}}%
        {{hash=9449802bcb467309c0ebced658096818}{%
           family={Riedmiller},
           familyi={R\bibinitperiod},
           given={Martin},
           giveni={M\bibinitperiod}}}%
        {{hash=be3d55306c5ab7ee716f96f137dddba6}{%
           family={Fidjeland},
           familyi={F\bibinitperiod},
           given={Andreas\bibnamedelima K.},
           giveni={A\bibinitperiod\bibinitdelim K\bibinitperiod}}}%
        {{hash=46cc21fb5dec973c05ceb0f321e02ca0}{%
           family={Ostrovski},
           familyi={O\bibinitperiod},
           given={Georg},
           giveni={G\bibinitperiod}}}%
        {{hash=4e381e44037009b1cd834d794735c311}{%
           family={Petersen},
           familyi={P\bibinitperiod},
           given={Stig},
           giveni={S\bibinitperiod}}}%
        {{hash=03cf4f0976cc27112d267a8916a2d169}{%
           family={Beattie},
           familyi={B\bibinitperiod},
           given={Charles},
           giveni={C\bibinitperiod}}}%
        {{hash=b827d5121d467eeb30ccac8c61094591}{%
           family={Sadik},
           familyi={S\bibinitperiod},
           given={Amir},
           giveni={A\bibinitperiod}}}%
        {{hash=af540e84ef1ecdaa70b1f7c90f59fd7d}{%
           family={Antonoglou},
           familyi={A\bibinitperiod},
           given={Ioannis},
           giveni={I\bibinitperiod}}}%
        {{hash=59998a15386f62e4d2776176ab58d49c}{%
           family={King},
           familyi={K\bibinitperiod},
           given={Helen},
           giveni={H\bibinitperiod}}}%
        {{hash=a425c81c03d315597e3f92690763e24d}{%
           family={Kumaran},
           familyi={K\bibinitperiod},
           given={Dharshan},
           giveni={D\bibinitperiod}}}%
        {{hash=d7805381550fb5f8360345f7f72c0b49}{%
           family={Wierstra},
           familyi={W\bibinitperiod},
           given={Daan},
           giveni={D\bibinitperiod}}}%
        {{hash=afdf5ed50a24cdca0f42433e4f4848d5}{%
           family={Legg},
           familyi={L\bibinitperiod},
           given={Shane},
           giveni={S\bibinitperiod}}}%
        {{hash=b160026950ebb1e2286dfb40c15482f5}{%
           family={Hassabis},
           familyi={H\bibinitperiod},
           given={Demis},
           giveni={D\bibinitperiod}}}%
      }
      \strng{namehash}{aff24b211b34cdd515b2fd148ce0c920}
      \strng{fullhash}{29e1f598b04c2ec7e97aaeb02f70e0c8}
      \strng{fullhashraw}{29e1f598b04c2ec7e97aaeb02f70e0c8}
      \strng{bibnamehash}{29e1f598b04c2ec7e97aaeb02f70e0c8}
      \strng{authorbibnamehash}{29e1f598b04c2ec7e97aaeb02f70e0c8}
      \strng{authornamehash}{aff24b211b34cdd515b2fd148ce0c920}
      \strng{authorfullhash}{29e1f598b04c2ec7e97aaeb02f70e0c8}
      \strng{authorfullhashraw}{29e1f598b04c2ec7e97aaeb02f70e0c8}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{An artificial agent is developed that learns to playÂ a diverse range of classic Atari 2600 computer games directly from sensory experience, achieving aÂ performance comparable to that of an expert human player; this work paves the way to building general-purpose learning algorithms that bridge the divide between perception and action.}
      \field{issn}{1476-4687}
      \field{journaltitle}{Nature}
      \field{month}{2}
      \field{number}{7540}
      \field{title}{Human-level control through deep reinforcement learning}
      \field{volume}{518}
      \field{year}{2015}
      \field{pages}{529\bibrangedash 533}
      \range{pages}{5}
      \verb{doi}
      \verb 10.1038/nature14236
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1038/nature14236
      \endverb
      \verb{url}
      \verb https://doi.org/10.1038/nature14236
      \endverb
    \endentry
    \entry{Qu2024}{article}{}{}
      \name{author}{5}{}{%
        {{hash=9fb69a9818d719d954118ccb463385a9}{%
           family={Qu},
           familyi={Q\bibinitperiod},
           given={Haohao},
           giveni={H\bibinitperiod}}}%
        {{hash=183a09ba40b4c76e1dc0ec50c46bd676}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Yifeng},
           giveni={Y\bibinitperiod}}}%
        {{hash=a26132c529ee9e29003497240faa4bce}{%
           family={Ning},
           familyi={N\bibinitperiod},
           given={Liangbo},
           giveni={L\bibinitperiod}}}%
        {{hash=c962fa5377a09410d9645db6e5704558}{%
           family={Fan},
           familyi={F\bibinitperiod},
           given={Wenqi},
           giveni={W\bibinitperiod}}}%
        {{hash=16a77262afb7cc9b0229c21f168bd098}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Qing},
           giveni={Q\bibinitperiod}}}%
      }
      \strng{namehash}{8666f9880d6b4181b88ee7ef179b7a41}
      \strng{fullhash}{e74ab6bc31e5fd26ada6f273ea61796d}
      \strng{fullhashraw}{e74ab6bc31e5fd26ada6f273ea61796d}
      \strng{bibnamehash}{e74ab6bc31e5fd26ada6f273ea61796d}
      \strng{authorbibnamehash}{e74ab6bc31e5fd26ada6f273ea61796d}
      \strng{authornamehash}{8666f9880d6b4181b88ee7ef179b7a41}
      \strng{authorfullhash}{e74ab6bc31e5fd26ada6f273ea61796d}
      \strng{authorfullhashraw}{e74ab6bc31e5fd26ada6f273ea61796d}
      \field{sortinit}{Q}
      \field{sortinithash}{ce69a400a872ddd02ee7fdb3b38c6abd}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Sequential recommendation methods are crucial in modern recommender systems for their remarkable capability to understand a user's changing interests based on past interactions. However, a significant challenge faced by current methods (e.g., RNN- or Transformer-based models) is to effectively and efficiently capture users' preferences by modeling long behavior sequences, which impedes their applications like short video platforms where interactions are numerous. Inspired by the Mamba architecture built on state space models (SSM), we propose SSD4Rec, a generic and efficient sequential recommendation backbone that leverages bidirectional Structured State Space Duality (SSD) blocks to achieve near-linear scalability with sequence length.}
      \field{journaltitle}{arXiv}
      \field{title}{SSD4Rec: A Structured State Space Duality Model for Efficient Sequential Recommendation}
      \field{volume}{abs/2409.01192}
      \field{year}{2024}
      \verb{doi}
      \verb 10.48550/arXiv.2409.01192
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.48550/arXiv.2409.01192
      \endverb
      \verb{url}
      \verb https://doi.org/10.48550/arXiv.2409.01192
      \endverb
    \endentry
    \entry{Resnick1994}{misc}{}{}
      \name{author}{5}{}{%
        {{hash=42c60cd629ab25ff7b8464868a0669aa}{%
           family={Resnick},
           familyi={R\bibinitperiod},
           given={Paul},
           giveni={P\bibinitperiod}}}%
        {{hash=c43a27cdf89c815d8b1941105c95b382}{%
           family={Iacovou},
           familyi={I\bibinitperiod},
           given={Neophytos},
           giveni={N\bibinitperiod}}}%
        {{hash=3a9887aa642740970bf6eea5d9ad7d04}{%
           family={Suchak},
           familyi={S\bibinitperiod},
           given={Mitesh},
           giveni={M\bibinitperiod}}}%
        {{hash=b3625e29d8e2da0c3ae5f8f25cedf7d2}{%
           family={Bergstrom},
           familyi={B\bibinitperiod},
           given={Peter},
           giveni={P\bibinitperiod}}}%
        {{hash=05e2f63cd94159cec34470131ca35297}{%
           family={Riedl},
           familyi={R\bibinitperiod},
           given={John},
           giveni={J\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{fa6abedf9b67cf8423902a986acfb850}
      \strng{fullhash}{ccb63dcab60011368c383a97b42d0e55}
      \strng{fullhashraw}{ccb63dcab60011368c383a97b42d0e55}
      \strng{bibnamehash}{ccb63dcab60011368c383a97b42d0e55}
      \strng{authorbibnamehash}{ccb63dcab60011368c383a97b42d0e55}
      \strng{authornamehash}{fa6abedf9b67cf8423902a986acfb850}
      \strng{authorfullhash}{ccb63dcab60011368c383a97b42d0e55}
      \strng{authorfullhashraw}{ccb63dcab60011368c383a97b42d0e55}
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Collaborative filters help people make choices based on the opinions of other people. GroupLens is a system for collaborative filtering of netnews, to help people find articles they will like in the huge stream of available articles. News reader clients display predicted scores and make it easy for users to rate articles after they read them. Rating servers, called Better Bit Bureaus, gather and disseminate the ratings. The rating servers predict scores based on the heuristic that people who agreed in the past will probably agree again. Users can protect their privacy by entering ratings under pseudonyms, without reducing the effectiveness of the score prediction. The entire architecture is open: alternative software for news clients and Better Bit Bureaus can be developed independently and can interoperate with the components we have developed.}
      \field{note}{New York, NY, USA}
      \field{title}{GroupLens: an open architecture for collaborative filtering of netnews}
      \field{year}{1994}
      \field{pages}{175\bibrangedash 186}
      \range{pages}{12}
      \verb{doi}
      \verb 10.1145/192844.192905
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/192844.192905
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/192844.192905
      \endverb
      \keyw{Usenet,collaborative filtering,electronic bulletin boards,information filtering,netnews,selective dissemination of information,social filtering,user model}
    \endentry
    \entry{Roy2022}{article}{}{}
      \name{author}{2}{}{%
        {{hash=3cb27c879db263c6beebad8238892ace}{%
           family={Roy},
           familyi={R\bibinitperiod},
           given={Deepjyoti},
           giveni={D\bibinitperiod}}}%
        {{hash=d5aa531d2045b417745883621ba0d751}{%
           family={Dutta},
           familyi={D\bibinitperiod},
           given={Mala},
           giveni={M\bibinitperiod}}}%
      }
      \strng{namehash}{a5532b42c749d4d3bf5f9f5dd62b4281}
      \strng{fullhash}{a5532b42c749d4d3bf5f9f5dd62b4281}
      \strng{fullhashraw}{a5532b42c749d4d3bf5f9f5dd62b4281}
      \strng{bibnamehash}{a5532b42c749d4d3bf5f9f5dd62b4281}
      \strng{authorbibnamehash}{a5532b42c749d4d3bf5f9f5dd62b4281}
      \strng{authornamehash}{a5532b42c749d4d3bf5f9f5dd62b4281}
      \strng{authorfullhash}{a5532b42c749d4d3bf5f9f5dd62b4281}
      \strng{authorfullhashraw}{a5532b42c749d4d3bf5f9f5dd62b4281}
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Recommender systems are efficient tools for filtering online information, which is widespread owing to the changing habits of computer users, personalization trends, and emerging access to the internet. Even though the recent recommender systems are eminent in giving precise recommendations, they suffer from various limitations and challenges like scalability, cold-start, sparsity, etc. Due to the existence of various techniques, the selection of techniques becomes a complex work while building application-focused recommender systems. In addition, each technique comes with its own set of features, advantages and disadvantages which raises even more questions, which should be addressed. This paper aims to undergo a systematic review on various recent contributions in the domain of recommender systems, focusing on diverse applications like books, movies, products, etc. Initially, the various applications of each recommender system are analysed. Then, the algorithmic analysis on various recommender systems is performed and a taxonomy is framed that accounts for various components required for developing an effective recommender system. In addition, the datasets gathered, simulation platform, and performance metrics focused on each contribution are evaluated and noted. Finally, this review provides a much-needed overview of the current state of research in this field and points out the existing gaps and challenges to help posterity in developing an efficient recommender system.}
      \field{issn}{2196-1115}
      \field{journaltitle}{Journal of Big Data}
      \field{month}{5}
      \field{number}{1}
      \field{title}{A systematic review and research perspective on recommender systems}
      \field{volume}{9}
      \field{year}{2022}
      \field{pages}{59}
      \range{pages}{1}
      \verb{doi}
      \verb 10.1186/s40537-022-00592-5
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1186/s40537-022-00592-5
      \endverb
      \verb{url}
      \verb https://doi.org/10.1186/s40537-022-00592-5
      \endverb
    \endentry
    \entry{Salton1975}{article}{}{}
      \name{author}{2}{}{%
        {{hash=0ece344e5cd40f244e157ac3eefc8fd4}{%
           family={Salton},
           familyi={S\bibinitperiod},
           given={A.},
           giveni={A\bibinitperiod},
           suffix={G.and\bibnamedelima Wong},
           suffixi={G\bibinitperiod\bibinitdelim W\bibinitperiod}}}%
        {{hash=09bbc7b7b2a15d80318e4af2bf2e4d53}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={C.\bibnamedelimi S.},
           giveni={C\bibinitperiod\bibinitdelim S\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{cac1b559ca526f93c7e8267d700014bc}
      \strng{fullhash}{cac1b559ca526f93c7e8267d700014bc}
      \strng{fullhashraw}{cac1b559ca526f93c7e8267d700014bc}
      \strng{bibnamehash}{cac1b559ca526f93c7e8267d700014bc}
      \strng{authorbibnamehash}{cac1b559ca526f93c7e8267d700014bc}
      \strng{authornamehash}{cac1b559ca526f93c7e8267d700014bc}
      \strng{authorfullhash}{cac1b559ca526f93c7e8267d700014bc}
      \strng{authorfullhashraw}{cac1b559ca526f93c7e8267d700014bc}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In a document retrieval, or other pattern matching environment where stored entities (documents) are compared with each other or with incoming patterns (search requests), it appears that the best indexing (property) space is one where each entity lies as far away from the others as possible; in these circumstances the value of an indexing system may be expressible as a function of the density of the object space; in particular, retrieval performance may correlate inversely with space density. An approach based on space density computations is used to choose an optimum indexing vocabulary for a collection of documents. Typical evaluation results are shown, demonstating the usefulness of the model.}
      \field{issn}{0001-0782}
      \field{journaltitle}{Commun. ACM}
      \field{month}{11}
      \field{number}{11}
      \field{title}{A vector space model for automatic indexing}
      \field{volume}{18}
      \field{year}{1975}
      \field{pages}{613\bibrangedash 620}
      \range{pages}{8}
      \verb{doi}
      \verb 10.1145/361219.361220
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/361219.361220
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/361219.361220
      \endverb
      \keyw{document space,content analysis,automatic information retrieval,automatic indexing}
    \endentry
    \entry{Sarwar2001}{misc}{}{}
      \name{author}{4}{}{%
        {{hash=df97c54d895b3a4f966cc71817673755}{%
           family={Sarwar},
           familyi={S\bibinitperiod},
           given={Badrul},
           giveni={B\bibinitperiod}}}%
        {{hash=3db7df6401b206bb040d6735adbe81e2}{%
           family={Karypis},
           familyi={K\bibinitperiod},
           given={George},
           giveni={G\bibinitperiod}}}%
        {{hash=8bad87d5c289efb778eeccbc0a3ce84a}{%
           family={Konstan},
           familyi={K\bibinitperiod},
           given={Joseph},
           giveni={J\bibinitperiod}}}%
        {{hash=05e2f63cd94159cec34470131ca35297}{%
           family={Riedl},
           familyi={R\bibinitperiod},
           given={John},
           giveni={J\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{fb9706c608f2db79c84390f6e0e9600c}
      \strng{fullhash}{a60eaaeac402f8cfe261a070e583e388}
      \strng{fullhashraw}{a60eaaeac402f8cfe261a070e583e388}
      \strng{bibnamehash}{a60eaaeac402f8cfe261a070e583e388}
      \strng{authorbibnamehash}{a60eaaeac402f8cfe261a070e583e388}
      \strng{authornamehash}{fb9706c608f2db79c84390f6e0e9600c}
      \strng{authorfullhash}{a60eaaeac402f8cfe261a070e583e388}
      \strng{authorfullhashraw}{a60eaaeac402f8cfe261a070e583e388}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{note}{New York, NY, USA}
      \field{title}{Item-based collaborative filtering recommendation algorithms}
      \field{year}{2001}
      \field{pages}{285\bibrangedash 295}
      \range{pages}{11}
      \verb{doi}
      \verb 10.1145/371920.372071
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/371920.372071
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/371920.372071
      \endverb
    \endentry
    \entry{Sedhain2015}{misc}{}{}
      \name{author}{4}{}{%
        {{hash=908995b50ca7f98a027b2238a0ee884a}{%
           family={Sedhain},
           familyi={S\bibinitperiod},
           given={Suvash},
           giveni={S\bibinitperiod}}}%
        {{hash=d5918aa4a3a43984bc6bd2bf025e1869}{%
           family={Menon},
           familyi={M\bibinitperiod},
           given={Aditya\bibnamedelima Krishna},
           giveni={A\bibinitperiod\bibinitdelim K\bibinitperiod}}}%
        {{hash=b9e05d93531c543fb71674dca5f7d9a2}{%
           family={Sanner},
           familyi={S\bibinitperiod},
           given={Scott},
           giveni={S\bibinitperiod}}}%
        {{hash=a0b3e11df6863fd4a4b3368f9b6c1d40}{%
           family={Xie},
           familyi={X\bibinitperiod},
           given={Lexing},
           giveni={L\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{37b75404751880a6653f7eee38bd3aea}
      \strng{fullhash}{4ff053ed8a33794de26fe1c9cb9e6022}
      \strng{fullhashraw}{4ff053ed8a33794de26fe1c9cb9e6022}
      \strng{bibnamehash}{4ff053ed8a33794de26fe1c9cb9e6022}
      \strng{authorbibnamehash}{4ff053ed8a33794de26fe1c9cb9e6022}
      \strng{authornamehash}{37b75404751880a6653f7eee38bd3aea}
      \strng{authorfullhash}{4ff053ed8a33794de26fe1c9cb9e6022}
      \strng{authorfullhashraw}{4ff053ed8a33794de26fe1c9cb9e6022}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper proposes AutoRec, a novel autoencoder framework for collaborative filtering (CF). Empirically, AutoRec's compact and efficiently trainable model outperforms state-of-the-art CF techniques (biased matrix factorization, RBM-CF and LLORMA) on the Movielens and Netflix datasets.}
      \field{note}{New York, NY, USA}
      \field{title}{AutoRec: Autoencoders Meet Collaborative Filtering}
      \field{year}{2015}
      \field{pages}{111\bibrangedash 112}
      \range{pages}{2}
      \verb{doi}
      \verb 10.1145/2740908.2742726
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/2740908.2742726
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/2740908.2742726
      \endverb
      \keyw{recommender systems,collaborative filtering,autoencoders}
    \endentry
    \entry{Sun2019}{misc}{}{}
      \name{author}{7}{}{%
        {{hash=0fff2d014f575fc5d680e70e02e8ce38}{%
           family={Sun},
           familyi={S\bibinitperiod},
           given={Fei},
           giveni={F\bibinitperiod}}}%
        {{hash=f2a0a4f5a03bef37fc5552061319cb71}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Jun},
           giveni={J\bibinitperiod}}}%
        {{hash=bb371597af3d6d97a656e6f879c0189d}{%
           family={Wu},
           familyi={W\bibinitperiod},
           given={Jian},
           giveni={J\bibinitperiod}}}%
        {{hash=46518ae7e34858f82e417641272a1393}{%
           family={Pei},
           familyi={P\bibinitperiod},
           given={Changhua},
           giveni={C\bibinitperiod}}}%
        {{hash=8bd77c05192decfa1a28f0261a6041ba}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Xiao},
           giveni={X\bibinitperiod}}}%
        {{hash=929d106dcb7cd193785f5aea5ada5006}{%
           family={Ou},
           familyi={O\bibinitperiod},
           given={Wenwu},
           giveni={W\bibinitperiod}}}%
        {{hash=a6cd330d65a61e5776df47ea793c79e3}{%
           family={Jiang},
           familyi={J\bibinitperiod},
           given={Peng},
           giveni={P\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{3194e1556ebc5c352042c0969b68e903}
      \strng{fullhash}{66154590c0d2ab7271f81c424137cbba}
      \strng{fullhashraw}{66154590c0d2ab7271f81c424137cbba}
      \strng{bibnamehash}{66154590c0d2ab7271f81c424137cbba}
      \strng{authorbibnamehash}{66154590c0d2ab7271f81c424137cbba}
      \strng{authornamehash}{3194e1556ebc5c352042c0969b68e903}
      \strng{authorfullhash}{66154590c0d2ab7271f81c424137cbba}
      \strng{authorfullhashraw}{66154590c0d2ab7271f81c424137cbba}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Modeling users' dynamic preferences from their historical behaviors is challenging and crucial for recommendation systems. Previous methods employ sequential neural networks to encode users' historical interactions from left to right into hidden representations for making recommendations. Despite their effectiveness, we argue that such left-to-right unidirectional models are sub-optimal due to the limitations including: begin enumerate* [label=seriesitshapealph*upshape)] item unidirectional architectures restrict the power of hidden representation in users' behavior sequences; item they often assume a rigidly ordered sequence which is not always practical. end enumerate* To address these limitations, we proposed a sequential recommendation model called BERT4Rec, which employs the deep bidirectional self-attention to model user behavior sequences. To avoid the information leakage and efficiently train the bidirectional model, we adopt the Cloze objective to sequential recommendation, predicting the random masked items in the sequence by jointly conditioning on their left and right context. In this way, we learn a bidirectional representation model to make recommendations by allowing each item in user historical behaviors to fuse information from both left and right sides. Extensive experiments on four benchmark datasets show that our model outperforms various state-of-the-art sequential models consistently.}
      \field{note}{New York, NY, USA}
      \field{title}{BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer}
      \field{year}{2019}
      \field{pages}{1441\bibrangedash 1450}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1145/3357384.3357895
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3357384.3357895
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3357384.3357895
      \endverb
      \keyw{bidirectional sequential model,cloze,sequential recommendation}
    \endentry
    \entry{Touvron2023}{article}{}{}
      \name{author}{14}{}{%
        {{hash=a2a13fcd633ec70c55a7f3f4812afdcf}{%
           family={Touvron},
           familyi={T\bibinitperiod},
           given={Hugo},
           giveni={H\bibinitperiod}}}%
        {{hash=c641a91d616b6eda08cbbdca7b7eb186}{%
           family={Lavril},
           familyi={L\bibinitperiod},
           given={Thibaut},
           giveni={T\bibinitperiod}}}%
        {{hash=a32ece3bc966e7e88747e905158c9a6a}{%
           family={Izacard},
           familyi={I\bibinitperiod},
           given={Gautier},
           giveni={G\bibinitperiod}}}%
        {{hash=7222f9d76b0fff504f39e7c9c2a526be}{%
           family={Martinet},
           familyi={M\bibinitperiod},
           given={Xavier},
           giveni={X\bibinitperiod}}}%
        {{hash=08284515d256b832e9dba10a88af84f4}{%
           family={Lachaux},
           familyi={L\bibinitperiod},
           given={Marie-Anne},
           giveni={M\bibinithyphendelim A\bibinitperiod}}}%
        {{hash=1d29ae55d8d993d9f195b3c97bd34f7c}{%
           family={Lacroix},
           familyi={L\bibinitperiod},
           given={TimothÃ©e},
           giveni={T\bibinitperiod}}}%
        {{hash=e0d9a8657c1043f53c54f3f5a6ff305f}{%
           family={RoziÃ¨re},
           familyi={R\bibinitperiod},
           given={Baptiste},
           giveni={B\bibinitperiod}}}%
        {{hash=78a420900f50a8470ad085fb05231bf6}{%
           family={Goyal},
           familyi={G\bibinitperiod},
           given={Naman},
           giveni={N\bibinitperiod}}}%
        {{hash=00ce63f55ae2ce6ea638e5f991996584}{%
           family={Hambro},
           familyi={H\bibinitperiod},
           given={Eric},
           giveni={E\bibinitperiod}}}%
        {{hash=5373a3313da61427121b3e9733df1ed2}{%
           family={Azhar},
           familyi={A\bibinitperiod},
           given={Faisal},
           giveni={F\bibinitperiod}}}%
        {{hash=a829e25f1d50c3545ed8e99f12890acc}{%
           family={Rodriguez},
           familyi={R\bibinitperiod},
           given={Aurelien},
           giveni={A\bibinitperiod}}}%
        {{hash=977d047821122d1c2e7aa855c30c8cf2}{%
           family={Joulin},
           familyi={J\bibinitperiod},
           given={Armand},
           giveni={A\bibinitperiod}}}%
        {{hash=ebdea2c3aa9f759075733b20dce6b873}{%
           family={Grave},
           familyi={G\bibinitperiod},
           given={Edouard},
           giveni={E\bibinitperiod}}}%
        {{hash=56509a94ba6cdaf0c71304d6cf806cee}{%
           family={Lample},
           familyi={L\bibinitperiod},
           given={Guillaume},
           giveni={G\bibinitperiod}}}%
      }
      \strng{namehash}{c237483431fea681283a37adbb23a59f}
      \strng{fullhash}{39aeaa201007bcb705db32778f923cb2}
      \strng{fullhashraw}{39aeaa201007bcb705db32778f923cb2}
      \strng{bibnamehash}{39aeaa201007bcb705db32778f923cb2}
      \strng{authorbibnamehash}{39aeaa201007bcb705db32778f923cb2}
      \strng{authornamehash}{c237483431fea681283a37adbb23a59f}
      \strng{authorfullhash}{39aeaa201007bcb705db32778f923cb2}
      \strng{authorfullhashraw}{39aeaa201007bcb705db32778f923cb2}
      \field{sortinit}{T}
      \field{sortinithash}{9af77f0292593c26bde9a56e688eaee9}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters. We train our models on trillions of tokens, and show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks, and LLaMA-65B is competitive with the best models, Chinchilla-70B and PaLM-540B. We release all our models to the research community.}
      \field{journaltitle}{arXiv preprint arXiv:2302.13971}
      \field{month}{2}
      \field{title}{LLaMA: Open and Efficient Foundation Language Models}
      \field{year}{2023}
      \verb{doi}
      \verb 10.48550/arXiv.2302.13971
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.48550/arXiv.2302.13971
      \endverb
      \verb{url}
      \verb https://doi.org/10.48550/arXiv.2302.13971
      \endverb
    \endentry
    \entry{Vaswani2017}{misc}{}{}
      \name{author}{8}{}{%
        {{hash=7f28e84700536646dd6620a0db07ad09}{%
           family={Vaswani},
           familyi={V\bibinitperiod},
           given={Ashish},
           giveni={A\bibinitperiod}}}%
        {{hash=62efade83d70f0323fe248755e6c90c5}{%
           family={Shazeer},
           familyi={S\bibinitperiod},
           given={Noam},
           giveni={N\bibinitperiod}}}%
        {{hash=06649ebab1ea5cac0250746a19764975}{%
           family={Parmar},
           familyi={P\bibinitperiod},
           given={Niki},
           giveni={N\bibinitperiod}}}%
        {{hash=831027ee0ebf22375e2a86afc1881909}{%
           family={Uszkoreit},
           familyi={U\bibinitperiod},
           given={Jakob},
           giveni={J\bibinitperiod}}}%
        {{hash=2fd2982e30ebcec93ec1cf76e0d797fd}{%
           family={Jones},
           familyi={J\bibinitperiod},
           given={Llion},
           giveni={L\bibinitperiod}}}%
        {{hash=27b07e4eacbf4ef7a1438e3badb7dd8d}{%
           family={Gomez},
           familyi={G\bibinitperiod},
           given={Aidan\bibnamedelima N.},
           giveni={A\bibinitperiod\bibinitdelim N\bibinitperiod}}}%
        {{hash=5c48a710d32767cdb8f0a0bfb4922585}{%
           family={Kaiser},
           familyi={K\bibinitperiod},
           given={{Å}\bibnamedelima Ukasz},
           giveni={Å\bibinitperiod\bibinitdelim U\bibinitperiod}}}%
        {{hash=95595a0fefb86187cbc36e551017d332}{%
           family={Polosukhin},
           familyi={P\bibinitperiod},
           given={Illia},
           giveni={I\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Curran Associates, Inc.}%
      }
      \strng{namehash}{ee273ab30cfb889666f8c4d806eb9ce7}
      \strng{fullhash}{67ef0afbae143149346a0c5895dae30c}
      \strng{fullhashraw}{67ef0afbae143149346a0c5895dae30c}
      \strng{bibnamehash}{67ef0afbae143149346a0c5895dae30c}
      \strng{authorbibnamehash}{67ef0afbae143149346a0c5895dae30c}
      \strng{authornamehash}{ee273ab30cfb889666f8c4d806eb9ce7}
      \strng{authorfullhash}{67ef0afbae143149346a0c5895dae30c}
      \strng{authorfullhashraw}{67ef0afbae143149346a0c5895dae30c}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{Attention is All you Need}
      \field{volume}{30}
      \field{year}{2017}
      \verb{doi}
      \verb 10.48550/arXiv.1706.03762
      \endverb
      \verb{urlraw}
      \verb https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf
      \endverb
      \verb{url}
      \verb https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf
      \endverb
    \endentry
    \entry{Wang2017}{misc}{}{}
      \name{author}{8}{}{%
        {{hash=2f3ea981fa5a715a69118b48e576a9f5}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Jun},
           giveni={J\bibinitperiod}}}%
        {{hash=98c85f16186b9ce495905d4a0dd69e57}{%
           family={Yu},
           familyi={Y\bibinitperiod},
           given={Lantao},
           giveni={L\bibinitperiod}}}%
        {{hash=fbc51a6317f158547173b93086d9b1a2}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Weinan},
           giveni={W\bibinitperiod}}}%
        {{hash=a078b5f9e219750df0e6b4771a07569e}{%
           family={Gong},
           familyi={G\bibinitperiod},
           given={Yu},
           giveni={Y\bibinitperiod}}}%
        {{hash=037aabea5cf2c1e00ab56773419bd6b5}{%
           family={Xu},
           familyi={X\bibinitperiod},
           given={Yinghui},
           giveni={Y\bibinitperiod}}}%
        {{hash=07b6ac71b6c34f04b3c5593596b3dc53}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Benyou},
           giveni={B\bibinitperiod}}}%
        {{hash=f189b293bd3263254702f8c5fe1d714b}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Peng},
           giveni={P\bibinitperiod}}}%
        {{hash=0e288a0b938246b15ffc7b73e4b5d5d2}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Dell},
           giveni={D\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{aa7a83578db6d97a4a3107198650dca5}
      \strng{fullhash}{621eeea7d3fb23739bf61bf081e3fd76}
      \strng{fullhashraw}{621eeea7d3fb23739bf61bf081e3fd76}
      \strng{bibnamehash}{621eeea7d3fb23739bf61bf081e3fd76}
      \strng{authorbibnamehash}{621eeea7d3fb23739bf61bf081e3fd76}
      \strng{authornamehash}{aa7a83578db6d97a4a3107198650dca5}
      \strng{authorfullhash}{621eeea7d3fb23739bf61bf081e3fd76}
      \strng{authorfullhashraw}{621eeea7d3fb23739bf61bf081e3fd76}
      \field{extraname}{1}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper provides a unified account of two schools of thinking in information retrieval modelling: the generative retrieval focusing on predicting relevant documents given a query, and the discriminative retrieval focusing on predicting relevancy given a query-document pair. We propose a game theoretical minimax game to iteratively optimise both models. On one hand, the discriminative model, aiming to mine signals from labelled and unlabelled data, provides guidance to train the generative model towards fitting the underlying relevance distribution over documents given the query. On the other hand, the generative model, acting as an attacker to the current discriminative model, generates difficult examples for the discriminative model in an adversarial way by minimising its discrimination objective. With the competition between these two models, we show that the unified framework takes advantage of both schools of thinking: (i) the generative model learns to fit the relevance distribution over documents via the signals from the discriminative model, and (ii) the discriminative model is able to exploit the unlabelled data selected by the generative model to achieve a better estimation for document ranking. Our experimental results have demonstrated significant performance gains as much as 23.96{\%} on Precision@5 and 15.50{\%} on MAP over strong baselines in a variety of applications including web search, item recommendation, and question answering.}
      \field{note}{New York, NY, USA}
      \field{title}{IRGAN: A Minimax Game for Unifying Generative and Discriminative Information Retrieval Models}
      \field{year}{2017}
      \field{pages}{515\bibrangedash 524}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1145/3077136.3080786
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3077136.3080786
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3077136.3080786
      \endverb
      \keyw{web search,recommender systems,question answering,information retrieval models,information retrieval,adversarial training}
    \endentry
    \entry{Wang2019_KGAT}{misc}{}{}
      \name{author}{5}{}{%
        {{hash=8fde8559617f603b3e2b3cf30cb48e9b}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Xiang},
           giveni={X\bibinitperiod}}}%
        {{hash=cf3f1b6bfe8e9131a8c719c1af0dce5d}{%
           family={He},
           familyi={H\bibinitperiod},
           given={Xiangnan},
           giveni={X\bibinitperiod}}}%
        {{hash=ffbd440be3d518a696e50320511efbfa}{%
           family={Cao},
           familyi={C\bibinitperiod},
           given={Yixin},
           giveni={Y\bibinitperiod}}}%
        {{hash=43e7ecabe8e7b628c5a10165aceb7ff5}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Meng},
           giveni={M\bibinitperiod}}}%
        {{hash=57e4257ea3484acff91be2a3df96d16b}{%
           family={Chua},
           familyi={C\bibinitperiod},
           given={Tat-Seng},
           giveni={T\bibinithyphendelim S\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{35ac326fad78d42d0760cfb75887ea69}
      \strng{fullhash}{bb9a4bb0ba23478e7843d6f31968d354}
      \strng{fullhashraw}{bb9a4bb0ba23478e7843d6f31968d354}
      \strng{bibnamehash}{bb9a4bb0ba23478e7843d6f31968d354}
      \strng{authorbibnamehash}{bb9a4bb0ba23478e7843d6f31968d354}
      \strng{authornamehash}{35ac326fad78d42d0760cfb75887ea69}
      \strng{authorfullhash}{bb9a4bb0ba23478e7843d6f31968d354}
      \strng{authorfullhashraw}{bb9a4bb0ba23478e7843d6f31968d354}
      \field{extraname}{2}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{To provide more accurate, diverse, and explainable recommendation, it is compulsory to go beyond modeling user-item interactions and take side information into account. Traditional methods like factorization machine (FM) cast it as a supervised learning problem, which assumes each interaction as an independent instance with side information encoded. Due to the overlook of the relations among instances or items (e.g., the director of a movie is also an actor of another movie), these methods are insufficient to distill the collaborative signal from the collective behaviors of users. In this work, we investigate the utility of knowledge graph (KG), which breaks down the independent interaction assumption by linking items with their attributes. We argue that in such a hybrid structure of KG and user-item graph, high-order relations --- which connect two items with one or multiple linked attributes --- are an essential factor for successful recommendation. We propose a new method named Knowledge Graph Attention Network (KGAT) which explicitly models the high-order connectivities in KG in an end-to-end fashion. It recursively propagates the embeddings from a node's neighbors (which can be users, items, or attributes) to refine the node's embedding, and employs an attention mechanism to discriminate the importance of the neighbors. Our KGAT is conceptually advantageous to existing KG-based recommendation methods, which either exploit high-order relations by extracting paths or implicitly modeling them with regularization. Empirical results on three public benchmarks show that KGAT significantly outperforms state-of-the-art methods like Neural FM and RippleNet. Further studies verify the efficacy of embedding propagation for high-order relation modeling and the interpretability benefits brought by the attention mechanism. We release the codes and datasets at https://github.com/xiangwang1223/knowledge{\_}graph{\_}attention{\_}network.}
      \field{note}{New York, NY, USA}
      \field{title}{KGAT: Knowledge Graph Attention Network for Recommendation}
      \field{year}{2019}
      \field{pages}{950\bibrangedash 958}
      \range{pages}{9}
      \verb{doi}
      \verb 10.1145/3292500.3330989
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3292500.3330989
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3292500.3330989
      \endverb
      \keyw{collaborative filtering,embedding propagation,graph neural network,higher-order connectivity,knowledge graph,recommendation}
    \endentry
    \entry{Wang2019}{misc}{}{}
      \name{author}{5}{}{%
        {{hash=8fde8559617f603b3e2b3cf30cb48e9b}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Xiang},
           giveni={X\bibinitperiod}}}%
        {{hash=cf3f1b6bfe8e9131a8c719c1af0dce5d}{%
           family={He},
           familyi={H\bibinitperiod},
           given={Xiangnan},
           giveni={X\bibinitperiod}}}%
        {{hash=00b734eb3fb588e4c6c94e4271080d0b}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Meng},
           giveni={M\bibinitperiod}}}%
        {{hash=9090db11da70fe0d8b95cbf3d73a6216}{%
           family={Feng},
           familyi={F\bibinitperiod},
           given={Fuli},
           giveni={F\bibinitperiod}}}%
        {{hash=57e4257ea3484acff91be2a3df96d16b}{%
           family={Chua},
           familyi={C\bibinitperiod},
           given={Tat-Seng},
           giveni={T\bibinithyphendelim S\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{35ac326fad78d42d0760cfb75887ea69}
      \strng{fullhash}{8210805709bda1fab28c8d403239efd4}
      \strng{fullhashraw}{8210805709bda1fab28c8d403239efd4}
      \strng{bibnamehash}{8210805709bda1fab28c8d403239efd4}
      \strng{authorbibnamehash}{8210805709bda1fab28c8d403239efd4}
      \strng{authornamehash}{35ac326fad78d42d0760cfb75887ea69}
      \strng{authorfullhash}{8210805709bda1fab28c8d403239efd4}
      \strng{authorfullhashraw}{8210805709bda1fab28c8d403239efd4}
      \field{extraname}{3}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Learning vector representations (aka. embeddings) of users and items lies at the core of modern recommender systems. Ranging from early matrix factorization to recently emerged deep learning based methods, existing efforts typically obtain a user's (or an item's) embedding by mapping from pre-existing features that describe the user (or the item), such as ID and attributes. We argue that an inherent drawback of such methods is that, the collaborative signal, which is latent in user-item interactions, is not encoded in the embedding process. As such, the resultant embeddings may not be sufficient to capture the collaborative filtering effect.In this work, we propose to integrate the user-item interactions - more specifically the bipartite graph structure - into the embedding process. We develop a new recommendation framework Neural Graph Collaborative Filtering (NGCF), which exploits the user-item graph structure by propagating embeddings on it. This leads to the expressive modeling of high-order connectivity in user-item graph, effectively injecting the collaborative signal into the embedding process in an explicit manner. We conduct extensive experiments on three public benchmarks, demonstrating significant improvements over several state-of-the-art models like HOP-Rec [39] and Collaborative Memory Network [5]. Further analysis verifies the importance of embedding propagation for learning better user and item representations, justifying the rationality and effectiveness of NGCF. Codes are available at https://github.com/xiangwang1223/neural{\_}graph{\_}collaborative{\_}filtering.}
      \field{note}{New York, NY, USA}
      \field{title}{Neural Graph Collaborative Filtering}
      \field{year}{2019}
      \field{pages}{165\bibrangedash 174}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1145/3331184.3331267
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3331184.3331267
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3331184.3331267
      \endverb
      \keyw{collaborative filtering,embedding propagation,graph neural network,high-order connectivity,recommendation}
    \endentry
    \entry{Wang2024}{article}{}{}
      \name{author}{3}{}{%
        {{hash=a11ee042886dbd36b0ebc323acf18ce7}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Yuda},
           giveni={Y\bibinitperiod}}}%
        {{hash=9ca071a6f54092803f867b95ab847d38}{%
           family={He},
           familyi={H\bibinitperiod},
           given={Xuxin},
           giveni={X\bibinitperiod}}}%
        {{hash=0913c79ec116a53787b3c6eb58084c3c}{%
           family={Zhu},
           familyi={Z\bibinitperiod},
           given={Shengxin},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{223eac946be70ec0b0c262b476c82938}
      \strng{fullhash}{223eac946be70ec0b0c262b476c82938}
      \strng{fullhashraw}{223eac946be70ec0b0c262b476c82938}
      \strng{bibnamehash}{223eac946be70ec0b0c262b476c82938}
      \strng{authorbibnamehash}{223eac946be70ec0b0c262b476c82938}
      \strng{authornamehash}{223eac946be70ec0b0c262b476c82938}
      \strng{authorfullhash}{223eac946be70ec0b0c262b476c82938}
      \strng{authorfullhashraw}{223eac946be70ec0b0c262b476c82938}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Drawing inspiration from the recent advancements of state space models (SSMs) in control theory... we introduce EchoMamba4Rec, a novel architecture that harmonizes bidirectional SSMs with spectral filtering to capture both sequential dependencies and frequency-domain patterns efficiently.}
      \field{journaltitle}{arXiv preprint arXiv:2406.02638}
      \field{month}{6}
      \field{title}{EchoMamba4Rec: Harmonizing Bidirectional State Space Models with Spectral Filtering for Advanced Sequential Recommendation}
      \field{year}{2024}
      \verb{doi}
      \verb 10.48550/arXiv.2406.02638
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.48550/arXiv.2406.02638
      \endverb
      \verb{url}
      \verb https://doi.org/10.48550/arXiv.2406.02638
      \endverb
    \endentry
    \entry{Wu2021}{misc}{}{}
      \name{author}{7}{}{%
        {{hash=ea8d9f16c5d553a2ed2a4c26be5b191e}{%
           family={Wu},
           familyi={W\bibinitperiod},
           given={Jiancan},
           giveni={J\bibinitperiod}}}%
        {{hash=8fde8559617f603b3e2b3cf30cb48e9b}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Xiang},
           giveni={X\bibinitperiod}}}%
        {{hash=9090db11da70fe0d8b95cbf3d73a6216}{%
           family={Feng},
           familyi={F\bibinitperiod},
           given={Fuli},
           giveni={F\bibinitperiod}}}%
        {{hash=cf3f1b6bfe8e9131a8c719c1af0dce5d}{%
           family={He},
           familyi={H\bibinitperiod},
           given={Xiangnan},
           giveni={X\bibinitperiod}}}%
        {{hash=ddc1e4faf59edc7d7675723be4296244}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Liang},
           giveni={L\bibinitperiod}}}%
        {{hash=0838975efd823c96d9fe318998235b56}{%
           family={Lian},
           familyi={L\bibinitperiod},
           given={Jianxun},
           giveni={J\bibinitperiod}}}%
        {{hash=0801da56d6877e3eff32e6a6030425d3}{%
           family={Xie},
           familyi={X\bibinitperiod},
           given={Xing},
           giveni={X\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{fdeed692c8f795b4ce67c446a05693c7}
      \strng{fullhash}{ad26aa9124774b659858abbf93830fb9}
      \strng{fullhashraw}{ad26aa9124774b659858abbf93830fb9}
      \strng{bibnamehash}{ad26aa9124774b659858abbf93830fb9}
      \strng{authorbibnamehash}{ad26aa9124774b659858abbf93830fb9}
      \strng{authornamehash}{fdeed692c8f795b4ce67c446a05693c7}
      \strng{authorfullhash}{ad26aa9124774b659858abbf93830fb9}
      \strng{authorfullhashraw}{ad26aa9124774b659858abbf93830fb9}
      \field{extraname}{1}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Representation learning on user-item graph for recommendation has evolved from using single ID or interaction history to exploiting higher-order neighbors. This leads to the success of graph convolution networks (GCNs) for recommendation such as PinSage and LightGCN. Despite effectiveness, we argue that they suffer from two limitations: (1) high-degree nodes exert larger impact on the representation learning, deteriorating the recommendations of low-degree (long-tail) items; and (2) representations are vulnerable to noisy interactions, as the neighborhood aggregation scheme further enlarges the impact of observed edges.In this work, we explore self-supervised learning on user-item graph, so as to improve the accuracy and robustness of GCNs for recommendation. The idea is to supplement the classical supervised task of recommendation with an auxiliary self-supervised task, which reinforces node representation learning via self-discrimination. Specifically, we generate multiple views of a node, maximizing the agreement between different views of the same node compared to that of other nodes. We devise three operators to generate the views --- node dropout, edge dropout, and random walk --- that change the graph structure in different manners. We term this new learning paradigm asSelf-supervised Graph Learning (SGL), implementing it on the state-of-the-art model LightGCN. Through theoretical analyses, we find that SGL has the ability of automatically mining hard negatives. Empirical studies on three benchmark datasets demonstrate the effectiveness of SGL, which improves the recommendation accuracy, especially on long-tail items, and the robustness against interaction noises. Our implementations are available at urlhttps://github.com/wujcan/SGL.}
      \field{note}{New York, NY, USA}
      \field{title}{Self-supervised Graph Learning for Recommendation}
      \field{year}{2021}
      \field{pages}{726\bibrangedash 735}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1145/3404835.3462862
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3404835.3462862
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3404835.3462862
      \endverb
      \keyw{collaborative filtering,graph neural network,long-tail recommendation,self-supervised learning}
    \endentry
    \entry{Wu2019_DiffNet}{misc}{}{}
      \name{author}{6}{}{%
        {{hash=fa1018e5a64f8c77d48cc132dae15d52}{%
           family={Wu},
           familyi={W\bibinitperiod},
           given={Le},
           giveni={L\bibinitperiod}}}%
        {{hash=365506d07be05155d769084f8a0490f4}{%
           family={Sun},
           familyi={S\bibinitperiod},
           given={Peijie},
           giveni={P\bibinitperiod}}}%
        {{hash=30ae9e14692d8631346a8a8ab6beebd5}{%
           family={Fu},
           familyi={F\bibinitperiod},
           given={Yanjie},
           giveni={Y\bibinitperiod}}}%
        {{hash=383491f887acc2dc4bf1c772728943da}{%
           family={Hong},
           familyi={H\bibinitperiod},
           given={Richang},
           giveni={R\bibinitperiod}}}%
        {{hash=465d9de4befead1025d5f95c6db12a4a}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Xiting},
           giveni={X\bibinitperiod}}}%
        {{hash=00b734eb3fb588e4c6c94e4271080d0b}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Meng},
           giveni={M\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{7c7df1dafdf244f629928a41fd9e041f}
      \strng{fullhash}{0900d6a82c560e0a8bd7639382f5d174}
      \strng{fullhashraw}{0900d6a82c560e0a8bd7639382f5d174}
      \strng{bibnamehash}{0900d6a82c560e0a8bd7639382f5d174}
      \strng{authorbibnamehash}{0900d6a82c560e0a8bd7639382f5d174}
      \strng{authornamehash}{7c7df1dafdf244f629928a41fd9e041f}
      \strng{authorfullhash}{0900d6a82c560e0a8bd7639382f5d174}
      \strng{authorfullhashraw}{0900d6a82c560e0a8bd7639382f5d174}
      \field{extraname}{2}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Precise user and item embedding learning is the key to building a successful recommender system. Traditionally, Collaborative Filtering (CF) provides a way to learn user and item embeddings from the user-item interaction history. However, the performance is limited due to the sparseness of user behavior data. With the emergence of online social networks, social recommender systems have been proposed to utilize each user's local neighbors' preferences to alleviate the data sparsity for better user embedding modeling. We argue that, for each user of a social platform, her potential embedding is influenced by her trusted users, with these trusted users are influenced by the trusted users' social connections. As social influence recursively propagates and diffuses in the social network, each user's interests change in the recursive process. Nevertheless, the current social recommendation models simply developed static models by leveraging the local neighbors of each user without simulating the recursive diffusion in the global social network, leading to suboptimal recommendation performance. In this paper, we propose a deep influence propagation model to stimulate how users are influenced by the recursive social diffusion process for social recommendation. For each user, the diffusion process starts with an initial embedding that fuses the related features and a free user latent vector that captures the latent behavior preference. The key idea of our proposed model is that we design a layer-wise influence propagation structure to model how users' latent embeddings evolve as the social diffusion process continues. We further show that our proposed model is general and could be applied when the user (item) attributes or the social network structure is not available. Finally, extensive experimental results on two real-world datasets clearly show the effectiveness of our proposed model, with more than 13{\%} performance improvements over the best baselines for top-10 recommendation on the two datasets.}
      \field{note}{New York, NY, USA}
      \field{title}{A Neural Influence Diffusion Model for Social Recommendation}
      \field{year}{2019}
      \field{pages}{235\bibrangedash 244}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1145/3331184.3331214
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3331184.3331214
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3331184.3331214
      \endverb
      \keyw{graph neural networks,influence diffusion,personalization,social recommendation}
    \endentry
    \entry{Wu2022}{article}{}{}
      \name{author}{5}{}{%
        {{hash=4375d75710702c65a026c6682889ce76}{%
           family={Wu},
           familyi={W\bibinitperiod},
           given={Shiwen},
           giveni={S\bibinitperiod}}}%
        {{hash=0fff2d014f575fc5d680e70e02e8ce38}{%
           family={Sun},
           familyi={S\bibinitperiod},
           given={Fei},
           giveni={F\bibinitperiod}}}%
        {{hash=617c3dfefd9eb92b86137977ec96fa36}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Wentao},
           giveni={W\bibinitperiod}}}%
        {{hash=3c4ae59f378e63f88f337a9748b63ce9}{%
           family={Xie},
           familyi={X\bibinitperiod},
           given={Xu},
           giveni={X\bibinitperiod}}}%
        {{hash=f6c0b53300ebf4c432dfa05ee736c54c}{%
           family={Cui},
           familyi={C\bibinitperiod},
           given={Bin},
           giveni={B\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{59733ab0ac2629860a1a24d5013fadf9}
      \strng{fullhash}{8fd91e8d37444f61d9462ec295d2d1d9}
      \strng{fullhashraw}{8fd91e8d37444f61d9462ec295d2d1d9}
      \strng{bibnamehash}{8fd91e8d37444f61d9462ec295d2d1d9}
      \strng{authorbibnamehash}{8fd91e8d37444f61d9462ec295d2d1d9}
      \strng{authornamehash}{59733ab0ac2629860a1a24d5013fadf9}
      \strng{authorfullhash}{8fd91e8d37444f61d9462ec295d2d1d9}
      \strng{authorfullhashraw}{8fd91e8d37444f61d9462ec295d2d1d9}
      \field{extraname}{3}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{With the explosive growth of online information, recommender systems play a key role to alleviate such information overload. Due to the important application value of recommender systems, there have always been emerging works in this field. In recommender systems, the main challenge is to learn the effective user/item representations from their interactions and side information (if any). Recently, graph neural network (GNN) techniques have been widely utilized in recommender systems since most of the information in recommender systems essentially has graph structure and GNN has superiority in graph representation learning. This article aims to provide a comprehensive review of recent research efforts on GNN-based recommender systems. Specifically, we provide a taxonomy of GNN-based recommendation models according to the types of information used and recommendation tasks. Moreover, we systematically analyze the challenges of applying GNN on different types of data and discuss how existing works in this field address these challenges. Furthermore, we state new perspectives pertaining to the development of this field. We collect the representative papers along with their open-source implementations in .}
      \field{issn}{0360-0300}
      \field{journaltitle}{ACM Comput. Surv.}
      \field{month}{12}
      \field{number}{5}
      \field{title}{Graph Neural Networks in Recommender Systems: A Survey}
      \field{volume}{55}
      \field{year}{2022}
      \verb{doi}
      \verb 10.1145/3535101
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3535101
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3535101
      \endverb
      \keyw{Recommender system,graph neural network,survey}
    \endentry
    \entry{Wu2019_SRGNN}{article}{}{}
      \name{author}{6}{}{%
        {{hash=d5cac0e55ceb387c5e6cfb97fd6ddcd4}{%
           family={Wu},
           familyi={W\bibinitperiod},
           given={Shu},
           giveni={S\bibinitperiod}}}%
        {{hash=e5aaff38f2e10193801f66ae8528ad05}{%
           family={Tang},
           familyi={T\bibinitperiod},
           given={Yuyuan},
           giveni={Y\bibinitperiod}}}%
        {{hash=632c1e5003d479abe750505c02f38c1a}{%
           family={Zhu},
           familyi={Z\bibinitperiod},
           given={Yanqiao},
           giveni={Y\bibinitperiod}}}%
        {{hash=cce05cab2c437e9c128f853684ee3137}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Liang},
           giveni={L\bibinitperiod}}}%
        {{hash=0801da56d6877e3eff32e6a6030425d3}{%
           family={Xie},
           familyi={X\bibinitperiod},
           given={Xing},
           giveni={X\bibinitperiod}}}%
        {{hash=116ce38201da138f399dde04290058b8}{%
           family={Tan},
           familyi={T\bibinitperiod},
           given={Tieniu},
           giveni={T\bibinitperiod}}}%
      }
      \strng{namehash}{d5ed9b1b5eb10fc9bd3e07803a79ad26}
      \strng{fullhash}{ca1202b76bd66881bc9d61f53692d99f}
      \strng{fullhashraw}{ca1202b76bd66881bc9d61f53692d99f}
      \strng{bibnamehash}{ca1202b76bd66881bc9d61f53692d99f}
      \strng{authorbibnamehash}{ca1202b76bd66881bc9d61f53692d99f}
      \strng{authornamehash}{d5ed9b1b5eb10fc9bd3e07803a79ad26}
      \strng{authorfullhash}{ca1202b76bd66881bc9d61f53692d99f}
      \strng{authorfullhashraw}{ca1202b76bd66881bc9d61f53692d99f}
      \field{extraname}{4}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{{\&}lt;p{\&}gt;The problem of session-based recommendation aims to predict user actions based on anonymous sessions. Previous methods model a session as a sequence and estimate user representations besides item representations to make recommendations. Though achieved promising results, they are insufficient to obtain accurate user vectors in sessions and neglect complex transitions of items. To obtain accurate item embedding and take complex transitions of items into account, we propose a novel method, i.e. {\&}lt;em{\&}gt;Session-based Recommendation with Graph Neural Networks{\&}lt;/em{\&}gt;, SR-GNN for brevity. In the proposed method, session sequences are modeled as graphstructured data. Based on the session graph, GNN can capture complex transitions of items, which are difficult to be revealed by previous conventional sequential methods. Each session is then represented as the composition of the global preference and the current interest of that session using an attention network. Extensive experiments conducted on two real datasets show that SR-GNN evidently outperforms the state-of-the-art session-based recommendation methods consistently.{\&}lt;/p{\&}gt;}
      \field{journaltitle}{Proceedings of the AAAI Conference on Artificial Intelligence}
      \field{month}{7}
      \field{number}{01}
      \field{title}{Session-Based Recommendation with Graph Neural Networks}
      \field{volume}{33}
      \field{year}{2019}
      \field{pages}{346\bibrangedash 353}
      \range{pages}{8}
      \verb{doi}
      \verb 10.1609/aaai.v33i01.3301346
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1609/aaai.v33i01.3301346
      \endverb
      \verb{url}
      \verb https://doi.org/10.1609/aaai.v33i01.3301346
      \endverb
    \endentry
    \entry{Xiao2025}{article}{}{}
      \name{author}{4}{}{%
        {{hash=e276ae26977a9b2e37343fd9ee050e70}{%
           family={Xiao},
           familyi={X\bibinitperiod},
           given={Wei},
           giveni={W\bibinitperiod}}}%
        {{hash=8d4cb371d4f2abbdb32e4428b3f0ecdd}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Huiying},
           giveni={H\bibinitperiod}}}%
        {{hash=2ca95e14023c484875da6fe7d7777c0d}{%
           family={Zhou},
           familyi={Z\bibinitperiod},
           given={Qifeng},
           giveni={Q\bibinitperiod}}}%
        {{hash=07a750250bc37c9181998579542af8c2}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Qing},
           giveni={Q\bibinitperiod}}}%
      }
      \strng{namehash}{7bac66f783c5c1c4cfbf4b79b50d0e4f}
      \strng{fullhash}{cb81b7fc34969f9792672aeb0826d570}
      \strng{fullhashraw}{cb81b7fc34969f9792672aeb0826d570}
      \strng{bibnamehash}{cb81b7fc34969f9792672aeb0826d570}
      \strng{authorbibnamehash}{cb81b7fc34969f9792672aeb0826d570}
      \strng{authornamehash}{7bac66f783c5c1c4cfbf4b79b50d0e4f}
      \strng{authorfullhash}{cb81b7fc34969f9792672aeb0826d570}
      \strng{authorfullhashraw}{cb81b7fc34969f9792672aeb0826d570}
      \field{sortinit}{X}
      \field{sortinithash}{1965c258adceecf23ce3d67b05113442}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Sequential recommendation is a key area in the field of recommendation systems aiming to model user interest based on historical interaction sequences with irregular intervals. We propose SS4Rec, which integrates a time-aware SSM to handle irregular time intervals and a relation-aware SSM to model contextual dependencies, enabling it to infer user interest from both temporal and sequential perspectives.}
      \field{journaltitle}{arXiv preprint arXiv:2502.08132}
      \field{month}{2}
      \field{title}{SS4Rec: Continuous-Time Sequential Recommendation with State Space Models}
      \field{year}{2025}
      \verb{doi}
      \verb 10.48550/arXiv.2502.08132
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.48550/arXiv.2502.08132
      \endverb
      \verb{url}
      \verb https://doi.org/10.48550/arXiv.2502.08132
      \endverb
    \endentry
    \entry{Ying2018}{misc}{}{}
      \name{author}{6}{}{%
        {{hash=6b37c8aefa150635663b2a6525952a7a}{%
           family={Ying},
           familyi={Y\bibinitperiod},
           given={Rex},
           giveni={R\bibinitperiod}}}%
        {{hash=1b8a48b9ddb1c09f1c48bd467d99488a}{%
           family={He},
           familyi={H\bibinitperiod},
           given={Ruining},
           giveni={R\bibinitperiod}}}%
        {{hash=806c56ba82f07f26518a4de5caf6b2b6}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Kaifeng},
           giveni={K\bibinitperiod}}}%
        {{hash=2146d3b9f777d15a77c7ff17474e9ad9}{%
           family={Eksombatchai},
           familyi={E\bibinitperiod},
           given={Pong},
           giveni={P\bibinitperiod}}}%
        {{hash=2abce6c40b4cc1a3d89f175883b24536}{%
           family={Hamilton},
           familyi={H\bibinitperiod},
           given={William\bibnamedelima L.},
           giveni={W\bibinitperiod\bibinitdelim L\bibinitperiod}}}%
        {{hash=900d107125ff0ca84698cb909e4f6c51}{%
           family={Leskovec},
           familyi={L\bibinitperiod},
           given={Jure},
           giveni={J\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{abe60498875b44b92d8ff87a690002b1}
      \strng{fullhash}{7aa9b85fe91011148b5ed02b4ca83c49}
      \strng{fullhashraw}{7aa9b85fe91011148b5ed02b4ca83c49}
      \strng{bibnamehash}{7aa9b85fe91011148b5ed02b4ca83c49}
      \strng{authorbibnamehash}{7aa9b85fe91011148b5ed02b4ca83c49}
      \strng{authornamehash}{abe60498875b44b92d8ff87a690002b1}
      \strng{authorfullhash}{7aa9b85fe91011148b5ed02b4ca83c49}
      \strng{authorfullhashraw}{7aa9b85fe91011148b5ed02b4ca83c49}
      \field{sortinit}{Y}
      \field{sortinithash}{fd67ad5a9ef0f7456bdd9aab10fe1495}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Recent advancements in deep neural networks for graph-structured data have led to state-of-the-art performance on recommender system benchmarks. However, making these methods practical and scalable to web-scale recommendation tasks with billions of items and hundreds of millions of users remains an unsolved challenge. Here we describe a large-scale deep recommendation engine that we developed and deployed at Pinterest. We develop a data-efficient Graph Convolutional Network (GCN) algorithm, which combines efficient random walks and graph convolutions to generate embeddings of nodes (i.e., items) that incorporate both graph structure as well as node feature information. Compared to prior GCN approaches, we develop a novel method based on highly efficient random walks to structure the convolutions and design a novel training strategy that relies on harder-and-harder training examples to improve robustness and convergence of the model. We also develop an efficient MapReduce model inference algorithm to generate embeddings using a trained model. Overall, we can train on and embed graphs that are four orders of magnitude larger than typical GCN implementations. We show how GCN embeddings can be used to make high-quality recommendations in various settings at Pinterest, which has a massive underlying graph with 3 billion nodes representing pins and boards, and 17 billion edges. According to offline metrics, user studies, as well as A/B tests, our approach generates higher-quality recommendations than comparable deep learning based systems. To our knowledge, this is by far the largest application of deep graph embeddings to date and paves the way for a new generation of web-scale recommender systems based on graph convolutional architectures.}
      \field{note}{New York, NY, USA}
      \field{title}{Graph Convolutional Neural Networks for Web-Scale Recommender Systems}
      \field{year}{2018}
      \field{pages}{974\bibrangedash 983}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1145/3219819.3219890
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3219819.3219890
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3219819.3219890
      \endverb
      \keyw{scalability,recommender systems,graph convolutional networks,deep learning}
    \endentry
    \entry{Yu2024}{article}{}{}
      \name{author}{6}{}{%
        {{hash=89b432fa4bb24ef9e7312fd806fb771b}{%
           family={Yu},
           familyi={Y\bibinitperiod},
           given={J.},
           giveni={J\bibinitperiod}}}%
        {{hash=d2c98597f95b4e5de3ecaabeed2e3c10}{%
           family={Yin},
           familyi={Y\bibinitperiod},
           given={H.},
           giveni={H\bibinitperiod}}}%
        {{hash=0088600888dd582c37cfeb4663ad46f9}{%
           family={Xia},
           familyi={X\bibinitperiod},
           given={X.},
           giveni={X\bibinitperiod}}}%
        {{hash=17541c65107086b7d7dd596d7ad81405}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={T.},
           giveni={T\bibinitperiod}}}%
        {{hash=ef065b28c31984323fd6d3483d29aafd}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={J.},
           giveni={J\bibinitperiod}}}%
        {{hash=038f0fdd7e236813f6a46ced7288f3c1}{%
           family={Huang},
           familyi={H\bibinitperiod},
           given={Z.},
           giveni={Z\bibinitperiod}}}%
      }
      \strng{namehash}{ebf31d2ea71f502eefb31d4563831d49}
      \strng{fullhash}{4119b6b3750da411143c31603edf6fdf}
      \strng{fullhashraw}{4119b6b3750da411143c31603edf6fdf}
      \strng{bibnamehash}{4119b6b3750da411143c31603edf6fdf}
      \strng{authorbibnamehash}{4119b6b3750da411143c31603edf6fdf}
      \strng{authornamehash}{ebf31d2ea71f502eefb31d4563831d49}
      \strng{authorfullhash}{4119b6b3750da411143c31603edf6fdf}
      \strng{authorfullhashraw}{4119b6b3750da411143c31603edf6fdf}
      \field{extraname}{1}
      \field{sortinit}{Y}
      \field{sortinithash}{fd67ad5a9ef0f7456bdd9aab10fe1495}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{1558-2191}
      \field{journaltitle}{IEEE Transactions on Knowledge and Data Engineering}
      \field{number}{1}
      \field{title}{Self-Supervised Learning for Recommender Systems: A Survey}
      \field{volume}{36}
      \field{year}{2024}
      \field{pages}{335\bibrangedash 355}
      \range{pages}{21}
      \verb{doi}
      \verb 10.1109/TKDE.2023.3282907
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1109/TKDE.2023.3282907
      \endverb
      \verb{url}
      \verb https://doi.org/10.1109/TKDE.2023.3282907
      \endverb
    \endentry
    \entry{Yu2021}{misc}{}{}
      \name{author}{6}{}{%
        {{hash=2f77368a25dacefba7f868b398b1c2da}{%
           family={Yu},
           familyi={Y\bibinitperiod},
           given={Junliang},
           giveni={J\bibinitperiod}}}%
        {{hash=684a7485a58d733155967691eae9a57f}{%
           family={Yin},
           familyi={Y\bibinitperiod},
           given={Hongzhi},
           giveni={H\bibinitperiod}}}%
        {{hash=e65a1a296c495b084e18c6871049b59e}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Jundong},
           giveni={J\bibinitperiod}}}%
        {{hash=67b37afc884ac475d05f012eca3b4a9b}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Qinyong},
           giveni={Q\bibinitperiod}}}%
        {{hash=788d1f0cd454e1118bc96b95dbe8fcf6}{%
           family={Hung},
           familyi={H\bibinitperiod},
           given={Nguyen\bibnamedelimb Quoc\bibnamedelima Viet},
           giveni={N\bibinitperiod\bibinitdelim Q\bibinitperiod\bibinitdelim V\bibinitperiod}}}%
        {{hash=78602a740c55ebc62bc5530e131d12d1}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Xiangliang},
           giveni={X\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{4110d32e948c870f2121f9775141c5c9}
      \strng{fullhash}{ba34bbecd5d2f226c78064736869d4f1}
      \strng{fullhashraw}{ba34bbecd5d2f226c78064736869d4f1}
      \strng{bibnamehash}{ba34bbecd5d2f226c78064736869d4f1}
      \strng{authorbibnamehash}{ba34bbecd5d2f226c78064736869d4f1}
      \strng{authornamehash}{4110d32e948c870f2121f9775141c5c9}
      \strng{authorfullhash}{ba34bbecd5d2f226c78064736869d4f1}
      \strng{authorfullhashraw}{ba34bbecd5d2f226c78064736869d4f1}
      \field{extraname}{2}
      \field{sortinit}{Y}
      \field{sortinithash}{fd67ad5a9ef0f7456bdd9aab10fe1495}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Social relations are often used to improve recommendation quality when user-item interaction data is sparse in recommender systems. Most existing social recommendation models exploit pairwise relations to mine potential user preferences. However, real-life interactions among users are very complex and user relations can be high-order. Hypergraph provides a natural way to model high-order relations, while its potentials for improving social recommendation are under-explored. In this paper, we fill this gap and propose a multi-channel hypergraph convolutional network to enhance social recommendation by leveraging high-order user relations. Technically, each channel in the network encodes a hypergraph that depicts a common high-order user relation pattern via hypergraph convolution. By aggregating the embeddings learned through multiple channels, we obtain comprehensive user representations to generate recommendation results. However, the aggregation operation might also obscure the inherent characteristics of different types of high-order connectivity information. To compensate for the aggregating loss, we innovatively integrate self-supervised learning into the training of the hypergraph convolutional network to regain the connectivity information with hierarchical mutual information maximization. Extensive experiments on multiple real-world datasets demonstrate the superiority of the proposed model over the current SOTA methods, and the ablation study verifies the effectiveness and rationale of the multi-channel setting and the self-supervised task. The implementation of our model is available via https://github.com/Coder-Yu/RecQ.}
      \field{note}{New York, NY, USA}
      \field{title}{Self-Supervised Multi-Channel Hypergraph Convolutional Network for Social Recommendation}
      \field{year}{2021}
      \field{pages}{413\bibrangedash 424}
      \range{pages}{12}
      \verb{doi}
      \verb 10.1145/3442381.3449844
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3442381.3449844
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3442381.3449844
      \endverb
      \keyw{Graph Convolutional Network,Hypergraph Learning,Recommender Systems,Self-supervised Learning,Social Recommendation}
    \endentry
    \entry{Yu2022}{misc}{}{}
      \name{author}{6}{}{%
        {{hash=2f77368a25dacefba7f868b398b1c2da}{%
           family={Yu},
           familyi={Y\bibinitperiod},
           given={Junliang},
           giveni={J\bibinitperiod}}}%
        {{hash=684a7485a58d733155967691eae9a57f}{%
           family={Yin},
           familyi={Y\bibinitperiod},
           given={Hongzhi},
           giveni={H\bibinitperiod}}}%
        {{hash=389bc525f2088642cfd16749beb3312e}{%
           family={Xia},
           familyi={X\bibinitperiod},
           given={Xin},
           giveni={X\bibinitperiod}}}%
        {{hash=84e53870b10b90866b8483be8fe5a60e}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Tong},
           giveni={T\bibinitperiod}}}%
        {{hash=375f79f434e65b63f3750a03a388ed99}{%
           family={Cui},
           familyi={C\bibinitperiod},
           given={Lizhen},
           giveni={L\bibinitperiod}}}%
        {{hash=2fff699c67514c16f4375166b14bf88d}{%
           family={Nguyen},
           familyi={N\bibinitperiod},
           given={Quoc\bibnamedelimb Viet\bibnamedelima Hung},
           giveni={Q\bibinitperiod\bibinitdelim V\bibinitperiod\bibinitdelim H\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{4110d32e948c870f2121f9775141c5c9}
      \strng{fullhash}{d54351fd0f1ede02d5d5f2af02c4a8ac}
      \strng{fullhashraw}{d54351fd0f1ede02d5d5f2af02c4a8ac}
      \strng{bibnamehash}{d54351fd0f1ede02d5d5f2af02c4a8ac}
      \strng{authorbibnamehash}{d54351fd0f1ede02d5d5f2af02c4a8ac}
      \strng{authornamehash}{4110d32e948c870f2121f9775141c5c9}
      \strng{authorfullhash}{d54351fd0f1ede02d5d5f2af02c4a8ac}
      \strng{authorfullhashraw}{d54351fd0f1ede02d5d5f2af02c4a8ac}
      \field{extraname}{3}
      \field{sortinit}{Y}
      \field{sortinithash}{fd67ad5a9ef0f7456bdd9aab10fe1495}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Contrastive learning (CL) recently has spurred a fruitful line of research in the field of recommendation, since its ability to extract self-supervised signals from the raw data is well-aligned with recommender systems' needs for tackling the data sparsity issue. A typical pipeline of CL-based recommendation models is first augmenting the user-item bipartite graph with structure perturbations, and then maximizing the node representation consistency between different graph augmentations. Although this paradigm turns out to be effective, what underlies the performance gains is still a mystery. In this paper, we first experimentally disclose that, in CL-based recommendation models, CL operates by learning more uniform user/item representations that can implicitly mitigate the popularity bias. Meanwhile, we reveal that the graph augmentations, which used to be considered necessary, just play a trivial role. Based on this finding, we propose a simple CL method which discards the graph augmentations and instead adds uniform noises to the embedding space for creating contrastive views. A comprehensive experimental study on three benchmark datasets demonstrates that, though it appears strikingly simple, the proposed method can smoothly adjust the uniformity of learned representations and has distinct advantages over its graph augmentation-based counterparts in terms of recommendation accuracy and training efficiency. The code is released at https://github.com/Coder-Yu/QRec.}
      \field{note}{New York, NY, USA}
      \field{title}{Are Graph Augmentations Necessary? Simple Graph Contrastive Learning for Recommendation}
      \field{year}{2022}
      \field{pages}{1294\bibrangedash 1303}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1145/3477495.3531937
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3477495.3531937
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3477495.3531937
      \endverb
      \keyw{contrastive learning,data augmentation,recommendation,self-supervised learning}
    \endentry
    \entry{Zhang2019}{article}{}{}
      \name{author}{4}{}{%
        {{hash=53eda2415f95a1d1f76572f661905aab}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Shuai},
           giveni={S\bibinitperiod}}}%
        {{hash=3f0f958e6b8421de727e2c1977907d6a}{%
           family={Yao},
           familyi={Y\bibinitperiod},
           given={Lina},
           giveni={L\bibinitperiod}}}%
        {{hash=8b562490f05b03da5ef1aca562e8b589}{%
           family={Sun},
           familyi={S\bibinitperiod},
           given={Aixin},
           giveni={A\bibinitperiod}}}%
        {{hash=7579658a0aca8cb0e17a89deb28b8ccc}{%
           family={Tay},
           familyi={T\bibinitperiod},
           given={Yi},
           giveni={Y\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{99449cc3aa6f0fbe8a4f7e40ac6da48a}
      \strng{fullhash}{04bf8a18134c1ab7195508609c6c8f40}
      \strng{fullhashraw}{04bf8a18134c1ab7195508609c6c8f40}
      \strng{bibnamehash}{04bf8a18134c1ab7195508609c6c8f40}
      \strng{authorbibnamehash}{04bf8a18134c1ab7195508609c6c8f40}
      \strng{authornamehash}{99449cc3aa6f0fbe8a4f7e40ac6da48a}
      \strng{authorfullhash}{04bf8a18134c1ab7195508609c6c8f40}
      \strng{authorfullhashraw}{04bf8a18134c1ab7195508609c6c8f40}
      \field{extraname}{1}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{With the growing volume of online information, recommender systems have been an effective strategy to overcome information overload. The utility of recommender systems cannot be overstated, given their widespread adoption in many web applications, along with their potential impact to ameliorate many problems related to over-choice. In recent years, deep learning has garnered considerable interest in many research fields such as computer vision and natural language processing, owing not only to stellar performance but also to the attractive property of learning feature representations from scratch. The influence of deep learning is also pervasive, recently demonstrating its effectiveness when applied to information retrieval and recommender systems research. The field of deep learning in recommender system is flourishing. This article aims to provide a comprehensive review of recent research efforts on deep learning-based recommender systems. More concretely, we provide and devise a taxonomy of deep learning-based recommendation models, along with a comprehensive summary of the state of the art. Finally, we expand on current trends and provide new perspectives pertaining to this new and exciting development of the field.}
      \field{issn}{0360-0300}
      \field{journaltitle}{ACM Comput. Surv.}
      \field{month}{2}
      \field{number}{1}
      \field{title}{Deep Learning Based Recommender System: A Survey and New Perspectives}
      \field{volume}{52}
      \field{year}{2019}
      \verb{doi}
      \verb 10.1145/3285029
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3285029
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3285029
      \endverb
      \keyw{survey,deep learning,Recommender system}
    \endentry
    \entry{Zhang2025}{inproceedings}{}{}
      \name{author}{4}{}{%
        {{hash=a3739bbe1787246c16692bfb043543a2}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Shun},
           giveni={S\bibinitperiod}}}%
        {{hash=72c05cd8e1a145a5c2910a03987fb299}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Runsen},
           giveni={R\bibinitperiod}}}%
        {{hash=bf1f93beddade7ab838eba8b041179e6}{%
           family={Yin},
           familyi={Y\bibinitperiod},
           given={Ziqiang},
           giveni={Z\bibinitperiod}}}%
        {{hash=dc0b0af8178dab565be331d1dc0f039b}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Zhirong},
           giveni={Z\bibinitperiod}}}%
      }
      \name{editor}{4}{}{%
        {{hash=9174f234e6e6f6ca1d35a398d0a7d5b1}{%
           family={Huang},
           familyi={H\bibinitperiod},
           given={De-Shuang},
           giveni={D\bibinithyphendelim S\bibinitperiod}}}%
        {{hash=06debc36f6b61a405e8f0da1c7ccd6ca}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Wei},
           giveni={W\bibinitperiod}}}%
        {{hash=896ecab4e96f7afcbf9a5f9521f6f823}{%
           family={Pan},
           familyi={P\bibinitperiod},
           given={Yijie},
           giveni={Y\bibinitperiod}}}%
        {{hash=e027b7c3363d0abd99dfd12d2a81cd68}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Haiming},
           giveni={H\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Singapore}%
      }
      \list{publisher}{1}{%
        {Springer Nature Singapore}%
      }
      \strng{namehash}{9cfb7ca0f332e388f9b5dda91f9bc0ba}
      \strng{fullhash}{8bff2bb479a32b8a2cdf63d08ce116ae}
      \strng{fullhashraw}{8bff2bb479a32b8a2cdf63d08ce116ae}
      \strng{bibnamehash}{8bff2bb479a32b8a2cdf63d08ce116ae}
      \strng{authorbibnamehash}{8bff2bb479a32b8a2cdf63d08ce116ae}
      \strng{authornamehash}{9cfb7ca0f332e388f9b5dda91f9bc0ba}
      \strng{authorfullhash}{8bff2bb479a32b8a2cdf63d08ce116ae}
      \strng{authorfullhashraw}{8bff2bb479a32b8a2cdf63d08ce116ae}
      \strng{editorbibnamehash}{acd98cc0a70239bd7ef2bcde5bd26e8f}
      \strng{editornamehash}{e11ab120d968ed45f6ac73208fc0ffce}
      \strng{editorfullhash}{acd98cc0a70239bd7ef2bcde5bd26e8f}
      \strng{editorfullhashraw}{acd98cc0a70239bd7ef2bcde5bd26e8f}
      \field{extraname}{2}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Sequential recommendation techniques aim at providing personalized recommendations by analyzing the dynamic preferences and sequential dependencies in user behavior sequences. However, dense datasets consisting of long sequences have the difficulty of fully capturing the sequential dependencies within historical user behaviors, while sparsity datasets of short sequences often struggle to extract sufficient interaction information due to the limited historical user behaviors. These challenges lead to undesirable recommendation performance and exacerbate the difficulty of achieving effective recommendations in sparse data scenarios. Then, we propose a novel sequential recommendation model named MaTrRec that integrates Mamba and Transformer. This model leverages the linear complexity advantages of Mamba while effectively enhancing sequential dependency modeling through its state-space representation and efficient sequential processing capabilities in continuous space, enabling the extraction of deeper sequential information from historical user behaviors. Moreover, it utilizes the global attention mechanism of Transformer to thoroughly explore the dependencies among items in historical user behaviors, thereby enhancing the model's predictive performance and robustness across both long and short sequence datasets by effectively capturing both local and global contextual information. To further optimize the computational complexity of the model, we design a linear sequential recommendation model called MaTrRec*, which reduces the computational complexity through a linear attention mechanism and effectively balances the complexity and recommendation accuracy. Experimental valuations on five widely used public datasets demonstrate that MaTrRec and MaTrRec* outperform the state-of-the-art sequential recommendation models. Our MaTrRec can significantly achieve up to 8.49{\%} higher model accuracy. Code: https://github.com/Unintelligentmumu/MaTrRec.}
      \field{booktitle}{Advanced Intelligent Computing Technology and Applications}
      \field{isbn}{978-981-95-0017-8}
      \field{title}{MaTrRec: A Mamba-Transformer Framework for Robust Sequential Recommendation}
      \field{year}{2025}
      \field{pages}{448\bibrangedash 459}
      \range{pages}{12}
      \verb{doi}
      \verb 10.48550/arXiv.2407.19239
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.48550/arXiv.2407.19239
      \endverb
      \verb{url}
      \verb https://doi.org/10.48550/arXiv.2407.19239
      \endverb
    \endentry
    \entry{Zhang2020}{article}{}{}
      \name{author}{2}{}{%
        {{hash=fd8216a36735a9f3107aef444551ecb2}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Yongfeng},
           giveni={Y\bibinitperiod}}}%
        {{hash=4f4900cae2c11cda82284d85107e92ae}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Xu},
           giveni={X\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Hanover, MA, USA}%
      }
      \list{publisher}{1}{%
        {Now Publishers Inc.}%
      }
      \strng{namehash}{b5ff90d6becebcc0a0b10069fceb79a5}
      \strng{fullhash}{b5ff90d6becebcc0a0b10069fceb79a5}
      \strng{fullhashraw}{b5ff90d6becebcc0a0b10069fceb79a5}
      \strng{bibnamehash}{b5ff90d6becebcc0a0b10069fceb79a5}
      \strng{authorbibnamehash}{b5ff90d6becebcc0a0b10069fceb79a5}
      \strng{authornamehash}{b5ff90d6becebcc0a0b10069fceb79a5}
      \strng{authorfullhash}{b5ff90d6becebcc0a0b10069fceb79a5}
      \strng{authorfullhashraw}{b5ff90d6becebcc0a0b10069fceb79a5}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Explainable recommendation attempts to develop models that generate not only high-quality recommendations but also intuitive explanations. The explanations may either be post-hoc or directly come from an explainable model (also called interpretable or transparent model in some contexts). Explainable recommendation tries to address the problem of why: by providing explanations to users or system designers, it helps humans to understand why certain items are recommended by the algorithm, where the human can either be users or system designers. Explainable recommendation helpsendation systems. It also facilitates system design to improve the transparency, persuasiveness, effectiveness, trustworthiness, and satisfaction of recommers for better system debugging. In recent years, a large number of explainable recommendation approaches -- especially model-based methods -- have been proposed and applied in real-world systems.In this survey, we provide a comprehensive review for the explainable recommendation research. We first highlight the position of explainable recommendation in recommender system research by categorizing recommendation problems into the 5W, i.e., what, when, who, where, and why. We then conduct a comprehensive survey of explainable recommendation on three perspectives: 1) We provide a chronological research timeline of explainable recommendation, including user study approaches in the early years and more recent model-based approaches. 2) We provide a two-dimensional taxonomy to classify existing explainable recommendation research: one dimension is the information source (or display style) of the explanations, and the other dimension is the algorithmic mechanism to generate explainable recommendations. 3) We summarize how explainable recommendation applies to different recommendation tasks, such as product recommendation, social recommendation, and POI recommendation.We also devote a section to discuss the explanation perspectives in broader IR and AI/ML research. We end the survey by discussing potential future directions to promote the explainable recommendation research area and beyond.}
      \field{issn}{1554-0669}
      \field{journaltitle}{Found. Trends Inf. Retr.}
      \field{month}{3}
      \field{number}{1}
      \field{title}{Explainable Recommendation: A Survey and New Perspectives}
      \field{volume}{14}
      \field{year}{2020}
      \field{pages}{1\bibrangedash 101}
      \range{pages}{101}
      \verb{doi}
      \verb 10.1561/1500000066
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1561/1500000066
      \endverb
      \verb{url}
      \verb https://doi.org/10.1561/1500000066
      \endverb
    \endentry
    \entry{Zhao2024}{article}{}{}
      \name{author}{11}{}{%
        {{hash=b34c3c1161c484ebb0bd152b415359db}{%
           family={Zhao},
           familyi={Z\bibinitperiod},
           given={Z.},
           giveni={Z\bibinitperiod}}}%
        {{hash=44daba4ecc7d571b0f2fb0568e9fa40b}{%
           family={Fan},
           familyi={F\bibinitperiod},
           given={W.},
           giveni={W\bibinitperiod}}}%
        {{hash=ef065b28c31984323fd6d3483d29aafd}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={J.},
           giveni={J\bibinitperiod}}}%
        {{hash=ce084360cc68e7db4fe6cae1287b3adf}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Y.},
           giveni={Y\bibinitperiod}}}%
        {{hash=199fccc51e70aacda359eab77e202198}{%
           family={Mei},
           familyi={M\bibinitperiod},
           given={X.},
           giveni={X\bibinitperiod}}}%
        {{hash=61ad10c626e1d641e0b1d7b5f48d3233}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Y.},
           giveni={Y\bibinitperiod}}}%
        {{hash=ea047479c8654da81b0d04041456b3ae}{%
           family={Wen},
           familyi={W\bibinitperiod},
           given={Z.},
           giveni={Z\bibinitperiod}}}%
        {{hash=3768cb3691d9f8be784a4b189ba55772}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={F.},
           giveni={F\bibinitperiod}}}%
        {{hash=b2ff85d118c95088c7ca004045563aa8}{%
           family={Zhao},
           familyi={Z\bibinitperiod},
           given={X.},
           giveni={X\bibinitperiod}}}%
        {{hash=cfc592e67cc246310d6f048315973684}{%
           family={Tang},
           familyi={T\bibinitperiod},
           given={J.},
           giveni={J\bibinitperiod}}}%
        {{hash=34eb0d3545d5a6175d27a342936002b1}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Q.},
           giveni={Q\bibinitperiod}}}%
      }
      \strng{namehash}{8501a8759d62823d8417a0c7fe05eb20}
      \strng{fullhash}{3dc1281638f0d60effb1f08c7922c729}
      \strng{fullhashraw}{3dc1281638f0d60effb1f08c7922c729}
      \strng{bibnamehash}{3dc1281638f0d60effb1f08c7922c729}
      \strng{authorbibnamehash}{3dc1281638f0d60effb1f08c7922c729}
      \strng{authornamehash}{8501a8759d62823d8417a0c7fe05eb20}
      \strng{authorfullhash}{3dc1281638f0d60effb1f08c7922c729}
      \strng{authorfullhashraw}{3dc1281638f0d60effb1f08c7922c729}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{1558-2191}
      \field{journaltitle}{IEEE Transactions on Knowledge and Data Engineering}
      \field{number}{11}
      \field{title}{Recommender Systems in the Era of Large Language Models (LLMs)}
      \field{volume}{36}
      \field{year}{2024}
      \field{pages}{6889\bibrangedash 6907}
      \range{pages}{19}
      \verb{doi}
      \verb 10.1109/TKDE.2024.3392335
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1109/TKDE.2024.3392335
      \endverb
      \verb{url}
      \verb https://doi.org/10.1109/TKDE.2024.3392335
      \endverb
    \endentry
    \entry{Zheng2018}{misc}{}{}
      \name{author}{7}{}{%
        {{hash=fc2303e573cbd4d55805cf3f63fb47ca}{%
           family={Zheng},
           familyi={Z\bibinitperiod},
           given={Guanjie},
           giveni={G\bibinitperiod}}}%
        {{hash=c123919bc93706c902dadde0f7fa0b04}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Fuzheng},
           giveni={F\bibinitperiod}}}%
        {{hash=db0cb71ed9ef782bb466be24f0336fb8}{%
           family={Zheng},
           familyi={Z\bibinitperiod},
           given={Zihan},
           giveni={Z\bibinitperiod}}}%
        {{hash=baa983e0769e57b7f9a497fc98e9a245}{%
           family={Xiang},
           familyi={X\bibinitperiod},
           given={Yang},
           giveni={Y\bibinitperiod}}}%
        {{hash=7b148e1061a6ad9bd829d4995ba34205}{%
           family={Yuan},
           familyi={Y\bibinitperiod},
           given={Nicholas\bibnamedelima Jing},
           giveni={N\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=0801da56d6877e3eff32e6a6030425d3}{%
           family={Xie},
           familyi={X\bibinitperiod},
           given={Xing},
           giveni={X\bibinitperiod}}}%
        {{hash=25ebc6d8b181f6379a65892949d0ddf3}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Zhenhui},
           giveni={Z\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {International World Wide Web Conferences Steering Committee}%
      }
      \strng{namehash}{978f133ed587a266aff6d824fb43a084}
      \strng{fullhash}{bc6b46f6a2f40e385a3d201d2792aaf5}
      \strng{fullhashraw}{bc6b46f6a2f40e385a3d201d2792aaf5}
      \strng{bibnamehash}{bc6b46f6a2f40e385a3d201d2792aaf5}
      \strng{authorbibnamehash}{bc6b46f6a2f40e385a3d201d2792aaf5}
      \strng{authornamehash}{978f133ed587a266aff6d824fb43a084}
      \strng{authorfullhash}{bc6b46f6a2f40e385a3d201d2792aaf5}
      \strng{authorfullhashraw}{bc6b46f6a2f40e385a3d201d2792aaf5}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper, we propose a novel Deep Reinforcement Learning framework for news recommendation. Online personalized news recommendation is a highly challenging problem due to the dynamic nature of news features and user preferences. Although some online recommendation models have been proposed to address the dynamic nature of news recommendation, these methods have three major issues. First, they only try to model current reward (e.g., Click Through Rate). Second, very few studies consider to use user feedback other than click / no click labels (e.g., how frequent user returns) to help improve recommendation. Third, these methods tend to keep recommending similar news to users, which may cause users to get bored. Therefore, to address the aforementioned challenges, we propose a Deep Q-Learning based recommendation framework, which can model future reward explicitly. We further consider user return pattern as a supplement to click / no click label in order to capture more user feedback information. In addition, an effective exploration strategy is incorporated to find new attractive news for users. Extensive experiments are conducted on the offline dataset and online production environment of a commercial news recommendation application and have shown the superior performance of our methods.}
      \field{note}{Republic and Canton of Geneva, CHE}
      \field{title}{DRN: A Deep Reinforcement Learning Framework for News Recommendation}
      \field{year}{2018}
      \field{pages}{167\bibrangedash 176}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1145/3178876.3185994
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3178876.3185994
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3178876.3185994
      \endverb
      \keyw{deep Q-Learning,news recommendation,reinforcement learning}
    \endentry
    \entry{Zhou2023}{misc}{}{}
      \name{author}{3}{}{%
        {{hash=47a465d4ac3f604967b0ee58efb190c1}{%
           family={Zhou},
           familyi={Z\bibinitperiod},
           given={Hongde},
           giveni={H\bibinitperiod}}}%
        {{hash=0494a2e24317dea84ee7278dce535558}{%
           family={Xiong},
           familyi={X\bibinitperiod},
           given={Fei},
           giveni={F\bibinitperiod}}}%
        {{hash=e87e8a8c9f80416167a7af5cae54e7e6}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Hongshu},
           giveni={H\bibinitperiod}}}%
      }
      \strng{namehash}{23dc7c4745667a5ad0b31f25f60fd23f}
      \strng{fullhash}{23dc7c4745667a5ad0b31f25f60fd23f}
      \strng{fullhashraw}{23dc7c4745667a5ad0b31f25f60fd23f}
      \strng{bibnamehash}{23dc7c4745667a5ad0b31f25f60fd23f}
      \strng{authorbibnamehash}{23dc7c4745667a5ad0b31f25f60fd23f}
      \strng{authornamehash}{23dc7c4745667a5ad0b31f25f60fd23f}
      \strng{authorfullhash}{23dc7c4745667a5ad0b31f25f60fd23f}
      \strng{authorfullhashraw}{23dc7c4745667a5ad0b31f25f60fd23f}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{With the increasing abundance of information resources and the development of deep learning techniques, recommender systems (RSs) based on deep learning have gradually become a research focus. Although RSs have evolved in recent years, a systematic review of existing RS approaches is still warranted. The main focus of this paper is on recommendation models that incorporate deep learning techniques. The objective is to guide novice researchers interested in this field through the investigation and application of the proposed recommendation models. Specifically, we first categorize existing RS approaches into four types: content-based recommendations, sequence recommendations, cross-domain recommendations, and social recommendation methods. We then introduce the definitions and address the challenges associated with these RS methodologies. Subsequently, we propose a comprehensive categorization framework and novel taxonomies for these methodologies, providing a thorough account of their research advancements. Finally, we discuss future developments regarding this topic.}
      \field{issn}{2076-3417}
      \field{number}{20}
      \field{title}{A Comprehensive Survey of Recommender Systems Based on Deep Learning}
      \field{volume}{13}
      \field{year}{2023}
      \field{pages}{11378}
      \range{pages}{1}
      \verb{doi}
      \verb 10.3390/app132011378
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.3390/app132011378
      \endverb
      \verb{url}
      \verb https://doi.org/10.3390/app132011378
      \endverb
      \keyw{recommender systems; deep learning; social networks; sequence recommendation; cross-domain recommendation}
    \endentry
  \enddatalist
\endrefsection
\endinput

