@article{bernerslee2001semantic,
	Author = {Berners-Lee, Tim and Hendler, James and Lassila, Ora},
	Date-Added = {2013-05-06 16:41:11 +0000},
	Date-Modified = {2013-06-12 20:57:49 +0000},
	Journal = {Scientific American},
	Number = 5,
	Pages = {28--37},
	Rating = {5},
	Read = {1},
	Title = {The Semantic Web},
	Volume = 284,
	Year = 2001,}

@misc{sw-activity,
	Author = {W3C},
	Date-Added = {2013-06-13 14:48:25 +0000},
	Date-Modified = {2013-06-13 14:48:50 +0000},
	Title = {Semantic Web Activity},
	Url = {http://www.w3.org/2001/sw/},}

@Article{Roy2022,
	author={Roy, Deepjyoti and Dutta, Mala},
	title={A systematic review and research perspective on recommender systems},
	journal={Journal of Big Data},
	year={2022},
	month={May},
	day={03},
	volume={9},
	number={1},
	pages={59},
	abstract={Recommender systems are efficient tools for filtering online information, which is widespread owing to the changing habits of computer users, personalization trends, and emerging access to the internet. Even though the recent recommender systems are eminent in giving precise recommendations, they suffer from various limitations and challenges like scalability, cold-start, sparsity, etc. Due to the existence of various techniques, the selection of techniques becomes a complex work while building application-focused recommender systems. In addition, each technique comes with its own set of features, advantages and disadvantages which raises even more questions, which should be addressed. This paper aims to undergo a systematic review on various recent contributions in the domain of recommender systems, focusing on diverse applications like books, movies, products, etc. Initially, the various applications of each recommender system are analysed. Then, the algorithmic analysis on various recommender systems is performed and a taxonomy is framed that accounts for various components required for developing an effective recommender system. In addition, the datasets gathered, simulation platform, and performance metrics focused on each contribution are evaluated and noted. Finally, this review provides a much-needed overview of the current state of research in this field and points out the existing gaps and challenges to help posterity in developing an efficient recommender system.},
	issn={2196-1115},
	doi={10.1186/s40537-022-00592-5},
	url={https://doi.org/10.1186/s40537-022-00592-5}
}

@Misc{Ko2022,
	author={Ko, Hyeyoung and Lee, Suyeon and Park, Yoonseo and Choi, Anna},
	title={A Survey of Recommendation Systems: Recommendation Models, Techniques, and Application Fields},
	year={2022},
	volume={11},
	number={1},
	pages={141},
	keywords={recommender system; recommendation system; content-based filtering; collaborative filtering; hybrid system; recommendation algorithm; recommendation technique},
	abstract={This paper reviews the research trends that link the advanced technical aspects of recommendation systems that are used in various service areas and the business aspects of these services. First, for a reliable analysis of recommendation models for recommendation systems, data mining technology, and related research by application service, more than 135 top-ranking articles and top-tier conferences published in Google Scholar between 2010 and 2021 were collected and reviewed. Based on this, studies on recommendation system models and the technology used in recommendation systems were systematized, and research trends by year were analyzed. In addition, the application service fields where recommendation systems were used were classified, and research on the recommendation system model and recommendation technique used in each field was analyzed. Furthermore, vast amounts of application service-related data used by recommendation systems were collected from 2010 to 2021 without taking the journal ranking into consideration and reviewed along with various recommendation system studies, as well as applied service field industry data. As a result of this study, it was found that the flow and quantitative growth of various detailed studies of recommendation systems interact with the business growth of the actual applied service field. While providing a comprehensive summary of recommendation systems, this study provides insight to many researchers interested in recommendation systems through the analysis of its various technologies and trends in the service field to which recommendation systems are applied.},
	issn={2079-9292},
	doi={10.3390/electronics11010141},
	url={https://doi.org/10.3390/electronics11010141}
}

@Misc{Resnick1994,
	author={Resnick, Paul and Iacovou, Neophytos and Suchak, Mitesh and Bergstrom, Peter and Riedl, John},
	title={GroupLens: an open architecture for collaborative filtering of netnews},
	year={1994},
	publisher={Association for Computing Machinery},
	pages={175--186},
	keywords={Usenet, collaborative filtering, electronic bulletin boards, information filtering, netnews, selective dissemination of information, social filtering, user model},
	abstract={Collaborative filters help people make choices based on the opinions of other people. GroupLens is a system for collaborative filtering of netnews, to help people find articles they will like in the huge stream of available articles. News reader clients display predicted scores and make it easy for users to rate articles after they read them. Rating servers, called Better Bit Bureaus, gather and disseminate the ratings. The rating servers predict scores based on the heuristic that people who agreed in the past will probably agree again. Users can protect their privacy by entering ratings under pseudonyms, without reducing the effectiveness of the score prediction. The entire architecture is open: alternative software for news clients and Better Bit Bureaus can be developed independently and can interoperate with the components we have developed.},
	note={New York, NY, USA},
	doi={10.1145/192844.192905},
	url={https://doi.org/10.1145/192844.192905}
}

@InProceedings{Hu2008,
	author={Hu, Y. and Koren, Y. and Volinsky, C.},
	title={Collaborative Filtering for Implicit Feedback Datasets},
	booktitle={2008 Eighth IEEE International Conference on Data Mining},
	series={2008 Eighth IEEE International Conference on Data Mining},
	year={2008},
	pages={263-272},
	issn={2374-8486},
	doi={10.1109/ICDM.2008.22},
	url={https://doi.org/10.1109/ICDM.2008.22}
}

@Article{Hidaka2023,
	author={Hidaka, Kazuyoshi},
	title={What influences users to provide explicit feedback? A case of food delivery recommenders},
	journal={User Modeling and User-Adapted Interaction},
	year={2023},
	month={Nov},
	day={21},
	volume={34},
	pages={1-44},
	doi={10.1007/s11257-023-09385-8},
	url={https://doi.org/10.1007/s11257-023-09385-8}
}

@Article{Zhang2019,
	author={Zhang, Shuai and Yao, Lina and Sun, Aixin and Tay, Yi},
	title={Deep Learning Based Recommender System: A Survey and New Perspectives},
	journal={ACM Comput. Surv.},
	year={2019},
	month={Feb},
	publisher={Association for Computing Machinery},
	address={New York, NY, USA},
	volume={52},
	number={1},
	keywords={survey, deep learning, Recommender system},
	abstract={With the growing volume of online information, recommender systems have been an effective strategy to overcome information overload. The utility of recommender systems cannot be overstated, given their widespread adoption in many web applications, along with their potential impact to ameliorate many problems related to over-choice. In recent years, deep learning has garnered considerable interest in many research fields such as computer vision and natural language processing, owing not only to stellar performance but also to the attractive property of learning feature representations from scratch. The influence of deep learning is also pervasive, recently demonstrating its effectiveness when applied to information retrieval and recommender systems research. The field of deep learning in recommender system is flourishing. This article aims to provide a comprehensive review of recent research efforts on deep learning-based recommender systems. More concretely, we provide and devise a taxonomy of deep learning-based recommendation models, along with a comprehensive summary of the state of the art. Finally, we expand on current trends and provide new perspectives pertaining to this new and exciting development of the field.},
	issn={0360-0300},
	doi={10.1145/3285029},
	url={https://doi.org/10.1145/3285029}
}

@Misc{Zhou2023,
	author={Zhou, Hongde and Xiong, Fei and Chen, Hongshu},
	title={A Comprehensive Survey of Recommender Systems Based on Deep Learning},
	year={2023},
	volume={13},
	number={20},
	pages={11378},
	keywords={recommender systems; deep learning; social networks; sequence recommendation; cross-domain recommendation},
	abstract={With the increasing abundance of information resources and the development of deep learning techniques, recommender systems (RSs) based on deep learning have gradually become a research focus. Although RSs have evolved in recent years, a systematic review of existing RS approaches is still warranted. The main focus of this paper is on recommendation models that incorporate deep learning techniques. The objective is to guide novice researchers interested in this field through the investigation and application of the proposed recommendation models. Specifically, we first categorize existing RS approaches into four types: content-based recommendations, sequence recommendations, cross-domain recommendations, and social recommendation methods. We then introduce the definitions and address the challenges associated with these RS methodologies. Subsequently, we propose a comprehensive categorization framework and novel taxonomies for these methodologies, providing a thorough account of their research advancements. Finally, we discuss future developments regarding this topic.},
	issn={2076-3417},
	doi={10.3390/app132011378},
	url={https://doi.org/10.3390/app132011378}
}

@Article{Wu2022,
	author={Wu, Shiwen and Sun, Fei and Zhang, Wentao and Xie, Xu and Cui, Bin},
	title={Graph Neural Networks in Recommender Systems: A Survey},
	journal={ACM Comput. Surv.},
	year={2022},
	month={Dec},
	publisher={Association for Computing Machinery},
	address={New York, NY, USA},
	volume={55},
	number={5},
	keywords={Recommender system, graph neural network, survey},
	abstract={With the explosive growth of online information, recommender systems play a key role to alleviate such information overload. Due to the important application value of recommender systems, there have always been emerging works in this field. In recommender systems, the main challenge is to learn the effective user/item representations from their interactions and side information (if any). Recently, graph neural network (GNN) techniques have been widely utilized in recommender systems since most of the information in recommender systems essentially has graph structure and GNN has superiority in graph representation learning. This article aims to provide a comprehensive review of recent research efforts on GNN-based recommender systems. Specifically, we provide a taxonomy of GNN-based recommendation models according to the types of information used and recommendation tasks. Moreover, we systematically analyze the challenges of applying GNN on different types of data and discuss how existing works in this field address these challenges. Furthermore, we state new perspectives pertaining to the development of this field. We collect the representative papers along with their open-source implementations in .},
	issn={0360-0300},
	doi={10.1145/3535101},
	url={https://doi.org/10.1145/3535101}
}

@Article{Batmaz2019,
	author={Batmaz, Zeynep and Yurekli, Ali and Bilge, Alper and Kaleli, Cihan},
	title={A review on deep learning for recommender systems: challenges and remedies},
	journal={Artificial Intelligence Review},
	year={2019},
	month={Jun},
	day={01},
	volume={52},
	number={1},
	pages={1-37},
	abstract={Recommender systems are effective tools of information filtering that are prevalent due to increasing access to the Internet, personalization trends, and changing habits of computer users. Although existing recommender systems are successful in producing decent recommendations, they still suffer from challenges such as accuracy, scalability, and cold-start. In the last few years, deep learning, the state-of-the-art machine learning technique utilized in many complex tasks, has been employed in recommender systems to improve the quality of recommendations. In this study, we provide a comprehensive review of deep learning-based recommendation approaches to enlighten and guide newbie researchers interested in the subject. We analyze compiled studies within four dimensions which are deep learning models utilized in recommender systems, remedies for the challenges of recommender systems, awareness and prevalence over recommendation domains, and the purposive properties. We also provide a comprehensive quantitative assessment of publications in the field and conclude by discussing gained insights and possible future work on the subject.},
	issn={1573-7462},
	doi={10.1007/s10462-018-9654-y},
	url={https://doi.org/10.1007/s10462-018-9654-y}
}

@Article{Zhang2020,
	author={Zhang, Yongfeng and Chen, Xu},
	title={Explainable Recommendation: A Survey and New Perspectives},
	journal={Found. Trends Inf. Retr.},
	year={2020},
	month={Mar},
	publisher={Now Publishers Inc.},
	address={Hanover, MA, USA},
	volume={14},
	number={1},
	pages={1--101},
	abstract={Explainable recommendation attempts to develop models that generate not only high-quality recommendations but also intuitive explanations. The explanations may either be post-hoc or directly come from an explainable model (also called interpretable or transparent model in some contexts). Explainable recommendation tries to address the problem of why: by providing explanations to users or system designers, it helps humans to understand why certain items are recommended by the algorithm, where the human can either be users or system designers. Explainable recommendation helpsendation systems. It also facilitates system design to improve the transparency, persuasiveness, effectiveness, trustworthiness, and satisfaction of recommers for better system debugging. In recent years, a large number of explainable recommendation approaches -- especially model-based methods -- have been proposed and applied in real-world systems.In this survey, we provide a comprehensive review for the explainable recommendation research. We first highlight the position of explainable recommendation in recommender system research by categorizing recommendation problems into the 5W, i.e., what, when, who, where, and why. We then conduct a comprehensive survey of explainable recommendation on three perspectives: 1) We provide a chronological research timeline of explainable recommendation, including user study approaches in the early years and more recent model-based approaches. 2) We provide a two-dimensional taxonomy to classify existing explainable recommendation research: one dimension is the information source (or display style) of the explanations, and the other dimension is the algorithmic mechanism to generate explainable recommendations. 3) We summarize how explainable recommendation applies to different recommendation tasks, such as product recommendation, social recommendation, and POI recommendation.We also devote a section to discuss the explanation perspectives in broader IR and AI/ML research. We end the survey by discussing potential future directions to promote the explainable recommendation research area and beyond.},
	issn={1554-0669},
	doi={10.1561/1500000066},
	url={https://doi.org/10.1561/1500000066}
}

@Article{Loeb1992,
	author={Loeb, Shoshana},
	title={Architecting personalized delivery of multimedia information},
	journal={Commun. ACM},
	year={1992},
	month={Dec},
	publisher={Association for Computing Machinery},
	address={New York, NY, USA},
	volume={35},
	number={12},
	pages={39--47},
	keywords={user profiling, user models, personalized information delivery, multimedia applications, information retrieval, information filtering, casual information usage},
	issn={0001-0782},
	doi={10.1145/138859.138862},
	url={https://doi.org/10.1145/138859.138862}
}

@Article{Salton1975,
	author={Salton, G.and Wong, A. and Yang, C. S.},
	title={A vector space model for automatic indexing},
	journal={Commun. ACM},
	year={1975},
	month={Nov},
	publisher={Association for Computing Machinery},
	address={New York, NY, USA},
	volume={18},
	number={11},
	pages={613--620},
	keywords={document space, content analysis, automatic information retrieval, automatic indexing},
	abstract={In a document retrieval, or other pattern matching environment where stored entities (documents) are compared with each other or with incoming patterns (search requests), it appears that the best indexing (property) space is one where each entity lies as far away from the others as possible; in these circumstances the value of an indexing system may be expressible as a function of the density of the object space; in particular, retrieval performance may correlate inversely with space density. An approach based on space density computations is used to choose an optimum indexing vocabulary for a collection of documents. Typical evaluation results are shown, demonstating the usefulness of the model.},
	issn={0001-0782},
	doi={10.1145/361219.361220},
	url={https://doi.org/10.1145/361219.361220}
}

@Misc{Sarwar2001,
	author={Sarwar, Badrul and Karypis, George and Konstan, Joseph and Riedl, John},
	title={Item-based collaborative filtering recommendation algorithms},
	year={2001},
	publisher={Association for Computing Machinery},
	pages={285--295},
	note={New York, NY, USA},
	doi={10.1145/371920.372071},
	url={https://doi.org/10.1145/371920.372071}
}

@Article{Linden2003,
	author={Linden, G. and Smith, B. and York, J.},
	title={Amazon.com recommendations: item-to-item collaborative filtering},
	journal={IEEE Internet Computing},
	year={2003},
	volume={7},
	number={1},
	pages={76-80},
	issn={1941-0131},
	doi={10.1109/MIC.2003.1167344},
	url={https://doi.org/10.1109/MIC.2003.1167344}
}

@Article{Koren2009,
	author={Koren, Y. and Bell, R. and Volinsky, C.},
	title={Matrix Factorization Techniques for Recommender Systems},
	journal={Computer},
	year={2009},
	volume={42},
	number={8},
	pages={30-37},
	issn={1558-0814},
	doi={10.1109/MC.2009.263},
	url={https://doi.org/10.1109/MC.2009.263}
}

@Article{Burke2002,
	author={Burke, Robin},
	title={Hybrid Recommender Systems: Survey and Experiments},
	journal={User Modeling and User-Adapted Interaction},
	year={2002},
	month={Nov},
	day={01},
	volume={12},
	number={4},
	pages={331-370},
	abstract={Recommender systems represent user preferences for the purpose of suggesting items to purchase or examine. They have become fundamental applications in electronic commerce and information access, providing suggestions that effectively prune large information spaces so that users are directed toward those items that best meet their needs and preferences. A variety of techniques have been proposed for performing recommendation, including content-based, collaborative, knowledge-based and other techniques. To improve performance, these methods have sometimes been combined in hybrid recommenders. This paper surveys the landscape of actual and possible hybrid recommenders, and introduces a novel hybrid, EntreeC, a system that combines knowledge-based recommendation and collaborative filtering to recommend restaurants. Further, we show that semantic ratings obtained from the knowledge-based part of the system enhance the effectiveness of collaborative filtering.},
	issn={1573-1391},
	doi={10.1023/A:1021240730564},
	url={https://doi.org/10.1023/A:1021240730564}
}

@Misc{He2017,
	author={He, Xiangnan and Liao, Lizi and Zhang, Hanwang and Nie, Liqiang and Hu, Xia and Chua, Tat-Seng},
	title={Neural Collaborative Filtering},
	year={2017},
	publisher={International World Wide Web Conferences Steering Committee},
	pages={173--182},
	keywords={collaborative filtering, deep learning, implicit feedback, matrix factorization, neural networks},
	abstract={In recent years, deep neural networks have yielded immense success on speech recognition, computer vision and natural language processing. However, the exploration of deep neural networks on recommender systems has received relatively less scrutiny. In this work, we strive to develop techniques based on neural networks to tackle the key problem in recommendation --- collaborative filtering --- on the basis of implicit feedback.Although some recent work has employed deep learning for recommendation, they primarily used it to model auxiliary information, such as textual descriptions of items and acoustic features of musics. When it comes to model the key factor in collaborative filtering --- the interaction between user and item features, they still resorted to matrix factorization and applied an inner product on the latent features of users and items.By replacing the inner product with a neural architecture that can learn an arbitrary function from data, we present a general framework named NCF, short for Neural network-based Collaborative Filtering. NCF is generic and can express and generalize matrix factorization under its framework. To supercharge NCF modelling with non-linearities, we propose to leverage a multi-layer perceptron to learn the user-item interaction function. Extensive experiments on two real-world datasets show significant improvements of our proposed NCF framework over the state-of-the-art methods. Empirical evidence shows that using deeper layers of neural networks offers better recommendation performance.},
	note={Republic and Canton of Geneva, CHE},
	doi={10.1145/3038912.3052569},
	url={https://doi.org/10.1145/3038912.3052569}
}

@Misc{Sedhain2015,
	author={Sedhain, Suvash and Menon, Aditya Krishna and Sanner, Scott and Xie, Lexing},
	title={AutoRec: Autoencoders Meet Collaborative Filtering},
	year={2015},
	publisher={Association for Computing Machinery},
	pages={111--112},
	keywords={recommender systems, collaborative filtering, autoencoders},
	abstract={This paper proposes AutoRec, a novel autoencoder framework for collaborative filtering (CF). Empirically, AutoRec's compact and efficiently trainable model outperforms state-of-the-art CF techniques (biased matrix factorization, RBM-CF and LLORMA) on the Movielens and Netflix datasets.},
	note={New York, NY, USA},
	doi={10.1145/2740908.2742726},
	url={https://doi.org/10.1145/2740908.2742726}
}

@inproceedings{Hidasi2016,
  author={Hidasi, Bal{\'a}zs and Karatzoglou, Alexandros and Baltrunas, Linas and Tikk, Domonkos},
  title={Session-based Recommendations with Recurrent Neural Networks},
  booktitle={4th International Conference on Learning Representations (ICLR 2016)},
  year={2016},
  doi={10.48550/arXiv.1511.06939},
  url={https://hidasi.eu/assets/pdf/gru4rec_iclr16.pdf}
}

@Misc{Kim2016,
	author={Kim, Donghyun and Park, Chanyoung and Oh, Jinoh and Lee, Sungyoung
	and Yu, Hwanjo},
	title={Convolutional Matrix Factorization for Document Context-Aware Recommendation},
	year={2016},
	publisher={Association for Computing Machinery},
	pages={233--240},
	keywords={collaborative filtering, contexual information, deep learning, document modeling, neural network' context-aware recommendation, recommender system},
	abstract={Sparseness of user-to-item rating data is one of the major factors that deteriorate the quality of recommender system. To handle the sparsity problem, several recommendation techniques have been proposed that additionally consider auxiliary information to improve rating prediction accuracy. In particular, when rating data is sparse, document modeling-based approaches have improved the accuracy by additionally utilizing textual data such as reviews, abstracts, or synopses. However, due to the inherent limitation of the bag-of-words model, they have difficulties in effectively utilizing contextual information of the documents, which leads to shallow understanding of the documents. This paper proposes a novel context-aware recommendation model, convolutional matrix factorization (ConvMF) that integrates convolutional neural network (CNN) into probabilistic matrix factorization (PMF). Consequently, ConvMF captures contextual information of documents and further enhances the rating prediction accuracy. Our extensive evaluations on three real-world datasets show that ConvMF significantly outperforms the state-of-the-art recommendation models even when the rating data is extremely sparse. We also demonstrate that ConvMF successfully captures subtle contextual difference of a word in a document. Our implementation and datasets are available at http://dm.postech.ac.kr/ConvMF.},
	note={New York, NY, USA},
	doi={10.1145/2959100.2959165},
	url={https://doi.org/10.1145/2959100.2959165}
}

@InProceedings{Kang2018,
	author={Kang, W.-C. and McAuley, J.},
	title={Self-Attentive Sequential Recommendation},
	booktitle={2018 IEEE International Conference on Data Mining (ICDM)},
	series={2018 IEEE International Conference on Data Mining (ICDM)},
	year={2018},
	pages={197-206},
	issn={2374-8486},
	doi={10.1109/ICDM.2018.00035},
	url={https://doi.org/10.1109/ICDM.2018.00035}
}

@Misc{Vaswani2017,
	author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, {\L} Ukasz and Polosukhin, Illia},
	title={Attention is All you Need},
	year={2017},
	publisher={Curran Associates, Inc.},
	volume={30},
	doi={10.48550/arXiv.1706.03762},
	url={https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf}
}

@Misc{Wang2017,
	author={Wang, Jun and Yu, Lantao and Zhang, Weinan and Gong, Yu and Xu, Yinghui and Wang, Benyou and Zhang, Peng and Zhang, Dell},
	title={IRGAN: A Minimax Game for Unifying Generative and Discriminative Information Retrieval Models},
	year={2017},
	publisher={Association for Computing Machinery},
	pages={515--524},
	keywords={web search, recommender systems, question answering, information retrieval models, information retrieval, adversarial training},
	abstract={This paper provides a unified account of two schools of thinking in information retrieval modelling: the generative retrieval focusing on predicting relevant documents given a query, and the discriminative retrieval focusing on predicting relevancy given a query-document pair. We propose a game theoretical minimax game to iteratively optimise both models. On one hand, the discriminative model, aiming to mine signals from labelled and unlabelled data, provides guidance to train the generative model towards fitting the underlying relevance distribution over documents given the query. On the other hand, the generative model, acting as an attacker to the current discriminative model, generates difficult examples for the discriminative model in an adversarial way by minimising its discrimination objective. With the competition between these two models, we show that the unified framework takes advantage of both schools of thinking: (i) the generative model learns to fit the relevance distribution over documents via the signals from the discriminative model, and (ii) the discriminative model is able to exploit the unlabelled data selected by the generative model to achieve a better estimation for document ranking. Our experimental results have demonstrated significant performance gains as much as 23.96{\%} on Precision@5 and 15.50{\%} on MAP over strong baselines in a variety of applications including web search, item recommendation, and question answering.},
	note={New York, NY, USA},
	doi={10.1145/3077136.3080786},
	url={https://doi.org/10.1145/3077136.3080786}
}

@Misc{Zheng2018,
	author={Zheng, Guanjie and Zhang, Fuzheng and Zheng, Zihan and Xiang, Yang and Yuan, Nicholas Jing and Xie, Xing and Li, Zhenhui},
	title={DRN: A Deep Reinforcement Learning Framework for News Recommendation},
	year={2018},
	publisher={International World Wide Web Conferences Steering Committee},
	pages={167--176},
	keywords={deep Q-Learning, news recommendation, reinforcement learning},
	abstract={In this paper, we propose a novel Deep Reinforcement Learning framework for news recommendation. Online personalized news recommendation is a highly challenging problem due to the dynamic nature of news features and user preferences. Although some online recommendation models have been proposed to address the dynamic nature of news recommendation, these methods have three major issues. First, they only try to model current reward (e.g., Click Through Rate). Second, very few studies consider to use user feedback other than click / no click labels (e.g., how frequent user returns) to help improve recommendation. Third, these methods tend to keep recommending similar news to users, which may cause users to get bored. Therefore, to address the aforementioned challenges, we propose a Deep Q-Learning based recommendation framework, which can model future reward explicitly. We further consider user return pattern as a supplement to click / no click label in order to capture more user feedback information. In addition, an effective exploration strategy is incorporated to find new attractive news for users. Extensive experiments are conducted on the offline dataset and online production environment of a commercial news recommendation application and have shown the superior performance of our methods.},
	note={Republic and Canton of Geneva, CHE},
	doi={10.1145/3178876.3185994},
	url={https://doi.org/10.1145/3178876.3185994}
}

@Article{Mnih2015,
	author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
	title={Human-level control through deep reinforcement learning},
	journal={Nature},
	year={2015},
	month={Feb},
	day={01},
	volume={518},
	number={7540},
	pages={529-533},
	abstract={An artificial agent is developed that learns to play a diverse range of classic Atari 2600 computer games directly from sensory experience, achieving a performance comparable to that of an expert human player; this work paves the way to building general-purpose learning algorithms that bridge the divide between perception and action.},
	issn={1476-4687},
	doi={10.1038/nature14236},
	url={https://doi.org/10.1038/nature14236}
}

@Misc{Wang2019,
	author={Wang, Xiang and He, Xiangnan and Wang, Meng and Feng, Fuli and Chua, Tat-Seng},
	title={Neural Graph Collaborative Filtering},
	year={2019},
	publisher={Association for Computing Machinery},
	pages={165--174},
	keywords={collaborative filtering, embedding propagation, graph neural network, high-order connectivity, recommendation},
	abstract={Learning vector representations (aka. embeddings) of users and items lies at the core of modern recommender systems. Ranging from early matrix factorization to recently emerged deep learning based methods, existing efforts typically obtain a user's (or an item's) embedding by mapping from pre-existing features that describe the user (or the item), such as ID and attributes. We argue that an inherent drawback of such methods is that, the collaborative signal, which is latent in user-item interactions, is not encoded in the embedding process. As such, the resultant embeddings may not be sufficient to capture the collaborative filtering effect.In this work, we propose to integrate the user-item interactions - more specifically the bipartite graph structure - into the embedding process. We develop a new recommendation framework Neural Graph Collaborative Filtering (NGCF), which exploits the user-item graph structure by propagating embeddings on it. This leads to the expressive modeling of high-order connectivity in user-item graph, effectively injecting the collaborative signal into the embedding process in an explicit manner. We conduct extensive experiments on three public benchmarks, demonstrating significant improvements over several state-of-the-art models like HOP-Rec [39] and Collaborative Memory Network [5]. Further analysis verifies the importance of embedding propagation for learning better user and item representations, justifying the rationality and effectiveness of NGCF. Codes are available at https://github.com/xiangwang1223/neural{\_}graph{\_}collaborative{\_}filtering.},
	note={New York, NY, USA},
	doi={10.1145/3331184.3331267},
	url={https://doi.org/10.1145/3331184.3331267}
}

@Misc{He2020,
	author={He, Xiangnan and Deng, Kuan and Wang, Xiang and Li, Yan and Zhang, Yongdong and Wang, Meng},
	title={LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation},
	year={2020},
	publisher={Association for Computing Machinery},
	pages={639--648},
	keywords={recommendation, graph neural network, embedding propagation, collaborative filtering},
	abstract={Graph Convolution Network (GCN) has become new state-of-the-art for collaborative filtering. Nevertheless, the reasons of its effectiveness for recommendation are not well understood. Existing work that adapts GCN to recommendation lacks thorough ablation analyses on GCN, which is originally designed for graph classification tasks and equipped with many neural network operations. However, we empirically find that the two most common designs in GCNs -- feature transformation and nonlinear activation -- contribute little to the performance of collaborative filtering. Even worse, including them adds to the difficulty of training and degrades recommendation performance.In this work, we aim to simplify the design of GCN to make it more concise and appropriate for recommendation. We propose a new model named LightGCN, including only the most essential component in GCN -- neighborhood aggregation -- for collaborative filtering. Specifically, LightGCN learns user and item embeddings by linearly propagating them on the user-item interaction graph, and uses the weighted sum of the embeddings learned at all layers as the final embedding. Such simple, linear, and neat model is much easier to implement and train, exhibiting substantial improvements (about 16.0{\%} relative improvement on average) over Neural Graph Collaborative Filtering (NGCF) -- a state-of-the-art GCN-based recommender model -- under exactly the same experimental setting. Further analyses are provided towards the rationality of the simple LightGCN from both analytical and empirical perspectives.},
	note={New York, NY, USA},
	doi={10.1145/3397271.3401063},
	url={https://doi.org/10.1145/3397271.3401063}
}

@Misc{Wu2021,
	author={Wu, Jiancan and Wang, Xiang and Feng, Fuli and He, Xiangnan and Chen, Liang and Lian, Jianxun and Xie, Xing},
	title={Self-supervised Graph Learning for Recommendation},
	year={2021},
	publisher={Association for Computing Machinery},
	pages={726--735},
	keywords={collaborative filtering, graph neural network, long-tail recommendation, self-supervised learning},
	abstract={Representation learning on user-item graph for recommendation has evolved from using single ID or interaction history to exploiting higher-order neighbors. This leads to the success of graph convolution networks (GCNs) for recommendation such as PinSage and LightGCN. Despite effectiveness, we argue that they suffer from two limitations: (1) high-degree nodes exert larger impact on the representation learning, deteriorating the recommendations of low-degree (long-tail) items; and (2) representations are vulnerable to noisy interactions, as the neighborhood aggregation scheme further enlarges the impact of observed edges.In this work, we explore self-supervised learning on user-item graph, so as to improve the accuracy and robustness of GCNs for recommendation. The idea is to supplement the classical supervised task of recommendation with an auxiliary self-supervised task, which reinforces node representation learning via self-discrimination. Specifically, we generate multiple views of a node, maximizing the agreement between different views of the same node compared to that of other nodes. We devise three operators to generate the views --- node dropout, edge dropout, and random walk --- that change the graph structure in different manners. We term this new learning paradigm asSelf-supervised Graph Learning (SGL), implementing it on the state-of-the-art model LightGCN. Through theoretical analyses, we find that SGL has the ability of automatically mining hard negatives. Empirical studies on three benchmark datasets demonstrate the effectiveness of SGL, which improves the recommendation accuracy, especially on long-tail items, and the robustness against interaction noises. Our implementations are available at urlhttps://github.com/wujcan/SGL.},
	note={New York, NY, USA},
	doi={10.1145/3404835.3462862},
	url={https://doi.org/10.1145/3404835.3462862}
}

@Misc{Yu2022,
	author={Yu, Junliang and Yin, Hongzhi and Xia, Xin and Chen, Tong and Cui, Lizhen and Nguyen, Quoc Viet Hung},
	title={Are Graph Augmentations Necessary? Simple Graph Contrastive Learning for Recommendation},
	year={2022},
	publisher={Association for Computing Machinery},
	pages={1294--1303},
	keywords={contrastive learning, data augmentation, recommendation, self-supervised learning},
	abstract={Contrastive learning (CL) recently has spurred a fruitful line of research in the field of recommendation, since its ability to extract self-supervised signals from the raw data is well-aligned with recommender systems' needs for tackling the data sparsity issue. A typical pipeline of CL-based recommendation models is first augmenting the user-item bipartite graph with structure perturbations, and then maximizing the node representation consistency between different graph augmentations. Although this paradigm turns out to be effective, what underlies the performance gains is still a mystery. In this paper, we first experimentally disclose that, in CL-based recommendation models, CL operates by learning more uniform user/item representations that can implicitly mitigate the popularity bias. Meanwhile, we reveal that the graph augmentations, which used to be considered necessary, just play a trivial role. Based on this finding, we propose a simple CL method which discards the graph augmentations and instead adds uniform noises to the embedding space for creating contrastive views. A comprehensive experimental study on three benchmark datasets demonstrates that, though it appears strikingly simple, the proposed method can smoothly adjust the uniformity of learned representations and has distinct advantages over its graph augmentation-based counterparts in terms of recommendation accuracy and training efficiency. The code is released at https://github.com/Coder-Yu/QRec.},
	note={New York, NY, USA},
	doi={10.1145/3477495.3531937},
	url={https://doi.org/10.1145/3477495.3531937}
}

@Misc{Lin2022,
	author={Lin, Zihan and Tian, Changxin and Hou, Yupeng and Zhao, Wayne Xin},
	title={Improving Graph Collaborative Filtering with Neighborhood-enriched Contrastive Learning},
	year={2022},
	publisher={Association for Computing Machinery},
	pages={2320--2329},
	keywords={Collaborative Filtering, Contrastive Learning, Graph Neural Network, Recommender System},
	abstract={Recently, graph collaborative filtering methods have been proposed as an effective recommendation approach, which can capture users' preference over items by modeling the user-item interaction graphs. Despite the effectiveness, these methods suffer from data sparsity in real scenarios. In order to reduce the influence of data sparsity, contrastive learning is adopted in graph collaborative filtering for enhancing the performance. However, these methods typically construct the contrastive pairs by random sampling, which neglect the neighboring relations among users (or items) and fail to fully exploit the potential of contrastive learning for recommendation. To tackle the above issue, we propose a novel contrastive learning approach, named Neighborhood-enriched Contrastive Learning, named NCL, which explicitly incorporates the potential neighbors into contrastive pairs. Specifically, we introduce the neighbors of a user (or an item) from graph structure and semantic space respectively. For the structural neighbors on the interaction graph, we develop a novel structure-contrastive objective that regards users (or items) and their structural neighbors as positive contrastive pairs. In implementation, the representations of users (or items) and neighbors correspond to the outputs of different GNN layers. Furthermore, to excavate the potential neighbor relation in semantic space, we assume that users with similar representations are within the semantic neighborhood, and incorporate these semantic neighbors into the prototype-contrastive objective. The proposed NCL can be optimized with EM algorithm and generalized to apply to graph collaborative filtering methods. Extensive experiments on five public datasets demonstrate the effectiveness of the proposed NCL, notably with 26{\%} and 17{\%} performance gain over a competitive graph collaborative filtering base model on the Yelp and Amazon-book datasets, respectively. Our implementation code is available at: https://github.com/RUCAIBox/NCL.},
	note={New York, NY, USA},
	doi={10.1145/3485447.3512104},
	url={https://doi.org/10.1145/3485447.3512104}
}

@Misc{Huang2022,
	author={Huang, Chao and Wang, Xiang and He, Xiangnan and Yin, Dawei},
	title={Self-Supervised Learning for Recommender System},
	year={2022},
	publisher={Association for Computing Machinery},
	pages={3440--3443},
	keywords={collaborative filtering, recommendation, self-supervised learning},
	abstract={Recommender systems have become key components for a wide spectrum of web applications (e.g., E-commerce sites, video sharing platforms, lifestyle applications, etc), so as to alleviate the information overload and suggest items for users. However, most existing recommendation models follow a supervised learning manner, which notably limits their representation ability with the ubiquitous sparse and noisy data in practical applications. Recently, self-supervised learning (SSL) has become a promising learning paradigm to distill informative knowledge from unlabeled data, without the heavy reliance on sufficient supervision signals. Inspired by the effectiveness of self-supervised learning, recent efforts bring SSL's superiority into various recommendation representation learning scenarios with augmented auxiliary learning tasks. In this tutorial, we aim to provide a systemic review of existing self-supervised learning frameworks and analyze the corresponding challenges for various recommendation scenarios, such as general collaborative filtering paradigm, social recommendation, sequential recommendation, and multi-behavior recommendation. We then raise discussions and future directions of this area. With the introduction of this emerging and promising topic, we expect the audience to have a deep understanding of this domain. We also seek to promote more ideas and discussions, which facilitates the development of self-supervised learning recommendation techniques.},
	note={New York, NY, USA},
	doi={10.1145/3477495.3532684},
	url={https://doi.org/10.1145/3477495.3532684}
}

@Misc{Ying2018,
	author={Ying, Rex and He, Ruining and Chen, Kaifeng and Eksombatchai, Pong and Hamilton, William L. and Leskovec, Jure},
	title={Graph Convolutional Neural Networks for Web-Scale Recommender Systems},
	year={2018},
	publisher={Association for Computing Machinery},
	pages={974--983},
	keywords={scalability, recommender systems, graph convolutional networks, deep learning},
	abstract={Recent advancements in deep neural networks for graph-structured data have led to state-of-the-art performance on recommender system benchmarks. However, making these methods practical and scalable to web-scale recommendation tasks with billions of items and hundreds of millions of users remains an unsolved challenge. Here we describe a large-scale deep recommendation engine that we developed and deployed at Pinterest. We develop a data-efficient Graph Convolutional Network (GCN) algorithm, which combines efficient random walks and graph convolutions to generate embeddings of nodes (i.e., items) that incorporate both graph structure as well as node feature information. Compared to prior GCN approaches, we develop a novel method based on highly efficient random walks to structure the convolutions and design a novel training strategy that relies on harder-and-harder training examples to improve robustness and convergence of the model. We also develop an efficient MapReduce model inference algorithm to generate embeddings using a trained model. Overall, we can train on and embed graphs that are four orders of magnitude larger than typical GCN implementations. We show how GCN embeddings can be used to make high-quality recommendations in various settings at Pinterest, which has a massive underlying graph with 3 billion nodes representing pins and boards, and 17 billion edges. According to offline metrics, user studies, as well as A/B tests, our approach generates higher-quality recommendations than comparable deep learning based systems. To our knowledge, this is by far the largest application of deep graph embeddings to date and paves the way for a new generation of web-scale recommender systems based on graph convolutional architectures.},
	note={New York, NY, USA},
	doi={10.1145/3219819.3219890},
	url={https://doi.org/10.1145/3219819.3219890}
}

@Article{Berg2017,
	author={van den Berg, Rianne and Kipf, Thomas N. and Welling, Max},
	title={Graph Convolutional Matrix Completion},
	journal={arXiv preprint arXiv:1706.02263},
	year={2017},
	doi={10.48550/arXiv.1706.02263},
	url={https://doi.org/10.48550/arXiv.1706.02263}
}

@Article{Wu2019_SRGNN,
	author={Wu, Shu and Tang, Yuyuan and Zhu, Yanqiao and Wang, Liang and Xie, Xing and Tan, Tieniu},
	title={Session-Based Recommendation with Graph Neural Networks},
	journal={Proceedings of the AAAI Conference on Artificial Intelligence},
	year={2019},
	month={Jul},
	day={17},
	volume={33},
	number={01},
	pages={346-353},
	abstract={{\&}lt;p{\&}gt;The problem of session-based recommendation aims to predict user actions based on anonymous sessions. Previous methods model a session as a sequence and estimate user representations besides item representations to make recommendations. Though achieved promising results, they are insufficient to obtain accurate user vectors in sessions and neglect complex transitions of items. To obtain accurate item embedding and take complex transitions of items into account, we propose a novel method, i.e. {\&}lt;em{\&}gt;Session-based Recommendation with Graph Neural Networks{\&}lt;/em{\&}gt;, SR-GNN for brevity. In the proposed method, session sequences are modeled as graphstructured data. Based on the session graph, GNN can capture complex transitions of items, which are difficult to be revealed by previous conventional sequential methods. Each session is then represented as the composition of the global preference and the current interest of that session using an attention network. Extensive experiments conducted on two real datasets show that SR-GNN evidently outperforms the state-of-the-art session-based recommendation methods consistently.{\&}lt;/p{\&}gt;},
	doi={10.1609/aaai.v33i01.3301346},
	url={https://ojs.aaai.org/index.php/AAAI/article/view/3804},
	url={https://doi.org/10.1609/aaai.v33i01.3301346}
}
@Misc{Wu2019_DiffNet,
author={Wu, Le and Sun, Peijie and Fu, Yanjie and Hong, Richang and Wang, Xiting and Wang, Meng},
title={A Neural Influence Diffusion Model for Social Recommendation},
year={2019},
publisher={Association for Computing Machinery},
pages={235--244},
keywords={graph neural networks, influence diffusion, personalization, social recommendation},
abstract={Precise user and item embedding learning is the key to building a successful recommender system. Traditionally, Collaborative Filtering (CF) provides a way to learn user and item embeddings from the user-item interaction history. However, the performance is limited due to the sparseness of user behavior data. With the emergence of online social networks, social recommender systems have been proposed to utilize each user's local neighbors' preferences to alleviate the data sparsity for better user embedding modeling. We argue that, for each user of a social platform, her potential embedding is influenced by her trusted users, with these trusted users are influenced by the trusted users' social connections. As social influence recursively propagates and diffuses in the social network, each user's interests change in the recursive process. Nevertheless, the current social recommendation models simply developed static models by leveraging the local neighbors of each user without simulating the recursive diffusion in the global social network, leading to suboptimal recommendation performance. In this paper, we propose a deep influence propagation model to stimulate how users are influenced by the recursive social diffusion process for social recommendation. For each user, the diffusion process starts with an initial embedding that fuses the related features and a free user latent vector that captures the latent behavior preference. The key idea of our proposed model is that we design a layer-wise influence propagation structure to model how users' latent embeddings evolve as the social diffusion process continues. We further show that our proposed model is general and could be applied when the user (item) attributes or the social network structure is not available. Finally, extensive experimental results on two real-world datasets clearly show the effectiveness of our proposed model, with more than 13{\%} performance improvements over the best baselines for top-10 recommendation on the two datasets.},
note={New York, NY, USA},
doi={10.1145/3331184.3331214},
url={https://doi.org/10.1145/3331184.3331214}
}

@Misc{Wang2019_KGAT,
	author={Wang, Xiang and He, Xiangnan and Cao, Yixin and Liu, Meng and Chua, Tat-Seng},
	title={KGAT: Knowledge Graph Attention Network for Recommendation},
	year={2019},
	publisher={Association for Computing Machinery},
	pages={950--958},
	keywords={collaborative filtering, embedding propagation, graph neural network, higher-order connectivity, knowledge graph, recommendation},
	abstract={To provide more accurate, diverse, and explainable recommendation, it is compulsory to go beyond modeling user-item interactions and take side information into account. Traditional methods like factorization machine (FM) cast it as a supervised learning problem, which assumes each interaction as an independent instance with side information encoded. Due to the overlook of the relations among instances or items (e.g., the director of a movie is also an actor of another movie), these methods are insufficient to distill the collaborative signal from the collective behaviors of users. In this work, we investigate the utility of knowledge graph (KG), which breaks down the independent interaction assumption by linking items with their attributes. We argue that in such a hybrid structure of KG and user-item graph, high-order relations --- which connect two items with one or multiple linked attributes --- are an essential factor for successful recommendation. We propose a new method named Knowledge Graph Attention Network (KGAT) which explicitly models the high-order connectivities in KG in an end-to-end fashion. It recursively propagates the embeddings from a node's neighbors (which can be users, items, or attributes) to refine the node's embedding, and employs an attention mechanism to discriminate the importance of the neighbors. Our KGAT is conceptually advantageous to existing KG-based recommendation methods, which either exploit high-order relations by extracting paths or implicitly modeling them with regularization. Empirical results on three public benchmarks show that KGAT significantly outperforms state-of-the-art methods like Neural FM and RippleNet. Further studies verify the efficacy of embedding propagation for high-order relation modeling and the interpretability benefits brought by the attention mechanism. We release the codes and datasets at https://github.com/xiangwang1223/knowledge{\_}graph{\_}attention{\_}network.},
	note={New York, NY, USA},
	doi={10.1145/3292500.3330989},
	url={https://doi.org/10.1145/3292500.3330989}
}

@Misc{Fan2019,
	author={Fan, Wenqi and Ma, Yao and Li, Qing and He, Yuan and Zhao, Eric and Tang, Jiliang and Yin, Dawei},
	title={Graph Neural Networks for Social Recommendation},
	year={2019},
	publisher={Association for Computing Machinery},
	pages={417--426},
	keywords={Social Recommendation, Social Network, Recommender Systems, Neural Networks, Graph Neural Networks},
	abstract={In recent years, Graph Neural Networks (GNNs), which can naturally integrate node information and topological structure, have been demonstrated to be powerful in learning on graph data. These advantages of GNNs provide great potential to advance social recommendation since data in social recommender systems can be represented as user-user social graph and user-item graph; and learning latent factors of users and items is the key. However, building social recommender systems based on GNNs faces challenges. For example, the user-item graph encodes both interactions and their associated opinions; social relations have heterogeneous strengths; users involve in two graphs (e.g., the user-user social graph and the user-item graph). To address the three aforementioned challenges simultaneously, in this paper, we present a novel graph neural network framework (GraphRec) for social recommendations. In particular, we provide a principled approach to jointly capture interactions and opinions in the user-item graph and propose the framework GraphRec, which coherently models two graphs and heterogeneous strengths. Extensive experiments on two real-world datasets demonstrate the effectiveness of the proposed framework GraphRec.},
	note={New York, NY, USA},
	doi={10.1145/3308558.3313488},
	url={https://doi.org/10.1145/3308558.3313488}
}

@Article{Yu2024,
	author={Yu, J. and Yin, H. and Xia, X. and Chen, T. and Li, J. and Huang, Z.},
	title={Self-Supervised Learning for Recommender Systems: A Survey},
	journal={IEEE Transactions on Knowledge and Data Engineering},
	year={2024},
	volume={36},
	number={1},
	pages={335-355},
	issn={1558-2191},
	doi={10.1109/TKDE.2023.3282907},
	url={https://doi.org/10.1109/TKDE.2023.3282907}
}

@Misc{Sun2019,
	author={Sun, Fei and Liu, Jun and Wu, Jian and Pei, Changhua and Lin, Xiao and Ou, Wenwu and Jiang, Peng},
	title={BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer},
	year={2019},
	publisher={Association for Computing Machinery},
	pages={1441--1450},
	keywords={bidirectional sequential model, cloze, sequential recommendation},
	abstract={Modeling users' dynamic preferences from their historical behaviors is challenging and crucial for recommendation systems. Previous methods employ sequential neural networks to encode users' historical interactions from left to right into hidden representations for making recommendations. Despite their effectiveness, we argue that such left-to-right unidirectional models are sub-optimal due to the limitations including: begin enumerate* [label=seriesitshapealph*upshape)] item unidirectional architectures restrict the power of hidden representation in users' behavior sequences; item they often assume a rigidly ordered sequence which is not always practical. end enumerate* To address these limitations, we proposed a sequential recommendation model called BERT4Rec, which employs the deep bidirectional self-attention to model user behavior sequences. To avoid the information leakage and efficiently train the bidirectional model, we adopt the Cloze objective to sequential recommendation, predicting the random masked items in the sequence by jointly conditioning on their left and right context. In this way, we learn a bidirectional representation model to make recommendations by allowing each item in user historical behaviors to fuse information from both left and right sides. Extensive experiments on four benchmark datasets show that our model outperforms various state-of-the-art sequential models consistently.},
	note={New York, NY, USA},
	doi={10.1145/3357384.3357895},
	url={https://doi.org/10.1145/3357384.3357895}
}

@Misc{Hou2022,
	author={Hou, Zhenyu and Liu, Xiao and Cen, Yukuo and Dong, Yuxiao and Yang, Hongxia and Wang, Chunjie and Tang, Jie},
	title={GraphMAE: Self-Supervised Masked Graph Autoencoders},
	year={2022},
	publisher={Association for Computing Machinery},
	pages={594--604},
	keywords={graph neural networks, graph representation learning, self-supervised learning},
	abstract={Self-supervised learning (SSL) has been extensively explored in recent years. Particularly, generative SSL has seen emerging success in natural language processing and other fields, such as the wide adoption of BERT and GPT. Despite this, contrastive learning---which heavily relies on structural data augmentation and complicated training strategies---has been the dominant approach in graph SSL, while the progress of generative SSL on graphs, especially graph autoencoders (GAEs), has thus far not reached the potential as promised in other fields. In this paper, we identify and examine the issues that negatively impact the development of GAEs, including their reconstruction objective, training robustness, and error metric. We present a masked graph autoencoder GraphMAE (code is publicly available at https://github.com/THUDM/GraphMAE) that mitigates these issues for generative self-supervised graph learning. Instead of reconstructing structures, we propose to focus on feature reconstruction with both a masking strategy and scaled cosine error that benefit the robust training of GraphMAE. We conduct extensive experiments on 21 public datasets for three different graph learning tasks. The results manifest that GraphMAE---a simple graph autoencoder with our careful designs---can consistently generate outperformance over both contrastive and generative state-of-the-art baselines. This study provides an understanding of graph autoencoders and demonstrates the potential of generative self-supervised learning on graphs.},
	note={New York, NY, USA},
	doi={10.1145/3534678.3539321},
	url={https://doi.org/10.1145/3534678.3539321}
}

@Article{Zhou2023,
	author={Zhou, Xin and Sun, Aixin and Liu, Yong and Zhang, Jie and Miao, Chunyan},
	title={SelfCF: A Simple Framework for Self-supervised Collaborative Filtering},
	journal={ACM Trans. Recomm. Syst.},
	year={2023},
	month={Jun},
	publisher={Association for Computing Machinery},
	address={New York, NY, USA},
	volume={1},
	number={2},
	keywords={Collaborative filtering, self-supervised learning, recommender systems, Siamese networks},
	abstract={Collaborative filtering (CF) is widely used to learn informative latent representations of users and items from observed interactions. Existing CF-based methods commonly adopt negative sampling to discriminate different items. That is, observed user-item pairs are treated as positive instances; unobserved pairs are considered as negative instances and are sampled under a defined distribution for training. Training with negative sampling on large datasets is computationally expensive. Further, negative items should be carefully sampled under the defined distribution, in order to avoid selecting an observed positive item in the training dataset. Unavoidably, some negative items sampled from the training dataset could be positive in the test set. Recently, self-supervised learning (SSL), has emerged as a powerful tool to learn a model without negative samples. In this paper, we propose a self-supervised collaborative filtering framework (SelfCF), that is specially designed for recommender scenario with implicit feedback. The proposed SelfCF framework simplifies Siamese networks and can be easily applied to existing deep-learning based CF models, which we refer to as backbone networks. The main idea of SelfCF is to augment the latent embeddings generated by backbone networks instead of the raw input of user/item ids. We propose and study three embedding perturbation techniques that can be applied to different types of backbone networks including both traditional CF models and graph-based models. The framework enables learning informative representations of users and items without negative samples, and is agnostic to the encapsulated backbones. We conduct experimental comparisons on four datasets, one self-supervised framework, and eight baselines to show that our framework may achieve even better recommendation accuracy than the encapsulated supervised counterpart with a 2{\texttimes}--4{\texttimes} faster training speed. The results also demonstrate that SelfCF can boost up the accuracy of a self-supervised framework BUIR by 17.79{\%} on average and shows competitive performance with baselines.},
	doi={10.1145/3591469},
	url={https://doi.org/10.1145/3591469}
}

@Misc{Yu2021,
	author={Yu, Junliang and Yin, Hongzhi and Li, Jundong and Wang, Qinyong and Hung, Nguyen Quoc Viet and Zhang, Xiangliang},
	title={Self-Supervised Multi-Channel Hypergraph Convolutional Network for Social Recommendation},
	year={2021},
	publisher={Association for Computing Machinery},
	pages={413--424},
	keywords={Graph Convolutional Network, Hypergraph Learning, Recommender Systems, Self-supervised Learning, Social Recommendation},
	abstract={Social relations are often used to improve recommendation quality when user-item interaction data is sparse in recommender systems. Most existing social recommendation models exploit pairwise relations to mine potential user preferences. However, real-life interactions among users are very complex and user relations can be high-order. Hypergraph provides a natural way to model high-order relations, while its potentials for improving social recommendation are under-explored. In this paper, we fill this gap and propose a multi-channel hypergraph convolutional network to enhance social recommendation by leveraging high-order user relations. Technically, each channel in the network encodes a hypergraph that depicts a common high-order user relation pattern via hypergraph convolution. By aggregating the embeddings learned through multiple channels, we obtain comprehensive user representations to generate recommendation results. However, the aggregation operation might also obscure the inherent characteristics of different types of high-order connectivity information. To compensate for the aggregating loss, we innovatively integrate self-supervised learning into the training of the hypergraph convolutional network to regain the connectivity information with hierarchical mutual information maximization. Extensive experiments on multiple real-world datasets demonstrate the superiority of the proposed model over the current SOTA methods, and the ablation study verifies the effectiveness and rationale of the multi-channel setting and the self-supervised task. The implementation of our model is available via https://github.com/Coder-Yu/RecQ.},
	note={New York, NY, USA},
	doi={10.1145/3442381.3449844},
	url={https://doi.org/10.1145/3442381.3449844}
}

@Article{Zhao2024,
	author={Zhao, Z. and Fan, W. and Li, J. and Liu, Y. and Mei, X. and Wang, Y. and Wen, Z. and Wang, F. and Zhao, X. and Tang, J. and Li, Q.},
	title={Recommender Systems in the Era of Large Language Models (LLMs)},
	journal={IEEE Transactions on Knowledge and Data Engineering},
	year={2024},
	volume={36},
	number={11},
	pages={6889-6907},
	issn={1558-2191},
	doi={10.1109/TKDE.2024.3392335},
	url={https://doi.org/10.1109/TKDE.2024.3392335}
}

@Article{Lin2025,
	author={Lin, Jianghao and Dai, Xinyi and Xi, Yunjia and Liu, Weiwen and Chen, Bo and Zhang, Hao and Liu, Yong and Wu, Chuhan and Li, Xiangyang and Zhu, Chenxu and Guo, Huifeng and Yu, Yong and Tang, Ruiming and Zhang, Weinan},
	title={How Can Recommender Systems Benefit from Large Language Models: A Survey},
	journal={ACM Trans. Inf. Syst.},
	year={2025},
	month={Jan},
	publisher={Association for Computing Machinery},
	address={New York, NY, USA},
	volume={43},
	number={2},
	keywords={Recommender systems, large language models},
	abstract={With the rapid development of online services and web applications, recommender systems (RS) have become increasingly indispensable for mitigating information overload and matching users' information needs by providing personalized suggestions over items. Although the RS research community has made remarkable progress over the past decades, conventional recommendation models (CRM) still have some limitations, e.g., lacking open-domain world knowledge, and difficulties in comprehending users' underlying preferences and motivations. Meanwhile, large language models (LLM) have shown impressive general intelligence and human-like capabilities for various natural language processing (NLP) tasks, which mainly stem from their extensive open-world knowledge, logical and commonsense reasoning abilities, as well as their comprehension of human culture and society. Consequently, the emergence of LLM is inspiring the design of RS and pointing out a promising research direction, i.e., whether we can incorporate LLM and benefit from their common knowledge and capabilities to compensate for the limitations of CRM. In this article, we conduct a comprehensive survey on this research direction, and draw a bird's-eye view from the perspective of the whole pipeline in real-world RS. Specifically, we summarize existing research works from two orthogonal aspects: where and how to adapt LLM to RS. For the ``WHERE'' question, we discuss the roles that LLM could play in different stages of the recommendation pipeline, i.e., feature engineering, feature encoder, scoring/ranking function, user interaction, and pipeline controller. For the ``HOW'' question, we investigate the training and inference strategies, resulting in two fine-grained taxonomy criteria, i.e., whether to tune LLM or not during training, and whether to involve CRM for inference. Detailed analysis and general development paths are provided for both ``WHERE'' and ``HOW'' questions, respectively. Then, we highlight the key challenges in adapting LLM to RS from three aspects, i.e., efficiency, effectiveness, and ethics. Finally, we summarize the survey and discuss the future prospects.},
	issn={1046-8188},
	doi={10.1145/3678004},
	url={https://doi.org/10.1145/3678004}
}

@Misc{Hou2022_UniSRec,
	author={Hou, Yupeng and Mu, Shanlei and Zhao, Wayne Xin and Li, Yaliang and Ding, Bolin and Wen, Ji-Rong},
	title={Towards Universal Sequence Representation Learning for Recommender Systems},
	year={2022},
	publisher={Association for Computing Machinery},
	pages={585--593},
	keywords={sequential recommendation, universal representation learning},
	abstract={In order to develop effective sequential recommenders, a series of sequence representation learning (SRL) methods are proposed to model historical user behaviors. Most existing SRL methods rely on explicit item IDs for developing the sequence models to better capture user preference. Though effective to some extent, these methods are difficult to be transferred to new recommendation scenarios, due to the limitation by explicitly modeling item IDs. To tackle this issue, we present a novel universal sequence representation learning approach, named UniSRec. The proposed approach utilizes the associated description text of items to learn transferable representations across different recommendation scenarios. For learning universal item representations, we design a lightweight item encoding architecture based on parametric whitening and mixture-of-experts enhanced adaptor. For learning universal sequence representations, we introduce two contrastive pre-training tasks by sampling multi-domain negatives. With the pre-trained universal sequence representation model, our approach can be effectively transferred to new recommendation domains or platforms in a parameter-efficient way, under either inductive or transductive settings. Extensive experiments conducted on real-world datasets demonstrate the effectiveness of the proposed approach. Especially, our approach also leads to a performance improvement in a cross-platform setting, showing the strong transferability of the proposed universal SRL method. The code and pre-trained model are available at: https://github.com/RUCAIBox/UniSRec.},
	note={New York, NY, USA},
	doi={10.1145/3534678.3539381},
	url={https://doi.org/10.1145/3534678.3539381}
}

@Misc{Geng2022,
	author={Geng, Shijie and Liu, Shuchang and Fu, Zuohui and Ge, Yingqiang and Zhang, Yongfeng},
	title={Recommendation as Language Processing (RLP): A Unified Pretrain, Personalized Prompt {\&} Predict Paradigm (P5)},
	year={2022},
	publisher={Association for Computing Machinery},
	pages={299--315},
	keywords={Language Modeling, Multitask Learning, Natural Language Processing, Personalized Prompt, Recommender Systems, Unified Model},
	abstract={For a long time, different recommendation tasks require designing task-specific architectures and training objectives. As a result, it is hard to transfer the knowledge and representations from one task to another, thus restricting the generalization ability of existing recommendation approaches. To deal with such issues, considering that language can describe almost anything and language grounding is a powerful medium to represent various problems or tasks, we present a flexible and unified text-to-text paradigm called ``Pretrain, Personalized Prompt, and Predict Paradigm'' (P5) for recommendation, which unifies various recommendation tasks in a shared framework. In P5, all data such as user-item interactions, user descriptions, item metadata, and user reviews are converted to a common format --- natural language sequences. The rich information from natural language assists P5 to capture deeper semantics for personalization and recommendation. Specifically, P5 learns different tasks with the same language modeling objective during pretraining. Thus, it serves as the foundation model for various downstream recommendation tasks, allows easy integration with other modalities, and enables instruction-based recommendation. P5 advances recommender systems from shallow model to deep model to big model, and will revolutionize the technical form of recommender systems towards universal recommendation engine. With adaptive personalized prompt for different users, P5 is able to make predictions in a zero-shot or few-shot manner and largely reduces the necessity for extensive fine-tuning. On several benchmarks, we conduct experiments to show the effectiveness of P5. To help advance future research on Recommendation as Language Processing (RLP), Personalized Foundation Models (PFM), and Universal Recommendation Engine (URE), we release the source code, dataset, prompts, and pretrained P5 model at https://github.com/jeykigung/P5.},
	note={New York, NY, USA},
	doi={10.1145/3523227.3546767},
	url={https://doi.org/10.1145/3523227.3546767}
}

@Misc{Bao2023,
	author={Bao, Keqin and Zhang, Jizhi and Zhang, Yang and Wang, Wenjie and Feng, Fuli and He, Xiangnan},
	title={TALLRec: An Effective and Efficient Tuning Framework to Align Large Language Model with Recommendation},
	year={2023},
	publisher={Association for Computing Machinery},
	pages={1007--1014},
	keywords={Instruction Tuning, Large Language Models, Recommendation},
	abstract={Large Language Models (LLMs) have demonstrated remarkable performance across diverse domains, thereby prompting researchers to explore their potential for use in recommendation systems. Initial attempts have leveraged the exceptional capabilities of LLMs, such as rich knowledge and strong generalization through In-context Learning, which involves phrasing the recommendation task as prompts. Nevertheless, the performance of LLMs in recommendation tasks remains suboptimal due to a substantial disparity between the training tasks for LLMs and recommendation tasks, as well as inadequate recommendation data during pre-training. To bridge the gap, we consider building a Large Recommendation Language Model by tunning LLMs with recommendation data. To this end, we propose an efficient and effective Tuning framework for Aligning LLMs with Recommendations, namely TALLRec. We have demonstrated that the proposed TALLRec framework can significantly enhance the recommendation capabilities of LLMs in the movie and book domains, even with a limited dataset of fewer than 100 samples. Additionally, the proposed framework is highly efficient and can be executed on a single RTX 3090 with LLaMA-7B. Furthermore, the fine-tuned LLM exhibits robust cross-domain generalization. Our code and data are available at https://github.com/SAI990323/TALLRec.},
	note={New York, NY, USA},
	doi={10.1145/3604915.3608857},
	url={https://doi.org/10.1145/3604915.3608857}
}

@Misc{Devlin2019,
	author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
	year={2019},
	month={Jun},
	publisher={Association for Computational Linguistics},
	pages={4171-4186},
	abstract={We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
	note={Minneapolis, Minnesota},
	doi={10.18653/v1/N19-1423},
	url={https://doi.org/10.18653/v1/N19-1423}
}

@Misc{Brown2020,
	author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D. and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
	title={Language Models are Few-Shot Learners},
	year={2020},
	publisher={Curran Associates, Inc.},
	volume={33},
	pages={1877-1901},
	doi={10.48550/arXiv.2005.14165},
	url={https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf}
}

@Article{Touvron2023,
	author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and Rodriguez, Aurelien and Joulin, Armand and Grave, Edouard and Lample, Guillaume},
	title={LLaMA: Open and Efficient Foundation Language Models},
	journal={arXiv preprint arXiv:2302.13971},
	year={2023},
	month={Feb},
	day={27},
	abstract={We introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters. We train our models on trillions of tokens, and show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks, and LLaMA-65B is competitive with the best models, Chinchilla-70B and PaLM-540B. We release all our models to the research community.},
	doi={10.48550/arXiv.2302.13971},
	url={https://doi.org/10.48550/arXiv.2302.13971}
}

@InProceedings{Hu2022,
	author={Hu, Edward J. and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
	title={LoRA: Low-Rank Adaptation of Large Language Models},
	year={2022},
	abstract={We propose Low-Rank Adaptation, or LoRA, which freezes the pre-trained model weights and injects trainable rank decomposition matrices into each layer of the Transformer architecture, greatly reducing the number of trainable parameters for downstream tasks.},
	note={International Conference on Learning Representations (ICLR)},
	doi={10.48550/arXiv.2106.09685},
	url={https://doi.org/10.48550/arXiv.2106.09685}
}

@Article{Gu2023,
	author={Gu, Albert and Dao, Tri},
	title={Mamba: Linear-Time Sequence Modeling with Selective State Spaces},
	journal={arXiv preprint arXiv:2312.00752},
	year={2023},
	month={Dec},
	day={01},
	abstract={Foundation models, now powering most of the exciting applications in deep learning, are almost universally based on the Transformer architecture and its core attention module. We propose a new class of selective state space models (SSMs) that improves on prior work on several axes to achieve the modeling power of Transformers while scaling linearly in sequence length.},
	doi={10.48550/arXiv.2312.00752},
	url={https://doi.org/10.48550/arXiv.2312.00752}
}

@InProceedings{Gu2022,
	author={Gu, Albert and Goel, Karan and R{\'e}, Christopher},
	title={Efficiently Modeling Long Sequences with Structured State Spaces},
	year={2022},
	abstract={We propose the Structured State Space sequence model (S4) based on a new parameterization for the SSM, and show that it can be computed much more efficiently than prior approaches while preserving their theoretical strengths. S4 achieves strong empirical results across a diverse range of benchmarks, including significantly outperforming Transformers on long-range tasks.},
	note={International Conference on Learning Representations (ICLR)},
	doi={10.48550/arXiv.2111.00396},
	url={https://doi.org/10.48550/arXiv.2111.00396}
}

@Article{Liu2024,
	author={Liu, Chengkai and Lin, Jianghao and Wang, Jianling and Liu, Hanzhou and Caverlee, James},
	title={Mamba4Rec: Towards Efficient Sequential Recommendation with Selective State Space Models},
	journal={arXiv preprint arXiv:2403.03900},
	year={2024},
	month={Mar},
	day={06},
	abstract={Sequential recommendation aims to estimate dynamic user preferences and sequential dependencies among historical user behaviors. Inspired by the recent success of state space models (SSMs), we propose Mamba4Rec, which is the first work to explore the potential of selective SSMs for efficient sequential recommendation. Built upon the basic Mamba block, we design a series of sequential modeling techniques to further promote model performance while maintaining inference efficiency.},
	doi={10.48550/arXiv.2403.03900},
	url={https://doi.org/10.48550/arXiv.2403.03900}
}

@Article{Wang2024,
	author={Wang, Yuda and He, Xuxin and Zhu, Shengxin},
	title={EchoMamba4Rec: Harmonizing Bidirectional State Space Models with Spectral Filtering for Advanced Sequential Recommendation},
	journal={arXiv preprint arXiv:2406.02638},
	year={2024},
	month={Jun},
	day={04},
	abstract={Drawing inspiration from the recent advancements of state space models (SSMs) in control theory... we introduce EchoMamba4Rec, a novel architecture that harmonizes bidirectional SSMs with spectral filtering to capture both sequential dependencies and frequency-domain patterns efficiently.},
	doi={10.48550/arXiv.2406.02638},
	url={https://doi.org/10.48550/arXiv.2406.02638}
}

@Article{Xiao2025,
	author={Xiao, Wei and Wang, Huiying and Zhou, Qifeng and Wang, Qing},
	title={SS4Rec: Continuous-Time Sequential Recommendation with State Space Models},
	journal={arXiv preprint arXiv:2502.08132},
	year={2025},
	month={Feb},
	day={12},
	abstract={Sequential recommendation is a key area in the field of recommendation systems aiming to model user interest based on historical interaction sequences with irregular intervals. We propose SS4Rec, which integrates a time-aware SSM to handle irregular time intervals and a relation-aware SSM to model contextual dependencies, enabling it to infer user interest from both temporal and sequential perspectives.},
	doi={10.48550/arXiv.2502.08132},
	url={https://doi.org/10.48550/arXiv.2502.08132}
}

@Article{Dao2024,
	author={Dao, Tri and Gu, Albert},
	title={Transformers are SSMs: Generalized Models and Efficient Algorithms Through Structured State Space Duality},
	journal={arXiv preprint arXiv:2405.21060},
	year={2024},
	month={May},
	day={31},
	abstract={We show that the dual forms of structured state space models (SSMs) and attention are closely related through a framework we call Structured State Space Duality (SSD). This allows us to design Mamba-2, an architecture that is 2-8x faster than Mamba while being competitive with Transformers.},
	doi={10.48550/arXiv.2405.21060},
	url={https://doi.org/10.48550/arXiv.2405.21060}
}

@InProceedings{Zhang2025,
	author={Zhang, Shun and Zhang, Runsen and Yin, Ziqiang and Yang, Zhirong},
	editor={Huang, De-Shuang and Chen, Wei and Pan, Yijie and Chen, Haiming},
	title={MaTrRec: A Mamba-Transformer Framework for Robust Sequential Recommendation},
	booktitle={Advanced Intelligent Computing Technology and Applications},
	year={2025},
	publisher={Springer Nature Singapore},
	address={Singapore},
	pages={448-459},
	abstract={Sequential recommendation techniques aim at providing personalized recommendations by analyzing the dynamic preferences and sequential dependencies in user behavior sequences. However, dense datasets consisting of long sequences have the difficulty of fully capturing the sequential dependencies within historical user behaviors, while sparsity datasets of short sequences often struggle to extract sufficient interaction information due to the limited historical user behaviors. These challenges lead to undesirable recommendation performance and exacerbate the difficulty of achieving effective recommendations in sparse data scenarios. Then, we propose a novel sequential recommendation model named MaTrRec that integrates Mamba and Transformer. This model leverages the linear complexity advantages of Mamba while effectively enhancing sequential dependency modeling through its state-space representation and efficient sequential processing capabilities in continuous space, enabling the extraction of deeper sequential information from historical user behaviors. Moreover, it utilizes the global attention mechanism of Transformer to thoroughly explore the dependencies among items in historical user behaviors, thereby enhancing the model's predictive performance and robustness across both long and short sequence datasets by effectively capturing both local and global contextual information. To further optimize the computational complexity of the model, we design a linear sequential recommendation model called MaTrRec*, which reduces the computational complexity through a linear attention mechanism and effectively balances the complexity and recommendation accuracy. Experimental valuations on five widely used public datasets demonstrate that MaTrRec and MaTrRec* outperform the state-of-the-art sequential recommendation models. Our MaTrRec can significantly achieve up to 8.49{\%} higher model accuracy. Code: https://github.com/Unintelligentmumu/MaTrRec.},
	isbn={978-981-95-0017-8},
	doi={10.48550/arXiv.2407.19239},
	url={https://doi.org/10.48550/arXiv.2407.19239}
}

@Article{Qu2024,
	author={Qu, Haohao and Zhang, Yifeng and Ning, Liangbo and Fan, Wenqi and Li, Qing},
	title={SSD4Rec: A Structured State Space Duality Model for Efficient Sequential Recommendation},
	journal={arXiv},
	year={2024},
	volume={abs/2409.01192},
	abstract={Sequential recommendation methods are crucial in modern recommender systems for their remarkable capability to understand a user's changing interests based on past interactions. However, a significant challenge faced by current methods (e.g., RNN- or Transformer-based models) is to effectively and efficiently capture users' preferences by modeling long behavior sequences, which impedes their applications like short video platforms where interactions are numerous. Inspired by the Mamba architecture built on state space models (SSM), we propose SSD4Rec, a generic and efficient sequential recommendation backbone that leverages bidirectional Structured State Space Duality (SSD) blocks to achieve near-linear scalability with sequence length.},
	doi={10.48550/arXiv.2409.01192},
	url={https://doi.org/10.48550/arXiv.2409.01192}
}

@Article{Fan2025,
	author={Fan, Hao and Zhu, Mengyi and Hu, Yanrong and Feng, Hailin and He, Zhijie and Liu, Hongjiu and Liu, Qingyang},
	title={TiM4Rec: An efficient sequential recommendation model based on time-aware structured state space duality model},
	journal={Neurocomputing},
	year={2025},
	month={Nov},
	day={14},
	volume={654},
	pages={131270},
	keywords={Sequential recommendation; State space model (SSM); State space duality (SSD); Mamba; Time-awareness},
	abstract={The modeling paradigm of sequential recommendation is shifting from Transformer to Mamba, including Mamba1, based on the State Space Model (SSM), and Mamba2, based on State Space Duality (SSD). While SSD achieves higher computational efficiency, it faces performance degradation in low-dimensional scenarios which is crucial for sequential recommendation tasks. Considering that time-aware enhancement methods are commonly employed to mitigate performance loss, our analysis reveals that the performance decline of SSD can similarly be fundamentally compensated by leveraging mechanisms in time-aware methods. To overcome challenges in adapting existing time-aware methods like TiSASRec, such as compatibility with SSD and computational inefficiencies in time-difference modeling, we propose Time-Aware Mamba for Recommendation (TiM4Rec), which integrates a novel Time-aware Structured Masked Matrix into SSD to enhance performance while improving efficiency. Extensive experiments on four real-world datasets demonstrate its superiority, marking the first time-aware method tailored to Mamba for sequential recommendation. The code for our model is accessible at https://github.com/AlwaysFHao/TiM4Rec.},
	issn={0925-2312},
	doi={10.1016/j.neucom.2025.131270},
	url={https://www.sciencedirect.com/science/article/pii/S0925231225019423}
}

@Article{Deldjoo2021,
	author={Deldjoo, Yashar and Noia, Tommaso Di and Merra, Felice Antonio},
	title={A Survey on Adversarial Recommender Systems: From Attack/Defense Strategies to Generative Adversarial Networks},
	journal={ACM Comput. Surv.},
	year={2021},
	month={Mar},
	publisher={Association for Computing Machinery},
	address={New York, NY, USA},
	volume={54},
	number={2},
	keywords={Recommender systems, adversarial machine learning, adversarial perturbation, generative adversarial network, min-max game, privacy, robustness, security},
	abstract={Latent-factor models (LFM) based on collaborative filtering (CF), such as matrix factorization (MF) and deep CF methods, are widely used in modern recommender systems (RS) due to their excellent performance and recommendation accuracy. However, success has been accompanied with a major new arising challenge: Many applications of machine learning (ML) are adversarial in nature [146]. In recent years, it has been shown that these methods are vulnerable to adversarial examples, i.e., subtle but non-random perturbations designed to force recommendation models to produce erroneous outputs.The goal of this survey is two-fold: (i) to present recent advances on adversarial machine learning (AML) for the security of RS (i.e., attacking and defense recommendation models) and (ii) to show another successful application of AML in generative adversarial networks (GANs) for generative applications, thanks to their ability for learning (high-dimensional) data distributions. In this survey, we provide an exhaustive literature review of 76 articles published in major RS and ML journals and conferences. This review serves as a reference for the RS community working on the security of RS or on generative models using GANs to improve their quality.},
	issn={0360-0300},
	doi={10.1145/3439729},
	url={https://doi.org/10.1145/3439729}
}

@Misc{Wang2024,
	author={Wang, Zongwei and Gao, Min and Yu, Junliang and Ma, Hao and Yin, Hongzhi and Sadiq, Shazia},
	title={Poisoning Attacks against Recommender Systems: A Survey},
	year={2024},
	abstract={This survey provides a comprehensive overview of poisoning attacks in recommender systems, including a taxonomy of attack types, analysis of methodologies, and discussion of defense strategies. The authors also introduce ARLib, an open-source library for benchmarking such attacks.},
	doi={10.48550/arXiv.2401.01527},
	url={https://doi.org/10.48550/arXiv.2401.01527}
}
@Misc{Lam2004,
	author={Lam, Shyong K. and Riedl, John},
	title={Shilling recommender systems for fun and profit},
	year={2004},
	publisher={Association for Computing Machinery},
	pages={393--402},
	keywords={collaborative filtering, recommender systems, shilling},
	abstract={Recommender systems have emerged in the past several years as an effective way to help people cope with the problem of information overload. One application in which they have become particularly common is in e-commerce, where recommendation of items can often help a customer find what she is interested in and, therefore can help drive sales. Unscrupulous producers in the never-ending quest for market penetration may find it profitable to shill recommender systems by lying to the systems in order to have their products recommended more often than those of their competitors. This paper explores four open questions that may affect the effectiveness of such shilling attacks: which recommender algorithm is being used, whether the application is producing recommendations or predictions, how detectable the attacks are by the operator of the system, and what the properties are of the items being attacked. The questions are explored experimentally on a large data set of movie ratings. Taken together, the results of the paper suggest that new ways must be used to evaluate and detect shilling attacks on recommender systems.},
	note={New York, NY, USA},
	doi={10.1145/988672.988726},
	url={https://doi.org/10.1145/988672.988726}
}

@Misc{Li2016,
	author={Li, Bo and Wang, Yining and Singh, Aarti and Vorobeychik, Yevgeniy},
	title={Data Poisoning Attacks on Factorization-Based Collaborative Filtering},
	year={2016},
	publisher={Curran Associates, Inc.},
	volume={29},
	doi={10.48550/arXiv.1608.08182},
	url={https://proceedings.neurips.cc/paper_files/paper/2016/file/83fa5a432ae55c253d0e60dbfa716723-Paper.pdf}
}

@Misc{Lin2020,
	author={Lin, Chen and Chen, Si and Li, Hui and Xiao, Yanghua and Li, Lianyun and Yang, Qian},
	title={Attacking Recommender Systems with Augmented User Profiles},
	year={2020},
	publisher={Association for Computing Machinery},
	pages={855--864},
	keywords={shilling attack, recommender systems, generative adversarial network},
	abstract={Recommendation Systems (RS) have become an essential part of many online services. Due to its pivotal role in guiding customers towards purchasing, there is a natural motivation for unscrupulous parties to spoof RS for profits. In this paper, we study the shilling attack: a subsistent and profitable attack where an adversarial party injects a number of user profiles to promote or demote a target item. Conventional shilling attack models are based on simple heuristics that can be easily detected, or directly adopt adversarial attack methods without a special design for RS. Moreover, the study on the attack impact on deep learning based RS is missing in the literature, making the effects of shilling attack against real RS doubtful. We present a novel Augmented Shilling Attack framework (AUSH) and implement it with the idea of Generative Adversarial Network. AUSH is capable of tailoring attacks against RS according to budget and complex attack goals, such as targeting a specific user group. We experimentally show that the attack impact of AUSH is noticeable on a wide range of RS including both classic and modern deep learning based RS, while it is virtually undetectable by the state-of-the-art attack detection model.},
	note={New York, NY, USA},
	doi={10.1145/3340531.3411884},
	url={https://doi.org/10.1145/3340531.3411884}
}

@Article{Wu2021_GOAT,
	author={Wu, Fan and Gao, Min and Yu, Junliang and Wang, Zongwei and Liu, Kecheng and Wang, Xu},
	title={Ready for emerging threats to recommender systems? A graph convolution-based generative shilling attack},
	journal={Information Sciences},
	year={2021},
	month={Nov},
	day={01},
	volume={578},
	pages={683-701},
	keywords={Collaborative filtering; Shilling attack; Generative adversarial networks; Graph convolution; Recommender systems},
	abstract={To explore the robustness of recommender systems, researchers have proposed various shilling attack models and analyzed their adverse effects. Primitive attacks are highly feasible but less effective due to simplistic handcrafted rules, while upgraded attacks are more powerful but costly and difficult to deploy because they require more knowledge from recommendations. In this paper, we explore a novel shilling attack called Graph cOnvolution-based generative shilling ATtack (GOAT) to balance the attacks' feasibility and effectiveness. GOAT adopts the primitive attacks' paradigm that assigns items for fake users by sampling and the upgraded attacks' paradigm that generates fake ratings by a deep learning-based model. It deploys a generative adversarial network (GAN) that learns the real rating distribution to generate fake ratings. Additionally, the generator combines a tailored graph convolution structure that leverages the correlations between co-rated items to smoothen the fake ratings and enhance their authenticity. The extensive experiments on two public datasets evaluate GOAT's performance from multiple perspectives. Our study of the GOAT demonstrates technical feasibility for building a more powerful and intelligent attack model with a much-reduced cost, enables analysis the threat of such an attack and guides for investigating necessary prevention measures.},
	issn={0020-0255},
	doi={10.1016/j.ins.2021.07.041},
	url={https://www.sciencedirect.com/science/article/pii/S0020025521007313}
}

@InProceedings{Fan2021,
	author={Fan, W. and Derr, T. and Zhao, X. and Ma, Y. and Liu, H. and Wang, J. and Tang, J. and Li, Q.},
	title={Attacking Black-box Recommendations via Copying Cross-domain User Profiles},
	booktitle={2021 IEEE 37th International Conference on Data Engineering (ICDE)},
	series={2021 IEEE 37th International Conference on Data Engineering (ICDE)},
	year={2021},
	pages={1583-1594},
	issn={2375-026X},
	doi={10.1109/ICDE51399.2021.00140},
	url={https://doi.org/10.1109/ICDE51399.2021.00140}
}

@Misc{Huang2021,
	author={Huang, Hai and Mu, Jiaming and Gong, Neil Zhenqiang and Li, Qi and Liu, Bin and Xu, Mingwei},
	title={Data Poisoning Attacks to Deep Learning Based Recommender Systems},
	year={2021},
	publisher={Internet Society},
	doi={10.14722/ndss.2021.24525},
	url={https://doi.org/10.14722/ndss.2021.24525}
}

@Misc{Fang2018,
	author={Fang, Minghong and Yang, Guolei and Gong, Neil Zhenqiang and Liu, Jia},
	title={Poisoning Attacks to Graph-Based Recommender Systems},
	year={2018},
	publisher={Association for Computing Machinery},
	pages={381--392},
	keywords={poisoning attacks, adversarial machine learning, Adversarial recommender systems},
	abstract={Recommender system is an important component of many web services to help users locate items that match their interests. Several studies showed that recommender systems are vulnerable to poisoning attacks, in which an attacker injects fake data to a recommender system such that the system makes recommendations as the attacker desires. However, these poisoning attacks are either agnostic to recommendation algorithms or optimized to recommender systems (e.g., association-rule-based or matrix-factorization-based recommender systems) that are not graph-based. Like association-rule-based and matrix-factorization-based recommender systems, graph-based recommender system is also deployed in practice, e.g., eBay, Huawei App Store (a big app store in China). However, how to design optimized poisoning attacks for graph-based recommender systems is still an open problem.In this work, we perform a systematic study on poisoning attacks to graph-based recommender systems. We consider an attacker's goal is to promote a target item to be recommended to as many users as possible. To achieve this goal, our a"acks inject fake users with carefully crafted rating scores to the recommender system. Due to limited resources and to avoid detection, we assume the number of fake users that can be injected into the system is bounded. The key challenge is how to assign rating scores to the fake users such that the target item is recommended to as many normal users as possible. To address the challenge, we formulate the poisoning attacks as an optimization problem, solving which determines the rating scores for the fake users. We also propose techniques to solve the optimization problem. We evaluate our attacks and compare them with existing attacks under white-box (recommendation algorithm and its parameters are known), gray-box (recommendation algorithm is known but its parameters are unknown), and blackbox (recommendation algorithm is unknown) settings using two real-world datasets. Our results show that our attack is effective and outperforms existing attacks for graph-based recommender systems. For instance, when 1{\%} of users are injected fake users, our attack can make a target item recommended to 580 times more normal users in certain scenarios.},
	note={New York, NY, USA},
	doi={10.1145/3274694.3274706},
	url={https://doi.org/10.1145/3274694.3274706}
}

@InProceedings{Song2020,
	author={Song, J. and Li, Z. and Hu, Z. and Wu, Y. and Li, J. and Gao, J.},
	title={PoisonRec: An Adaptive Data Poisoning Framework for Attacking Black-box Recommender Systems},
	booktitle={2020 IEEE 36th International Conference on Data Engineering (ICDE)},
	series={2020 IEEE 36th International Conference on Data Engineering (ICDE)},
	year={2020},
	pages={157-168},
	issn={2375-026X},
	doi={10.1109/ICDE48307.2020.00021},
	url={https://doi.org/10.1109/ICDE48307.2020.00021}
}

@Misc{Zhang2020_LOKI,
	author={Zhang, Hengtong and Li, Yaliang and Ding, Bolin and Gao, Jing},
	title={Practical Data Poisoning Attack against Next-Item Recommendation},
	year={2020},
	publisher={Association for Computing Machinery},
	pages={2458--2464},
	keywords={Adversarial Learning, Data Poisoning, Recommendation System},
	abstract={Online recommendation systems make use of a variety of information sources to provide users the items that users are potentially interested in. However, due to the openness of the online platform, recommendation systems are vulnerable to data poisoning attacks. Existing attack approaches are either based on simple heuristic rules or designed against specific recommendations approaches. The former often suffers unsatisfactory performance, while the latter requires strong knowledge of the target system. In this paper, we focus on a general next-item recommendation setting and propose a practical poisoning attack approach named LOKI against blackbox recommendation systems. The proposed LOKI utilizes the reinforcement learning algorithm to train the attack agent, which can be used to generate user behavior samples for data poisoning. In real-world recommendation systems, the cost of retraining recommendation models is high, and the interaction frequency between users and a recommendation system is restricted. Given these real-world restrictions, we propose to let the agent interact with a recommender simulator instead of the target recommendation system and leverage the transferability of the generated adversarial samples to poison the target system. We also propose to use the influence function to efficiently estimate the influence of injected samples on the recommendation results, without re-training the models within the simulator. Extensive experiments on two datasets against four representative recommendation models show that the proposed LOKI achieves better attacking performance than existing methods.},
	note={New York, NY, USA},
	doi={10.1145/3366423.3379992},
	url={https://doi.org/10.1145/3366423.3379992}
}

@Misc{Wan2023,
	author={Wan, Alexander and Wallace, Eric and Shen, Sheng and Klein, Dan},
	title={Poisoning Language Models During Instruction Tuning},
	year={2023},
	publisher={PMLR},
	volume={202},
	pages={35413-35425},
	abstract={Instruction-tuned LMs such as ChatGPT, FLAN, and InstructGPT are finetuned on datasets that contain user-submitted examples, e.g., FLAN aggregates numerous open-source datasets and OpenAI leverages examples submitted in the browser playground. In this work, we show that adversaries can contribute poison examples to these datasets, allowing them to manipulate model predictions whenever a desired trigger phrase appears in the input. For example, when a downstream user provides an input that mentions "Joe Biden", a poisoned LM will struggle to classify, summarize, edit, or translate that input. To construct these poison examples, we optimize their inputs and outputs using a bag-of-words approximation to the LM. We evaluate our method on open-source instruction-tuned LMs. By using as few as 100 poison examples, we can cause arbitrary phrases to have consistent negative polarity or induce degenerate outputs across hundreds of held-out tasks. Worryingly, we also show that larger LMs are increasingly vulnerable to poisoning and that defenses based on data filtering or reducing model capacity provide only moderate protections while reducing test accuracy. Notice: This paper contains tasks with obscene content.},
	doi={10.48550/arXiv.2305.00944},
	url={https://proceedings.mlr.press/v202/wan23b.html}
}

@Article{Lin2024,
	author={Lin, C. and Chen, S. and Zeng, M. and Zhang, S. and Gao, M. and Li, H.},
	title={Shilling Black-Box Recommender Systems by Learning to Generate Fake User Profiles},
	journal={IEEE Transactions on Neural Networks and Learning Systems},
	year={2024},
	volume={35},
	number={1},
	pages={1305-1319},
	issn={2162-2388},
	doi={10.1109/TNNLS.2022.3183210},
	url={https://doi.org/10.1109/TNNLS.2022.3183210}
}

@Misc{Tramèr2016,
	author={Tram{\`e}r, Florian and Zhang, Fan and Juels, Ari and Reiter, Michael K. and Ristenpart, Thomas},
	title={Stealing Machine Learning Models via Prediction APIs},
	year={2016},
	month={Aug},
	publisher={USENIX Association},
	pages={601-618},
	note={Austin, TX},
	doi={10.48550/arXiv.1609.02943},
	url={https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/tramer}
}

@Article{Herlocker2004,
	author={Herlocker, Jonathan L. and Konstan, Joseph A. and Terveen, Loren G. and Riedl, John T.},
	title={Evaluating collaborative filtering recommender systems},
	journal={ACM Trans. Inf. Syst.},
	year={2004},
	month={Jan},
	publisher={Association for Computing Machinery},
	address={New York, NY, USA},
	volume={22},
	number={1},
	pages={5--53},
	keywords={Collaborative filtering, evaluation, metrics, recommender systems},
	abstract={Recommender systems have been evaluated in many, often incomparable, ways. In this article, we review the key decisions in evaluating collaborative filtering recommender systems: the user tasks being evaluated, the types of analysis and datasets being used, the ways in which prediction quality is measured, the evaluation of prediction attributes other than quality, and the user-based evaluation of the system as a whole. In addition to reviewing the evaluation strategies used by prior researchers, we present empirical results from the analysis of various accuracy metrics on one content domain where all the tested metrics collapsed roughly into three equivalence classes. Metrics within each equivalency class were strongly correlated, while metrics from different equivalency classes were uncorrelated.},
	issn={1046-8188},
	doi={10.1145/963770.963772},
	url={https://doi.org/10.1145/963770.963772}
}

@Article{Zangerle2022,
	author={Zangerle, Eva and Bauer, Christine},
	title={Evaluating Recommender Systems: Survey and Framework},
	journal={ACM Comput. Surv.},
	year={2022},
	month={Dec},
	publisher={Association for Computing Machinery},
	address={New York, NY, USA},
	volume={55},
	number={8},
	keywords={FEVR, Framework for EValuating Recommender systems, Survey},
	abstract={The comprehensive evaluation of the performance of a recommender system is a complex endeavor: many facets need to be considered in configuring an adequate and effective evaluation setting. Such facets include, for instance, defining the specific goals of the evaluation, choosing an evaluation method, underlying data, and suitable evaluation metrics. In this article, we consolidate and systematically organize this dispersed knowledge on recommender systems evaluation. We introduce the Framework for Evaluating Recommender systems (FEVR), which we derive from the discourse on recommender systems evaluation. In FEVR, we categorize the evaluation space of recommender systems evaluation. We postulate that the comprehensive evaluation of a recommender system frequently requires considering multiple facets and perspectives in the evaluation. The FEVR framework provides a structured foundation to adopt adequate evaluation configurations that encompass this required multi-facetedness and provides the basis to advance in the field. We outline and discuss the challenges of a comprehensive evaluation of recommender systems and provide an outlook on what we need to embrace and do to move forward as a research community.},
	issn={0360-0300},
	doi={10.1145/3556536},
	url={https://doi.org/10.1145/3556536}
}

@Misc{Sun2020,
	author={Sun, Zhu and Yu, Di and Fang, Hui and Yang, Jie and Qu, Xinghua and Zhang, Jie and Geng, Cong},
	title={Are We Evaluating Rigorously? Benchmarking Recommendation for Reproducible Evaluation and Fair Comparison},
	year={2020},
	publisher={Association for Computing Machinery},
	pages={23--32},
	keywords={Reproducible Evaluation, Recommender Systems, Benchmarks},
	abstract={With tremendous amount of recommendation algorithms proposed every year, one critical issue has attracted a considerable amount of attention: there are no effective benchmarks for evaluation, which leads to two major concerns, i.e., unreproducible evaluation and unfair comparison. This paper aims to conduct rigorous (i.e., reproducible and fair) evaluation for implicit-feedback based top-N recommendation algorithms. We first systematically review 85 recommendation papers published at eight top-tier conferences (e.g., RecSys, SIGIR) to summarize important evaluation factors, e.g., data splitting and parameter tuning strategies, etc. Through a holistic empirical study, the impacts of different factors on recommendation performance are then analyzed in-depth. Following that, we create benchmarks with standardized procedures and provide the performance of seven well-tuned state-of-the-arts across six metrics on six widely-used datasets as a reference for later study. Additionally, we release a user-friendly Python toolkit, which differs from existing ones in addressing the broad scope of rigorous evaluation for recommendation. Overall, our work sheds light on the issues in recommendation evaluation and lays the foundation for further investigation. Our code and datasets are available at GitHub (https://github.com/AmazingDD/daisyRec).},
	note={New York, NY, USA},
	doi={10.1145/3383313.3412489},
	url={https://doi.org/10.1145/3383313.3412489}
}

@Article{Arulkumaran2017,
	author={Arulkumaran, K. and Deisenroth, M. P. and Brundage, M. and Bharath, A. A.},
	title={Deep Reinforcement Learning: A Brief Survey},
	journal={IEEE Signal Processing Magazine},
	year={2017},
	volume={34},
	number={6},
	pages={26-38},
	issn={1558-0792},
	doi={10.1109/MSP.2017.2743240},
	url={https://doi.org/10.1109/MSP.2017.2743240}
}

@Article{vanHasselt2016,
	author={van Hasselt, Hado and Guez, Arthur and Silver, David},
	title={Deep Reinforcement Learning with Double Q-Learning},
	journal={Proceedings of the AAAI Conference on Artificial Intelligence},
	year={2016},
	month={Mar},
	day={02},
	volume={30},
	number={1},
	abstract={{\&}lt;p{\&}gt; The popular Q-learning algorithm is known to overestimate action values under certain conditions. It was not previously known whether, in practice, such overestimations are common, whether they harm performance, and whether they can generally be prevented.  In this paper, we answer all these questions affirmatively.  In particular, we first show that the recent DQN algorithm, which combines Q-learning with a deep neural network, suffers from substantial overestimations in some games in the Atari 2600 domain.  We then show that the idea behind the Double Q-learning algorithm, which was introduced in a tabular setting, can be generalized to work with large-scale function approximation.  We propose a specific adaptation to the DQN algorithm and show that the resulting algorithm not only reduces the observed overestimations, as hypothesized, but that this also leads to much better performance on several games.      {\&}lt;/p{\&}gt;},
	doi={10.1609/aaai.v30i1.10295},
	url={https://ojs.aaai.org/index.php/AAAI/article/view/10295},
	url={https://doi.org/10.1609/aaai.v30i1.10295}
}

@InProceedings{Wang2016,
	author={Wang, Ziyu and Schaul, Tom and Hessel, Matteo and Hasselt, Hado and Lanctot, Marc and Freitas, Nando},
	title={Dueling Network Architectures for Deep Reinforcement Learning},
	booktitle={Proceedings of the 33rd International Conference on Machine Learning},
	editor={Balcan, Maria Florina and Weinberger, Kilian Q.},
	year={2016},
	volume={48},
	pages={1995--2003},
	publisher={PMLR},
	url={https://proceedings.mlr.press/v48/wangf16.html}
}

@Article{Mnih2015,
	author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
	title={Human-level control through deep reinforcement learning},
	journal={Nature},
	year={2015},
	month={Feb},
	day={01},
	volume={518},
	number={7540},
	pages={529-533},
	abstract={An artificial agent is developed that learns to play a diverse range of classic Atari 2600 computer games directly from sensory experience, achieving a performance comparable to that of an expert human player; this work paves the way to building general-purpose learning algorithms that bridge the divide between perception and action.},
	issn={1476-4687},
	doi={10.1038/nature14236},
	url={https://doi.org/10.1038/nature14236}
}

@Inbook{Fayaz2022,
	author={Fayaz, Sheikh Amir and Jahangeer Sidiq, S. and Zaman, Majid and Butt, Muheet Ahmed},
	title={Machine Learning: An Introduction to Reinforcement Learning},
	series={Machine Learning and Data Science},
	year={2022},
	month={Jul},
	day={30},
	pages={1-22},
	keywords={Reinforcement learning; Markov decision process; agent-environment interaction; exploitation; exploration},
	abstract={Summary Reinforcement Learning (RL) is a prevalent prototype for finite sequential decision making under improbability. A distinctive RL algorithm functions with only restricted knowledge of the environment and with limited response or feedback on the quality of the conclusions. To work efficiently in complex environments, learning agents entail the capability to form convenient generalizations, that is, the ability to selectively overlook extraneous facts. It is a challenging task to develop a single illustration that is suitable for a large problem setting. This chapter provides a brief introduction to reinforcement learning models, procedures, techniques, and reinforcement learning processes. Particular focus is on the aspects related to the agent-environment interface and how Reinforcement Learning can be used in various daily life practical applications. The basic concept that we will explore is that of a solution to the Re-enforcement Learning problem using the Markov Decision Process (MDP). We assume that the reader has a basic idea of machine learning concepts and algorithms.},
	note={Wiley Online Books},
	isbn={9781119776499},
	doi={10.1002/9781119776499.ch1},
	url={https://doi.org/10.1002/9781119776499.ch1}
}

@Article{Watkins1992,
	author={Watkins, Christopher J. C. H. and Dayan, Peter},
	title={Q-learning},
	journal={Machine Learning},
	year={1992},
	month={May},
	day={01},
	volume={8},
	number={3},
	pages={279-292},
	abstract={Q-learning (Watkins, 1989) is a simple way for agents to learn how to act optimally in controlled Markovian domains. It amounts to an incremental method for dynamic programming which imposes limited computational demands. It works by successively improving its evaluations of the quality of particular actions at particular states.},
	issn={1573-0565},
	doi={10.1007/BF00992698},
	url={https://doi.org/10.1007/BF00992698}
}

@Misc{Mnih2013,
	author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
	title={Playing Atari with Deep Reinforcement Learning},
	year={2013},
	archivePrefix={arXiv},
	eprint={1312.5602},
	doi={10.48550/arXiv.1312.5602},
	url={http://arxiv.org/abs/1312.5602}
}

@Book{Sutton2018,
	author={Sutton, Richard S. and Barto, Andrew G.},
	title={Reinforcement Learning: An Introduction},
	year={2018},
	publisher={MIT Press},
	address={Cambridge, MA, USA},
	isbn={9780262039246},
	url={http://incompleteideas.net/book/the-book.html}
}

@Article{Schaul2015,
	author={Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
	title={Prioritized Experience Replay},
	series={arXiv},
	year={2015},
	month={Nov},
	day={18},
	doi={10.48550/arXiv.1511.05952},
	url={https://arxiv.org/abs/1511.05952}
}

@Misc{Schulman2017,
	author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
	title={Proximal Policy Optimization Algorithms},
	year={2017},
	archivePrefix={arXiv},
	doi={10.48550/arXiv.1707.06347},
	url={http://arxiv.org/abs/1707.06347}
}

@Misc{Lillicrap2019,
	author={Lillicrap, Timothy P. and Hunt, Jonathan J. and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
	title={Continuous control with deep reinforcement learning},
	year={2019},
	archivePrefix={arXiv},
	doi={10.48550/arXiv.1509.02971},
	url={http://arxiv.org/abs/1509.02971}
}

@Misc{Haarnoja2018,
	author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
	title={Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
	year={2018},
	publisher={PMLR},
	volume={80},
	pages={1861-1870},
	abstract={Model-free deep reinforcement learning (RL) algorithms have been demonstrated on a range of challenging decision making and control tasks. However, these methods typically suffer from two major challenges: very high sample complexity and brittle convergence properties, which necessitate meticulous hyperparameter tuning. Both of these challenges severely limit the applicability of such methods to complex, real-world domains. In this paper, we propose soft actor-critic, an off-policy actor-critic deep RL algorithm based on the maximum entropy reinforcement learning framework. In this framework, the actor aims to maximize expected reward while also maximizing entropy. That is, to succeed at the task while acting as randomly as possible. Prior deep RL methods based on this framework have been formulated as Q-learning methods. By combining off-policy updates with a stable stochastic actor-critic formulation, our method achieves state-of-the-art performance on a range of continuous control benchmark tasks, outperforming prior on-policy and off-policy methods. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving very similar performance across different random seeds.},
	doi={10.48550/arXiv.1801.01290},
	url={https://proceedings.mlr.press/v80/haarnoja18b.html}
}

@Misc{Fujimoto2018,
	author={Fujimoto, Scott and van Hoof, Herke and Meger, David},
	title={Addressing Function Approximation Error in Actor-Critic Methods},
	year={2018},
	publisher={PMLR},
	volume={80},
	pages={1587-1596},
	abstract={In value-based reinforcement learning methods such as deep Q-learning, function approximation errors are known to lead to overestimated value estimates and suboptimal policies. We show that this problem persists in an actor-critic setting and propose novel mechanisms to minimize its effects on both the actor and the critic. Our algorithm builds on Double Q-learning, by taking the minimum value between a pair of critics to limit overestimation. We draw the connection between target networks and overestimation bias, and suggest delaying policy updates to reduce per-update error and further improve performance. We evaluate our method on the suite of OpenAI gym tasks, outperforming the state of the art in every environment tested.},
	doi={10.48550/arXiv.1802.09477},
	url={https://proceedings.mlr.press/v80/fujimoto18a.html}
}

@Misc{Dulac-Arnold2016,
	author={Dulac-Arnold, Gabriel and Evans, Richard and van Hasselt, Hado and Sunehag, Peter and Lillicrap, Timothy and Hunt, Jonathan and Mann, Timothy and Weber, Theophane and Degris, Thomas and Coppin, Ben},
	title={Deep Reinforcement Learning in Large Discrete Action Spaces},
	year={2016},
	archivePrefix={arXiv},
	doi={10.48550/arXiv.1512.07679},
	url={http://arxiv.org/abs/1512.07679}
}

@Article{Kaelbling1998,
	author={Kaelbling, Leslie Pack and Littman, Michael L. and Cassandra, Anthony R.},
	title={Planning and acting in partially observable stochastic domains},
	journal={Artificial Intelligence},
	year={1998},
	month={May},
	day={01},
	volume={101},
	number={1},
	pages={99-134},
	keywords={Planning; Uncertainty; Partially observable Markov decision processes},
	abstract={In this paper, we bring techniques from operations research to bear on the problem of choosing optimal actions in partially observable stochastic domains. We begin by introducing the theory of Markov decision processes (mdps) and partially observable MDPs (pomdps). We then outline a novel algorithm for solving pomdps off line and show how, in some cases, a finite-memory controller can be extracted from the solution to a POMDP. We conclude with a discussion of how our approach relates to previous work, the complexity of finding exact solutions to pomdps, and of some possibilities for finding approximate solutions.},
	issn={0004-3702},
	doi={10.1016/S0004-3702(98)00023-X},
	url={https://www.sciencedirect.com/science/article/pii/S000437029800023X}
}

@Misc{Levine2020,
	author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
	title={Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems},
	year={2020},
	archivePrefix={arXiv},
	eprint={2005.01643},
	doi={10.48550/arXiv.2005.01643},
	url={http://doi.org/10.48550/arXiv.2005.01643}
}

@Inbook{Sutton1990,
	author={Sutton, Richard S.},
	title={Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic Programming},
	bookTitle={Machine Learning Proceedings 1990},
	year={1990},
	month={Jan},
	day={01},
	publisher={Morgan Kaufmann},
	address={San Francisco (CA)},
	pages={216-224},
	abstract={This paper extends previous work with Dyna, a class of architectures for intelligent systems based on approximating dynamic programming methods. Dyna architectures integrate trial-and-error (reinforcement) learning and execution-time planning into a single process operating alternately on the world and on a learned model of the world. In this paper, I present and show results for two Dyna architectures. The Dyna-PI architecture is based on dynamic programming's policy iteration method and can be related to existing AI ideas such as evaluation functions and universal plans (reactive systems). Using a navigation task, results are shown for a simple Dyna-PI system that simultaneously learns by trial and error, learns a world model, and plans optimal routes using the evolving world model. The Dyna-Q architecture is based on Watkins's Q-learning, a new kind of reinforcement learning. Dyna-Q uses a less familiar set of data structures than does Dyna-PI, but is arguably simpler to implement and use. We show that Dyna-Q architectures are easy to adapt for use in changing environments.},
	isbn={978-1-55860-141-3},
	doi={10.1016/B978-1-55860-141-3.50030-4},
	url={https://www.sciencedirect.com/science/article/pii/B9781558601413500304}
}

@Article{Browne2012,
	author={Browne, C. B. and Powley, E. and Whitehouse, D. and Lucas, S. M. and Cowling, P. I. and Rohlfshagen, P. and Tavener, S. and Perez, D. and Samothrakis, S. and Colton, S.},
	title={A Survey of Monte Carlo Tree Search Methods},
	journal={IEEE Transactions on Computational Intelligence and AI in Games},
	year={2012},
	volume={4},
	number={1},
	pages={1-43},
	issn={1943-0698},
	doi={10.1109/TCIAIG.2012.2186810},
	url={https://doi.org/10.1109/TCIAIG.2012.2186810}
}

@Misc{Ha2018,
	author={Ha, David and Schmidhuber, J{\"u}rgen},
	title={Recurrent World Models Facilitate Policy Evolution},
	year={2018},
	publisher={Curran Associates, Inc.},
	volume={31},
	doi={10.48550/arXiv.1809.01999},
	url={https://proceedings.neurips.cc/paper_files/paper/2018/file/2de5d16682c3c35007e4e92982f1a2ba-Paper.pdf}
}

@Article{Williams1992,
	author={Williams, Ronald J.},
	title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
	journal={Machine Learning},
	year={1992},
	month={May},
	day={01},
	volume={8},
	number={3},
	pages={229-256},
	abstract={This article presents a general class of associative reinforcement learning algorithms for connectionist networks containing stochastic units. These algorithms, called REINFORCE algorithms, are shown to make weight adjustments in a direction that lies along the gradient of expected reinforcement in both immediate-reinforcement tasks and certain limited forms of delayed-reinforcement tasks, and they do this without explicitly computing gradient estimates or even storing information from which such estimates could be computed. Specific examples of such algorithms are presented, some of which bear a close relationship to certain existing algorithms while others are novel but potentially interesting in their own right. Also given are results that show how such algorithms can be naturally integrated with backpropagation. We close with a brief discussion of a number of additional issues surrounding the use of such algorithms, including what is known about their limiting behaviors as well as further considerations that might be used to help develop similar but potentially more powerful reinforcement learning algorithms.},
	issn={1573-0565},
	doi={10.1007/BF00992696},
	url={https://doi.org/10.1007/BF00992696}
}

@TechReport{Rummery1994,
	author={Rummery, Gavin A. and Niranjan, Mahesan},
	title={On-Line Q-Learning Using Connectionist Systems},
	year={1994},
	publisher={Cambridge University Engineering Department},
	address={Cambridge, UK},
	url={https://www.researchgate.net/profile/Mahesan-Niranjan/publication/2500611_On-Line_Q-Learning_Using_Connectionist_Systems/links/5438d5db0cf204cab1d6db0f/On-Line-Q-Learning-Using-Connectionist-Systems.pdf?_sg%5B0%5D=HYd0h230b7WOR6m4hj5yx01K97aS61Z0DufUURMQr9ZqMqcEVZ0dNpG84h6uCfRl_M40FNkXgRX-GnpnxH31Ww.jBF3fgrlhaJYs3bDEaHQU22nRpKP0zKeF_oOsqh7WddL8pfxAomPSbeANzdmLP9YPB26HbLeSaEJqhFgzIxvWQ&_sg%5B1%5D=CZtZhHTEMgSwBZrpZU_7BACd8RH04JUKiITdXRQJ6MQ9SFS27jreZmcsuNcqYYWRoxcwBE-xBMbrfl1QobmEZ65bmkmpzonq5JoLRIIUKXne.jBF3fgrlhaJYs3bDEaHQU22nRpKP0zKeF_oOsqh7WddL8pfxAomPSbeANzdmLP9YPB26HbLeSaEJqhFgzIxvWQ&_iepl=}
}

@Misc{Mnih2016,
	author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
	title={Asynchronous Methods for Deep Reinforcement Learning},
	year={2016},
	publisher={PMLR},
	volume={48},
	pages={1928-1937},
	abstract={We propose a conceptually simple and lightweight framework for deep reinforcement learning that uses asynchronous gradient descent for optimization of deep neural network controllers. We present asynchronous variants of four standard reinforcement learning algorithms and show that parallel actor-learners have a stabilizing effect on training allowing all four methods to successfully train neural network controllers. The best performing method, an asynchronous variant of actor-critic, surpasses the current state-of-the-art on the Atari domain while training for half the time on a single multi-core CPU instead of a GPU. Furthermore, we show that asynchronous actor-critic succeeds on a wide variety of continuous motor control problems as well as on a new task of navigating random 3D mazes using a visual input.},
	note={New York, New York, USA},
	doi={10.48550/arXiv.1602.01783},
	url={https://proceedings.mlr.press/v48/mniha16.html}
}

@Misc{Konda1999,
	author={Konda, Vijay and Tsitsiklis, John},
	title={Actor-Critic Algorithms},
	year={1999},
	publisher={MIT Press},
	volume={12},
	url={https://proceedings.neurips.cc/paper_files/paper/1999/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf}
}


